{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f595141d-a047-4987-94e9-5f8d0c951962",
   "metadata": {},
   "source": [
    "# NOIRE-Net-analyze: This notebook loads the trained NOIRE-Net models and automatically classifies and scales ionograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12112e-096d-4ba0-8695-b2e74c5be197",
   "metadata": {},
   "source": [
    "## 1 - Import libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d36316-d3d7-4454-b3e1-1eaae611f82d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from statistics import median\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b323fb-6100-4107-bda5-124bd668af73",
   "metadata": {},
   "source": [
    "## 2 - Load NOIRE-Net models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31385eed-08f0-4aa3-94b7-d6256d335b56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:33:21.900621: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-20 11:33:21.900800: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load E-classify models \n",
    "e_classify_models = [load_model(f'/Users/akv020/Tensorflow/NOIRE-Net/NOIRE-Net/E-classify/E-classify_run{i}.h5') for i in range(1, 11)]\n",
    "\n",
    "# Load E-scale models\n",
    "e_scale_models = [load_model(f'/Users/akv020/Tensorflow/NOIRE-Net/NOIRE-Net/E-scale/E-scale_run{i}.h5') for i in range(1, 11)]\n",
    "\n",
    "# Load F-classify models\n",
    "f_classify_models = [load_model(f'/Users/akv020/Tensorflow/NOIRE-Net/NOIRE-Net/F-classify/F-classify_run{i}.h5') for i in range(1, 11)]\n",
    "\n",
    "# Load F-scale models\n",
    "f_scale_models = [load_model(f'/Users/akv020/Tensorflow/NOIRE-Net/NOIRE-Net/F-scale/F-scale_run{i}.h5') for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e827ac-395d-4736-a851-f86da2897f95",
   "metadata": {},
   "source": [
    "## 3 - Define directory containing black-and-white ionograms in .png format with dimension (310x310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590b727e-a357-456a-8172-05e3d6244b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory where the images are stored\n",
    "image_dir = '/Users/akv020/Tensorflow/NOIRE-Net/data/2024-03-19/ionograms/'\n",
    "result_dir = '/Users/akv020/Tensorflow/NOIRE-Net/data/2024-03-19/NOIRE-Net-analyzed/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a89bb79-9bb1-4fe8-a2c8-858270aa3d18",
   "metadata": {},
   "source": [
    "## 4 - Define a function to classify and scale ionograms using the NOIRE-Net models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2380a3-0c72-4f9a-9568-92387319ad9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code classify a PNG image in a specified directory using two sets of CNN models\n",
    "# (E-classify and F-classify). Positive ionograms are then processed by the CNN regression models:\n",
    "# (E-scale and F-scale), which computes the median and standard deviation of their regression outputs,\n",
    "# and stores these results along with their standard deviations in respective dictionaries for the\n",
    "# E-region and F-region analyses.\n",
    "\n",
    "# Function to both classify and scale (if positive class) an ionogram\n",
    "def classify_and_scale(image_array, classify_models, scale_models):\n",
    "    \n",
    "    # Use classify models to classify the ionogram into positive or negative class\n",
    "    classifications = [model.predict(image_array, verbose=0)[0][0] for model in classify_models]\n",
    "    positive_votes = sum(c > 0.5 for c in classifications)\n",
    "    negative_votes = len(classify_models) - positive_votes\n",
    "\n",
    "    # Handle tiebreaker with average accuracy\n",
    "    if positive_votes == negative_votes:\n",
    "        average_accuracy = np.mean(classifications)\n",
    "        is_positive = average_accuracy > 0.5\n",
    "    else:\n",
    "        is_positive = positive_votes > negative_votes\n",
    "    \n",
    "    # For positive ionograms (containing an E or an F-region trace) scale the ionogram\n",
    "    if is_positive:\n",
    "        scale_results = [model.predict(image_array, verbose=0) for model in scale_models]\n",
    "        median_result = np.median(scale_results, axis=0).tolist()\n",
    "        std_result = np.std(scale_results, axis=0).tolist()\n",
    "        \n",
    "    # For negative ionograms, populate dictonary index with \"nans\" \n",
    "    else:\n",
    "        median_result, std_result = [np.nan, np.nan], [np.nan, np.nan]\n",
    "    \n",
    "    # Return the results\n",
    "    return median_result, std_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d5846-e6a7-4611-ad20-0edbfa4f0f66",
   "metadata": {},
   "source": [
    "## 5 - Iterate over all images in a directory containing the input ionograms (.png files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622343df-3913-4a89-aba6-49dc8a38952c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:35:14.829879: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-03-20 11:35:14.955447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:17.582374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:17.855844: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:18.145526: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x35f049120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:35:18.427007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:18.713194: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x35f048b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:35:19.013809: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:19.327186: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:19.665512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:20.025736: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:20.315064: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:20.666000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:20.995408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:21.398139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:21.695987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:21.997160: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:22.562819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:22.908693: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:23.262945: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:23.702505: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:24.143006: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:24.493275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:24.836367: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:25.220398: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:25.667915: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:26.108992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:26.544351: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:26.974358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:27.411075: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:27.832840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:28.971812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:29.404696: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:29.964024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:30.396583: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:30.855679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:31.287341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:31.712531: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:32.145432: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:32.564502: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-20 11:35:33.009215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store results and standard deviations for E and F regions\n",
    "e_results, f_results = {}, {}\n",
    "e_std_devs, f_std_devs = {}, {}\n",
    "\n",
    "# Process each image in the specified directory\n",
    "#for image_name in os.listdir(image_dir):\n",
    "#    if image_name.endswith('.png'):\n",
    "        \n",
    "for i, image_name in enumerate(os.listdir(image_dir)):\n",
    "    if image_name.endswith('.png'):\n",
    "        # Construct the full path to the image\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "        # Read and preprocess the image\n",
    "        # Convert to grayscale, resize, and normalize the pixel values\n",
    "        img = Image.open(image_path).convert('L').resize((310, 310))\n",
    "        img_array = np.expand_dims(np.array(img).astype('float32') / 255.0, axis=[0, -1])\n",
    "\n",
    "        # Process the image with E-classify/E-scale models\n",
    "        # Store the results and standard deviations for E-region\n",
    "        e_results[image_name], e_std_devs[image_name] = classify_and_scale(img_array, e_classify_models, e_scale_models)\n",
    "\n",
    "        # Process the image with F-classify/F-scale models\n",
    "        # Store the results and standard deviations for F-region\n",
    "        f_results[image_name], f_std_devs[image_name] = classify_and_scale(img_array, f_classify_models, f_scale_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40cae47-2f16-434d-8dbd-741ab7d166d1",
   "metadata": {},
   "source": [
    "## 6 - Define a function to draw the E-scale and F-scale lines on top of the ionogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71a6a3e-38ac-4138-a955-c66929e0b29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_colored_lines_on_image(image_np, horizontal, vertical, std_horizontal, std_vertical, color='r'):\n",
    "    # Convert the NumPy array to a PIL Image and ensure it's in RGB mode\n",
    "    image = Image.fromarray(np.uint8(image_np))\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    # Create a draw object\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Define the line color as an RGB tuple\n",
    "    line_color = (255, 0, 0) if color == 'r' else (0, 0, 255)  # Red or blue\n",
    "\n",
    "    # Draw horizontal and vertical lines if they are not NaN\n",
    "    if not np.isnan(horizontal):\n",
    "        draw.line([(0, horizontal), (image.width, horizontal)], fill=line_color, width=1)\n",
    "\n",
    "    if not np.isnan(vertical):\n",
    "        draw.line([(vertical, 0), (vertical, image.height)], fill=line_color, width=1)\n",
    "\n",
    "    # Draw standard deviation lines if they are not NaN\n",
    "    if not np.isnan(std_horizontal):\n",
    "        upper_horizontal = max(0, min(image.height, horizontal + std_horizontal))\n",
    "        lower_horizontal = max(0, min(image.height, horizontal - std_horizontal))\n",
    "        draw.line([(0, upper_horizontal), (image.width, upper_horizontal)], fill=line_color, width=1)\n",
    "        draw.line([(0, lower_horizontal), (image.width, lower_horizontal)], fill=line_color, width=1)\n",
    "\n",
    "    if not np.isnan(std_vertical):\n",
    "        upper_vertical = max(0, min(image.width, vertical + std_vertical))\n",
    "        lower_vertical = max(0, min(image.width, vertical - std_vertical))\n",
    "        draw.line([(upper_vertical, 0), (upper_vertical, image.height)], fill=line_color, width=1)\n",
    "        draw.line([(lower_vertical, 0), (lower_vertical, image.height)], fill=line_color, width=1)\n",
    "\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b2427-5dc2-49ec-9583-320108369be6",
   "metadata": {},
   "source": [
    "## 7 - Define a function to acess regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2ea0a6-521c-44b4-aa78-74449e20fcf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function unpack_results checks if the input result is a nested list and, if so, unpacks\n",
    "# and returns the inner list; otherwise, it returns the input as is.\n",
    "def unpack_results(result):\n",
    "    if isinstance(result, list) and len(result) == 1 and isinstance(result[0], list):\n",
    "        return result[0]  # Unpack nested list\n",
    "    return result  # Use as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6541b18-17d2-448f-901e-7b33bc66299f",
   "metadata": {},
   "source": [
    "## 8 - Define functions to convert pixel values to a cusom scale and vise-verca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6124de1f-37ce-4898-8b80-32745c978fef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function converts a pixel value into a corresponding value on a custom scale. \n",
    "# Used to convert coordinates from an image to frequency in MHz or distance in km. \n",
    "# The function linearly interpolates the pixel value based on the range of the scale.\n",
    "def convert_pixel_to_custom_scale(pixel, image_size, min_val, max_val):\n",
    "    \"\"\"\n",
    "    Converts a pixel value to a value on a custom scale.\n",
    "    \n",
    "    Args:\n",
    "    pixel (float): The pixel value to convert.\n",
    "    image_size (int): The size of the image (in pixels) along the axis of interest.\n",
    "    min_val (float): The minimum value of the custom scale.\n",
    "    max_val (float): The maximum value of the custom scale.\n",
    "    \n",
    "    Returns:\n",
    "    float: The corresponding value on the custom scale.\n",
    "    \"\"\"\n",
    "    # Normalize the pixel value to a range [0, 1]\n",
    "    normalized_pixel = pixel / image_size\n",
    "\n",
    "    # Convert the normalized pixel to the custom scale\n",
    "    return min_val + (max_val - min_val) * normalized_pixel\n",
    "\n",
    "# Function to map custom values to pixel positions\n",
    "def map_to_pixel(value, start, stop, num_pixels):\n",
    "    return int((value - start) / (stop - start) * num_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222cb8b9-e6e5-42d0-aebf-e02290973c5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 9 - Save ionograms contianinng the scaling results for positive classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2add637a-f8c8-47d1-b641-2349c22b573f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images saved in the 'results' directory\n"
     ]
    }
   ],
   "source": [
    "# This code processes and saves images from a specified directory, overlaying them with colored lines\n",
    "# representing E-region and F-region scaling results, and annotates each image with custom frequency\n",
    "# and range scales, adjusting the title based on the presence of E and/or F-region features.\n",
    "\n",
    "# Define the scale for frequency and virtual distance\n",
    "range_start = 200058.33938693197 / 1e3  # km\n",
    "range_stop = 1498436.9620081205 / 1e3  # km\n",
    "freq_start = 0.549734235380000  # MHz\n",
    "freq_stop = 15.992268665599999  # MHz\n",
    "\n",
    "# Create frequency and range arrays\n",
    "frequencies = np.linspace(freq_start, freq_stop, num=310)\n",
    "ranges = np.linspace(range_start, range_stop, num=310)\n",
    "\n",
    "# Custom frequency and range values for ticks\n",
    "custom_frequencies = np.array([1, 3, 5, 7, 9, 11, 13, 15])  # MHz\n",
    "custom_ranges = np.array([300, 500, 700, 900, 1100, 1300, 1500])  # km\n",
    "\n",
    "# Process and save images with scaling results\n",
    "for image_name in os.listdir(image_dir):\n",
    "    if image_name.endswith('.png'):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        result_path = os.path.join(result_dir, image_name)\n",
    "\n",
    "        # Read and preprocess the image\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        img_array = np.flipud(np.array(img))  # Convert to numpy array and flip vertically\n",
    "\n",
    "        # Unpack results and standard deviations\n",
    "        e_vertical, e_horizontal = unpack_results(e_results.get(image_name, [np.nan, np.nan]))\n",
    "        f_vertical, f_horizontal = unpack_results(f_results.get(image_name, [np.nan, np.nan]))\n",
    "        e_std_vertical, e_std_horizontal = unpack_results(e_std_devs.get(image_name, [np.nan, np.nan]))\n",
    "        f_std_vertical, f_std_horizontal = unpack_results(f_std_devs.get(image_name, [np.nan, np.nan]))\n",
    "\n",
    "        # Adjust coordinates for flipped image\n",
    "        e_horizontal = img_array.shape[0] - e_horizontal\n",
    "        f_horizontal = img_array.shape[0] - f_horizontal\n",
    "\n",
    "        # Convert pixel values to frequency and range\n",
    "        e_frequency = convert_pixel_to_custom_scale(e_vertical, img_array.shape[1], freq_start, freq_stop)\n",
    "        f_frequency = convert_pixel_to_custom_scale(f_vertical, img_array.shape[1], freq_start, freq_stop)\n",
    "        e_range = convert_pixel_to_custom_scale(e_horizontal, img_array.shape[0], range_start, range_stop)\n",
    "        f_range = convert_pixel_to_custom_scale(f_horizontal, img_array.shape[0], range_start, range_stop)\n",
    "\n",
    "        # Draw lines on the image\n",
    "        img_with_e_lines = draw_colored_lines_on_image(img_array, e_horizontal, e_vertical, e_std_horizontal, e_std_vertical, color='r')\n",
    "        img_with_f_lines = draw_colored_lines_on_image(img_array, f_horizontal, f_vertical, f_std_horizontal, f_std_vertical, color='g')\n",
    "\n",
    "        # Combine images with lines\n",
    "        combined_img = np.maximum(img_with_e_lines, img_with_f_lines)\n",
    "\n",
    "        # Create a figure and axis for the plot\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.imshow(combined_img, cmap='gray', aspect='auto')\n",
    "\n",
    "        # Set custom x-ticks and y-ticks\n",
    "        x_tick_positions = [map_to_pixel(f, freq_start, freq_stop, combined_img.shape[1]) for f in custom_frequencies]\n",
    "        y_tick_positions = [map_to_pixel(r, range_stop, range_start, combined_img.shape[0]) for r in custom_ranges]\n",
    "\n",
    "        ax.set_xticks(x_tick_positions)\n",
    "        ax.set_xticklabels([f\"{f}\" for f in custom_frequencies])\n",
    "        ax.set_yticks(y_tick_positions)\n",
    "        ax.set_yticklabels([f\"{r}\" for r in custom_ranges])\n",
    "\n",
    "        ax.set_xlabel('Frequency [MHz]')\n",
    "        ax.set_ylabel('Virtual distance [km]')\n",
    "\n",
    "        # Set the title based on E and F-region results\n",
    "        title = 'No trace'\n",
    "        if not np.isnan(e_horizontal) and not np.isnan(f_horizontal):\n",
    "            title = 'E and F-region'\n",
    "        elif not np.isnan(e_horizontal):\n",
    "            title = 'E-region'\n",
    "        elif not np.isnan(f_horizontal):\n",
    "            title = 'F-region'\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # Adjust layout and save the image\n",
    "        plt.tight_layout()  # Adjust layout\n",
    "        plt.savefig(result_path, bbox_inches='tight')  # Save with reduced whitespace\n",
    "        plt.close()\n",
    "\n",
    "print(\"Processed images saved in the 'results' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7d75f-554a-417e-9df8-d849eadc7d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
