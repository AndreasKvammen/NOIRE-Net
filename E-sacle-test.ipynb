{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e53ced-74f4-49c9-9b7b-a6c7855016fb",
   "metadata": {},
   "source": [
    "# E-scale-test: This Notebook evaluates the NOIRE-Net E-region scaling pperformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed3f2a-1f02-4e67-808b-11874418ad77",
   "metadata": {},
   "source": [
    "## 1 - Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f284d-0972-4fdd-ad25-a5969779a5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f1d6d-b73b-49f2-8163-5a0f76c5d49c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 - Define a function to get ionogram scaling parameters from the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea3d2e-5c9d-4b89-97cb-8655b6f76a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_regression_label_from_par reads a .par file and returns \n",
    "# the E-region maximum frequency and the E-region height.\n",
    "# Both the foE and hE must be values (can not be 'nan'). \n",
    "\n",
    "def get_regression_label_from_par(par_file_path):\n",
    "    try:\n",
    "        # Open the file at the specified path\n",
    "        with open(par_file_path, 'r') as file:\n",
    "            content = file.readline().strip()  # Read the first line and remove leading/trailing whitespace\n",
    "            items = content.split()  # Split the line into individual items\n",
    "\n",
    "            # Check if both the second and fourth items are not 'nan' (not a number)\n",
    "            # If they are both valid numbers, convert them to floats and return them as a tuple\n",
    "            if items[1].lower() != 'nan' and items[3].lower() != 'nan':\n",
    "                return float(items[1]), float(items[3])\n",
    "            else:\n",
    "                # If either item is 'nan', return None\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        # Print an error message if an exception occurs while processing the file\n",
    "        print(f\"Error reading {par_file_path}: {e}\")\n",
    "        # Return None if there is an error\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad1694-eac3-480b-9e42-b0062f225da1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3 - Define functions to load and process test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9b91b-97b5-4215-bcba-6619fef281ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The load_data function loads and preprocesses image data from a specified directory,\n",
    "# converting images to grayscale and resizing them, while also extracting corresponding\n",
    "# scaling parameters from associated .par files for a regression task.\n",
    "\n",
    "def load_data(data_dir, target_size=(310, 310)):\n",
    "    images = []  # List to store preprocessed images\n",
    "    labels = []  # List to store corresponding regression labels\n",
    "\n",
    "    # Construct paths to the directories containing ionograms and parameters\n",
    "    ionograms_dir = os.path.join(data_dir, 'ionograms')\n",
    "    parameters_dir = os.path.join(data_dir, 'parameters')\n",
    "\n",
    "    # Iterate over the files in the ionograms directory\n",
    "    for filename in os.listdir(ionograms_dir):\n",
    "        if filename.endswith('.png'):  # Check if the file is a PNG image\n",
    "            # Construct full paths to the image file and its corresponding .par file\n",
    "            img_path = os.path.join(ionograms_dir, filename)\n",
    "            par_path = os.path.join(parameters_dir, filename.replace('.png', '.par'))\n",
    "\n",
    "            # Load the image, convert it to grayscale, resize it, and normalize pixel values\n",
    "            image = load_img(img_path, color_mode='grayscale', target_size=target_size)\n",
    "            image = img_to_array(image) / 255.0  # Normalize image pixels to be between 0 and 1\n",
    "\n",
    "            # Get the regression labels from the .par file\n",
    "            regression_label = get_regression_label_from_par(par_path)\n",
    "            \n",
    "            # Proceed only if valid regression labels are found\n",
    "            if regression_label is not None:\n",
    "                images.append(image)\n",
    "                labels.append(regression_label)\n",
    "\n",
    "    # Convert the lists of images and labels to numpy arrays and return them\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa36f89-3f55-44db-b1a1-de6d498c3797",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4 - Extract testing images and scaling parameters from human experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcf650-979d-4bb9-aabb-a21a99f6104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the data is stored\n",
    "data_dir = 'train-val-test'  # 'train_test_val' should be replaced with the actual path to your data directory\n",
    "\n",
    "# Call the load_data function to load and preprocess the data\n",
    "# X contain the preprocessed images, and y will contain the corresponding labels\n",
    "X, y = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d92b86-06e9-4180-8f3a-efe6a62ed5cb",
   "metadata": {},
   "source": [
    "## 5 - Load the trained models and evaluate the performance on the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2552c-ffd7-4b9e-a674-fa00fca8e344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code calculates and prints regression performance metrics (Root Mean Squared Error and \n",
    "# Median Absolute Distance) for two sets of true and predicted values, specifically for the\n",
    "# E-region maximum frequency and the E-region height.\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, scale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Calculate metrics for a given set of true and predicted values.\n",
    "    Args:\n",
    "    y_true (array): The true values.\n",
    "    y_pred (array): The predicted values.\n",
    "    scale_factor (float): Scale factor for RMSE.\n",
    "    Returns:\n",
    "    A dictionary containing RMSE and MAD metrics.\n",
    "    \"\"\"\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred)) * scale_factor\n",
    "    mad = np.median(np.abs(y_true - y_pred)) * scale_factor\n",
    "    return {'rmse': rmse, 'mad': mad}\n",
    "\n",
    "# Directory where models are saved\n",
    "model_dir = 'E-scale'\n",
    "\n",
    "# Define scale factors\n",
    "dF = 50     # The frequency resolution is 50 kHz/pixel\n",
    "dZ = 4.1935 # The virtual height resolution is 4.1935 km/pixel\n",
    "\n",
    "# Initialize lists to store metrics for all models\n",
    "all_freq_rmse, all_height_rmse = [], []\n",
    "all_freq_mad, all_height_mad = [], []\n",
    "\n",
    "# Load models and evaluate\n",
    "for i in range(10):\n",
    "    \n",
    "    # Use the same random state as in training for consistent test set\n",
    "    _, X_temp, _, y_temp = train_test_split(X, y, test_size=0.3, random_state=i)\n",
    "    _, X_test, _, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=i)\n",
    "\n",
    "    # Load the trained model\n",
    "    model_path = os.path.join(model_dir, f'E-scale_run{i+1}.h5')\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Predict on the test data\n",
    "    predictions = model.predict(X_test)\n",
    "    model_path = os.path.join(model_dir, f'E-scale_run{i+1}.h5')\n",
    "    model = load_model(model_path)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Extract frequency and height predictions\n",
    "    predictions_freq = predictions[:, 0]\n",
    "    predictions_height = predictions[:, 1]\n",
    "\n",
    "    # Extract true frequency and height values\n",
    "    y_test_freq = y_test[:, 0]\n",
    "    y_test_height = y_test[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    freq_metrics = calculate_metrics(y_test_freq, predictions_freq, dF)\n",
    "    height_metrics = calculate_metrics(y_test_height, predictions_height, dZ)\n",
    "\n",
    "    # Append metrics to respective lists\n",
    "    all_freq_rmse.append(freq_metrics['rmse'])\n",
    "    all_height_rmse.append(height_metrics['rmse'])\n",
    "    all_freq_mad.append(freq_metrics['mad'])\n",
    "    all_height_mad.append(height_metrics['mad'])\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_freq_rmse, std_freq_rmse = np.mean(all_freq_rmse), np.std(all_freq_rmse)\n",
    "mean_height_rmse, std_height_rmse = np.mean(all_height_rmse), np.std(all_height_rmse)\n",
    "mean_freq_mad, std_freq_mad = np.mean(all_freq_mad), np.std(all_freq_mad)\n",
    "mean_height_mad, std_height_mad = np.mean(all_height_mad), np.std(all_height_mad)\n",
    "\n",
    "# Print the results with standard deviation\n",
    "print(f\"E-region maximum frequency [kHz]: RMSE = {mean_freq_rmse:.2f} ± {std_freq_rmse:.2f}, MAD = {mean_freq_mad:.2f} ± {std_freq_mad:.2f}\")\n",
    "print(f\"E-region height [km]: RMSE = {mean_height_rmse:.2f} ± {std_height_rmse:.2f}, MAD = {mean_height_mad:.2f} ± {std_height_mad:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06001859-b4ab-47f1-89bb-78fae4ecc2ef",
   "metadata": {},
   "source": [
    "## 6 - Define function to extract testing images and scaling parameters from multi-human data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99635b-c759-444c-b916-6b76163181bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The load_data_experts function loads and preprocesses image data from a specified directory,\n",
    "# converting images to grayscale and resizing them, while also extracting corresponding\n",
    "# scaling parameters from associated .par files for a regression task.\n",
    "\n",
    "def load_data_experts(data_dir, experts, target_size=(310, 310)):\n",
    "    images = []  # List to store preprocessed images\n",
    "    labels = []  # List to store corresponding regression labels\n",
    "    timestamps = []  # List to store timestamps for each image\n",
    "\n",
    "    ionograms_dir = os.path.join(data_dir, 'ionograms')\n",
    "    parameters_dir = os.path.join(data_dir, 'parameters')\n",
    "\n",
    "    # Function to load and preprocess an image\n",
    "    def load_and_preprocess_image(image_path):\n",
    "        # Load the image file, resize it, and convert it to grayscale\n",
    "        image = load_img(image_path, target_size=target_size, color_mode='grayscale')\n",
    "        # Convert the image to a numpy array and normalize it\n",
    "        image = img_to_array(image) / 255.0\n",
    "        return image\n",
    "\n",
    "    # Iterate over the files in the ionograms directory\n",
    "    for filename in os.listdir(ionograms_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            img_path = os.path.join(ionograms_dir, filename)\n",
    "            # Extract timestamp without expert prefix\n",
    "            timestamp = os.path.splitext(filename)[0]\n",
    "            for expert in experts:\n",
    "                if timestamp.startswith(expert + '-'):\n",
    "                    timestamp = timestamp[len(expert) + 1:]  # Remove expert prefix and '-'\n",
    "                    break\n",
    "            timestamps.append(timestamp)\n",
    "\n",
    "            # Collect labels from all experts for this image\n",
    "            expert_labels = []\n",
    "            for expert in experts:\n",
    "                par_path = os.path.join(parameters_dir, f\"{expert}-{timestamp}.par\")\n",
    "                if os.path.exists(par_path):\n",
    "                    label = get_regression_label_from_par(par_path)\n",
    "                    if label is not None:\n",
    "                        expert_labels.append(label)\n",
    "\n",
    "            # Proceed only if there are labels from experts\n",
    "            if expert_labels:\n",
    "                image = load_and_preprocess_image(img_path)\n",
    "                images.append(image)\n",
    "                # Calculate the median label across experts for this image\n",
    "                labels.append(np.median(expert_labels, axis=0))\n",
    "\n",
    "    # Convert the lists of images and labels to numpy arrays and return them\n",
    "    return np.array(images), np.array(labels), timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a9da6-108c-4dc4-812b-acc7a22e1976",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7 - Load the multi-human testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cc6a2e-dc11-492a-b2e8-6eade066e96e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_experts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have a function to load test data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# X_test contains test images, and y_test contains corresponding human labels\u001b[39;00m\n\u001b[1;32m      3\u001b[0m experts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124makv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdhu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124masp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m X_test, y_test, image_timestamps \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_experts\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, experts)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data_experts' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have a function to load test data\n",
    "# X_test contains test images, and y_test contains corresponding human labels\n",
    "experts = ['akv', 'trx', 'dhu', 'jvi', 'asp']\n",
    "X_test, y_test, image_timestamps = load_data_experts('test', experts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d490e2-2c85-4df8-8806-3065d23cab22",
   "metadata": {},
   "source": [
    "## 8 - Load the trained models with the lowest validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d72d77-4225-425b-b9f6-2a9dc36b547b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming models are named 'E-scale-run1' to 'E-scale-run10' and saved in the 'E-scale' directory\n",
    "model_dir = 'E-scale'\n",
    "model_names = [f'E-scale_run{i}' for i in range(1, 11)]\n",
    "models = []\n",
    "\n",
    "# Load all models\n",
    "for model_name in model_names:\n",
    "    model_path = os.path.join(model_dir, model_name + '.h5')  # Adjust extension based on how models are saved\n",
    "    models.append(load_model(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efabd6-f596-4475-8e1a-a654d3f7f0b7",
   "metadata": {},
   "source": [
    "## 9 - Use the trained CNNs to predict the ionogram E-region scaling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13cfdd3-c7ff-44ae-9906-3849701b8c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict using each model\n",
    "predictions = [model.predict(X_test) for model in models]\n",
    "\n",
    "# Convert list of predictions to a numpy array for easy median calculation\n",
    "predictions_array = np.array(predictions)\n",
    "\n",
    "# Calculate the median across all model predictions for each test data point\n",
    "median_predictions = np.median(predictions_array, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73bc26f-28c3-458f-b394-a10be110bd14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 10 - Extract the median human and median CNN predicaiton across the 10 CNNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a34b3-2d9e-4788-bddd-e35dc80c293f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract human outputs for E-region maximum frequency (first output) and E-region height (second output)\n",
    "y_test_freq = y_test[:, 0]\n",
    "y_test_height = y_test[:, 1]\n",
    "\n",
    "\n",
    "# Extract CNN predictions for E-region maximum frequency (first output) and E-region height (second output)\n",
    "median_predictions_freq = median_predictions[:, 0]\n",
    "median_predictions_height = median_predictions[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39dc24a-5301-48ca-b947-14777edff07b",
   "metadata": {},
   "source": [
    "## 11 - Calculate and display the scaling evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960920c-ba28-4510-a919-6c819563fce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code calculates and prints regression performance metrics (Root Mean Squared Error and \n",
    "# Median Absolute Distance) for two sets of true and predicted values, specifically for the\n",
    "# E-region maximum frequency and the E-region height.\n",
    "\n",
    "def calculate_and_print_metrics(y_true, y_pred, output_name, scale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Calculate and print metrics for a given set of true and predicted values.\n",
    "\n",
    "    Args:\n",
    "    y_true (array): The true values.\n",
    "    y_pred (array): The predicted values.\n",
    "    output_name (str): The name of the output (for printing).\n",
    "    scale_factor (float): Scale factor for RMSE (default is 1.0).\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mad = np.median(np.abs(y_true - y_pred))\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"{output_name}:\")\n",
    "    print(f\"Root Mean Squared Error: {rmse * scale_factor}\")\n",
    "    print(f\"Median Absolute Distance: {mad * scale_factor}\")\n",
    "\n",
    "\n",
    "dF = 50     # The frequency resolution is 50 kHz/pixel\n",
    "dZ = 4.1935 # The virtual distance resolution is 4.1935 km/pixel\n",
    "\n",
    "# Calculate and print metrics for each output\n",
    "calculate_and_print_metrics(y_test_freq, median_predictions_freq, \n",
    "                            \"E-region maximum frequency [kHz]\", scale_factor=dF)\n",
    "calculate_and_print_metrics(y_test_height, median_predictions_height, \n",
    "                            \"E-region height [km]\", scale_factor=dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6312f76-7d2a-4547-a27b-9dcb6a44be76",
   "metadata": {},
   "source": [
    "## 12 - Visually compare the human and CNN E-region scaling for 4 random ionograms in the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dff447-c802-41dc-8d11-63dbe7b04e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code visualizes 4 randomly selected test images, overlaying them with horizontal and vertical lines \n",
    "# representing the true and predicted values for certain parameters, where the true values are marked\n",
    "# in green and the predictions in red. \n",
    "\n",
    "def draw_colored_lines_on_image(image, horizontal, vertical, std_horizontal, std_vertical, color='r'):\n",
    "    \"\"\"\n",
    "    Draws horizontal and vertical colored lines on the image, along with thinner standard deviation lines.\n",
    "    \"\"\"\n",
    "    # Convert grayscale to RGB if necessary\n",
    "    if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "        image_rgb = np.stack((image.squeeze(),) * 3, axis=-1)\n",
    "    else:\n",
    "        image_rgb = np.copy(image)\n",
    "\n",
    "    # Define line color\n",
    "    line_color = [1, 0, 0] if color == 'r' else [0, 1, 0]  # Red for prediction, Green for true value\n",
    "\n",
    "    # Draw main lines (thicker)\n",
    "    image_rgb[int(horizontal), :] = line_color\n",
    "    image_rgb[:, int(vertical)] = line_color\n",
    "\n",
    "    # Draw standard deviation lines (thinner)\n",
    "    if color == 'r':  # Only for predictions\n",
    "        std_color = [1, 0, 0]  # Red color\n",
    "        upper_horizontal, lower_horizontal = int(horizontal + std_horizontal), int(horizontal - std_horizontal)\n",
    "        upper_vertical, lower_vertical = int(vertical + std_vertical), int(vertical - std_vertical)\n",
    "\n",
    "        # Single pixel line for standard deviation\n",
    "        image_rgb[upper_horizontal, :] = std_color\n",
    "        image_rgb[lower_horizontal, :] = std_color\n",
    "        image_rgb[:, upper_vertical] = std_color\n",
    "        image_rgb[:, lower_vertical] = std_color\n",
    "\n",
    "    return image_rgb\n",
    "\n",
    "# Select 9 random images and their labels from the test set\n",
    "indices = random.sample(range(len(X_test)), 4)\n",
    "sample_images = X_test[indices]\n",
    "sample_labels = y_test[indices]\n",
    "sample_predictions = median_predictions[indices]\n",
    "\n",
    "# Calculate standard deviations for predictions\n",
    "std_predictions = np.std(predictions_array, axis=0)\n",
    "std_predictions_vertical = std_predictions[:, 0]\n",
    "std_predictions_horizontal = std_predictions[:, 1]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Original image flipped vertically\n",
    "    img = np.flipud(sample_images[i].squeeze())  # Remove channel dimension and flip\n",
    "    \n",
    "    # Get standard deviations for the current sample\n",
    "    std_pred_horizontal = std_predictions_horizontal[indices[i]]\n",
    "    std_pred_vertical = std_predictions_vertical[indices[i]]\n",
    "\n",
    "    # Get true and predicted values, adjusted for the flipped image\n",
    "    true_vertical, true_horizontal = sample_labels[i]  # Swap the order here\n",
    "    true_horizontal = img.shape[0] - true_horizontal  # Adjust for flipping\n",
    "    pred_vertical, pred_horizontal = sample_predictions[i]  # Swap the order here\n",
    "    pred_horizontal = img.shape[0] - pred_horizontal  # Adjust for flipping\n",
    "\n",
    "    # Draw lines including standard deviations\n",
    "    img_with_pred_lines = draw_colored_lines_on_image(img, pred_horizontal, pred_vertical, std_pred_horizontal, std_pred_vertical, color='r')\n",
    "    img_with_true_lines = draw_colored_lines_on_image(img, true_horizontal, true_vertical, 0, 0, color='g')\n",
    "\n",
    "    # Combine images with true and predicted lines\n",
    "    combined_img = np.maximum(img_with_true_lines, img_with_pred_lines)\n",
    "\n",
    "    # Display the image with lines\n",
    "    ax.imshow(combined_img, cmap='gray')\n",
    "    ax.set_title(f\"Image {indices[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
