{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6553ab89-fa75-447a-8c08-7f25ac7ad487",
   "metadata": {},
   "source": [
    "# E-scale: This Notebook develops and evaluates the NOIRE-Net E-region scaling networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c0c57-c234-41ea-8680-1323ec8c1656",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 - Develop NOIRE-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ec13f-8079-401c-aaf2-37f2981acd5b",
   "metadata": {},
   "source": [
    "### 1.1 - Import libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80990a8e-2d87-444b-aa25-42ea1903521d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57942b9-0d1e-4c29-b201-dae42e4f99bd",
   "metadata": {},
   "source": [
    "### 1.2 - Define function to get E-region scaling parameters from .par file (item1 = fE, item2 = hE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b8714c8-324c-4ddb-ab4e-5ac56070ba76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function get_regression_label_from_par reads a .par file and returns \n",
    "# the E-region maximum frequency and the E-region height.\n",
    "# Both the fE and hE must be values (can not be 'nan'). \n",
    "\n",
    "def get_regression_label_from_par(par_file_path):\n",
    "    try:\n",
    "        # Open the file at the specified path\n",
    "        with open(par_file_path, 'r') as file:\n",
    "            content = file.readline().strip()  # Read the first line and remove leading/trailing whitespace\n",
    "            items = content.split()  # Split the line into individual items\n",
    "\n",
    "            # Check if both the second and fourth items are not 'nan' (not a number)\n",
    "            # If they are both valid numbers, convert them to floats and return them as a tuple\n",
    "            if items[1].lower() != 'nan' and items[3].lower() != 'nan':\n",
    "                return float(items[1]), float(items[3])\n",
    "            else:\n",
    "                # If either item is 'nan', return None\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        # Print an error message if an exception occurs while processing the file\n",
    "        print(f\"Error reading {par_file_path}: {e}\")\n",
    "        # Return None if there is an error\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5dd112-47cc-48b4-915e-5d52e25ec6cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3 - Define function to load ionograms and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c413a846-e152-4d08-9231-856a3066eded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The load_data function loads and preprocesses image data from a specified directory,\n",
    "# converting images to grayscale and resizing them, while also extracting corresponding\n",
    "# scaling parameters from associated .par files for a regression task.\n",
    "\n",
    "def load_data(data_dir, target_size=(310, 310)):\n",
    "    images = []  # List to store preprocessed images\n",
    "    labels = []  # List to store corresponding regression labels\n",
    "\n",
    "    # Construct paths to the directories containing ionograms and parameters\n",
    "    ionograms_dir = os.path.join(data_dir, 'ionograms')\n",
    "    parameters_dir = os.path.join(data_dir, 'parameters')\n",
    "\n",
    "    # Iterate over the files in the ionograms directory\n",
    "    for filename in os.listdir(ionograms_dir):\n",
    "        if filename.endswith('.png'):  # Check if the file is a PNG image\n",
    "            # Construct full paths to the image file and its corresponding .par file\n",
    "            img_path = os.path.join(ionograms_dir, filename)\n",
    "            par_path = os.path.join(parameters_dir, filename.replace('.png', '.par'))\n",
    "\n",
    "            # Load the image, convert it to grayscale, resize it, and normalize pixel values\n",
    "            image = load_img(img_path, color_mode='grayscale', target_size=target_size)\n",
    "            image = img_to_array(image) / 255.0  # Normalize image pixels to be between 0 and 1\n",
    "\n",
    "            # Get the regression labels from the .par file\n",
    "            regression_label = get_regression_label_from_par(par_path)\n",
    "            \n",
    "            # Proceed only if valid regression labels are found\n",
    "            if regression_label is not None:\n",
    "                images.append(image)\n",
    "                labels.append(regression_label)\n",
    "\n",
    "    # Convert the lists of images and labels to numpy arrays and return them\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34042b-b7a9-4fce-ae53-61d68a1252e1",
   "metadata": {},
   "source": [
    "### 1.4 - Load the ionograms and labels from the data folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d19eba-8888-42dc-a7c1-8f01e388aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where the data is stored\n",
    "data_dir = 'train-val'  # 'train_test_val' should be replaced with the actual path to your data directory\n",
    "\n",
    "# Call the load_data function to load and preprocess the data\n",
    "# X wildsdsdl contain the preprocessed images, and y will contain the corresponding labels\n",
    "X, y = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12934bcf-6a1f-4429-b3a7-31bbf697c4fb",
   "metadata": {},
   "source": [
    "### 1.5 - Define a function to create the NOIRE-Net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63999a78-e194-419d-a6cb-93a42fd9a1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code defines and complies NOIRE-Net a convolutional neural network (CNN) model using Keras, \n",
    "# with multiple convolutional layers, batch normalization, max pooling, and dense layers, \n",
    "# designed for binary classification tasks.\n",
    "\n",
    "def NOIREnet():\n",
    "    model = Sequential([\n",
    "    # First convolutional layer with 32 filters and a kernel size of 3x3\n",
    "    # 'padding=same' ensures the output size is the same as the input size\n",
    "    # 'input_shape' is set for the first layer to indicate the shape of the input data\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(310, 310, 1)),\n",
    "    \n",
    "    # Batch normalization to normalize the activations from the previous layer\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # Second convolutional layer with 32 filters and a kernel size of 3x3\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "\n",
    "    # Another batch normalization\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # First max pooling layer to reduce spatial dimensions\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Repeating the pattern of two convolutional layers followed by batch normalization\n",
    "    # and a max pooling layer, gradually increasing the number of filters\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Flatten the output from the convolutional layers to feed into dense layers\n",
    "    Flatten(),\n",
    "\n",
    "    # Dense (fully connected) layer with 256 neurons and relu activation\n",
    "    Dense(256, activation='relu'),\n",
    "\n",
    "    # Dropout layer to reduce overfitting\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Another dense layer with 128 neurons\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # Output layer with a single neuron and sigmoid activation for binary classification\n",
    "    Dense(2, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    # Compile the CNN model\n",
    "    model.compile(\n",
    "        optimizer='adam',  # Using the Adam optimizer for adaptive learning rate optimization\n",
    "        loss='mse',  # Mean squared error loss function, suitable for regression tasks\n",
    "        metrics=['mse']  # The model will report 'mse' as a performance metric\n",
    "    )\n",
    "    \n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e79f5-b94d-4d83-9fb5-2eec0704815b",
   "metadata": {},
   "source": [
    "### 1.6 - Train 10 CNNs for E-region scaling and save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c64aa5-20e0-4d48-b719-ccc1e1d6e537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 19:03:23.275345: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-30 19:03:23.275483: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 19:03:25.538871: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-11-30 19:03:26.383801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 4800.0112 - mse: 4800.0112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 19:04:27.947327: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 6602.66846, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 68s 668ms/step - loss: 4800.0112 - mse: 4800.0112 - val_loss: 6602.6685 - val_mse: 6602.6685 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 499.9536 - mse: 499.9536\n",
      "Epoch 2: val_loss improved from 6602.66846 to 5856.19531, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 66s 690ms/step - loss: 499.9536 - mse: 499.9536 - val_loss: 5856.1953 - val_mse: 5856.1953 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 273.5941 - mse: 273.5941\n",
      "Epoch 3: val_loss improved from 5856.19531 to 4890.13818, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 273.5941 - mse: 273.5941 - val_loss: 4890.1382 - val_mse: 4890.1382 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 252.0084 - mse: 252.0084\n",
      "Epoch 4: val_loss improved from 4890.13818 to 3940.87817, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 252.0084 - mse: 252.0084 - val_loss: 3940.8782 - val_mse: 3940.8782 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 229.2492 - mse: 229.2492\n",
      "Epoch 5: val_loss improved from 3940.87817 to 2304.36938, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 65s 687ms/step - loss: 229.2492 - mse: 229.2492 - val_loss: 2304.3694 - val_mse: 2304.3694 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 203.7773 - mse: 203.7773\n",
      "Epoch 6: val_loss improved from 2304.36938 to 1741.12061, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 66s 689ms/step - loss: 203.7773 - mse: 203.7773 - val_loss: 1741.1206 - val_mse: 1741.1206 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 134.8481 - mse: 134.8481\n",
      "Epoch 7: val_loss improved from 1741.12061 to 414.51196, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 65s 680ms/step - loss: 134.8481 - mse: 134.8481 - val_loss: 414.5120 - val_mse: 414.5120 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 117.5479 - mse: 117.5479\n",
      "Epoch 8: val_loss did not improve from 414.51196\n",
      "95/95 [==============================] - 63s 665ms/step - loss: 117.5479 - mse: 117.5479 - val_loss: 425.1608 - val_mse: 425.1608 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 163.0390 - mse: 163.0390\n",
      "Epoch 9: val_loss improved from 414.51196 to 138.98299, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 163.0390 - mse: 163.0390 - val_loss: 138.9830 - val_mse: 138.9830 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 131.7879 - mse: 131.7879\n",
      "Epoch 10: val_loss improved from 138.98299 to 93.97102, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 131.7879 - mse: 131.7879 - val_loss: 93.9710 - val_mse: 93.9710 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 119.3413 - mse: 119.3413\n",
      "Epoch 11: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 65s 688ms/step - loss: 119.3413 - mse: 119.3413 - val_loss: 325.4504 - val_mse: 325.4504 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 104.7207 - mse: 104.7207\n",
      "Epoch 12: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 104.7207 - mse: 104.7207 - val_loss: 125.4106 - val_mse: 125.4106 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 105.6187 - mse: 105.6187\n",
      "Epoch 13: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 105.6187 - mse: 105.6187 - val_loss: 99.4256 - val_mse: 99.4256 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 121.9973 - mse: 121.9973\n",
      "Epoch 14: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 64s 674ms/step - loss: 121.9973 - mse: 121.9973 - val_loss: 128.1185 - val_mse: 128.1185 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 83.8027 - mse: 83.8027\n",
      "Epoch 15: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 65s 683ms/step - loss: 83.8027 - mse: 83.8027 - val_loss: 102.7031 - val_mse: 102.7031 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 108.9328 - mse: 108.9328\n",
      "Epoch 16: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 108.9328 - mse: 108.9328 - val_loss: 114.1726 - val_mse: 114.1726 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 74.5171 - mse: 74.5171\n",
      "Epoch 17: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 74.5171 - mse: 74.5171 - val_loss: 111.3365 - val_mse: 111.3365 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 83.8652 - mse: 83.8652\n",
      "Epoch 18: val_loss did not improve from 93.97102\n",
      "95/95 [==============================] - 64s 680ms/step - loss: 83.8652 - mse: 83.8652 - val_loss: 96.3908 - val_mse: 96.3908 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 69.5136 - mse: 69.5136\n",
      "Epoch 19: val_loss improved from 93.97102 to 83.48868, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 69.5136 - mse: 69.5136 - val_loss: 83.4887 - val_mse: 83.4887 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 70.7252 - mse: 70.7252\n",
      "Epoch 20: val_loss improved from 83.48868 to 80.89634, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 65s 682ms/step - loss: 70.7252 - mse: 70.7252 - val_loss: 80.8963 - val_mse: 80.8963 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 75.9972 - mse: 75.9972\n",
      "Epoch 21: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 65s 690ms/step - loss: 75.9972 - mse: 75.9972 - val_loss: 138.8037 - val_mse: 138.8037 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 58.9585 - mse: 58.9585\n",
      "Epoch 22: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 58.9585 - mse: 58.9585 - val_loss: 95.3763 - val_mse: 95.3763 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 63.7701 - mse: 63.7701\n",
      "Epoch 23: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 67s 703ms/step - loss: 63.7701 - mse: 63.7701 - val_loss: 86.2927 - val_mse: 86.2927 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 85.3623 - mse: 85.3623\n",
      "Epoch 24: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 66s 691ms/step - loss: 85.3623 - mse: 85.3623 - val_loss: 109.4242 - val_mse: 109.4242 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 93.8481 - mse: 93.8481\n",
      "Epoch 25: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 93.8481 - mse: 93.8481 - val_loss: 129.7137 - val_mse: 129.7137 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 69.0834 - mse: 69.0834\n",
      "Epoch 26: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 65s 684ms/step - loss: 69.0834 - mse: 69.0834 - val_loss: 97.8488 - val_mse: 97.8488 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 49.6923 - mse: 49.6923\n",
      "Epoch 27: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 65s 689ms/step - loss: 49.6923 - mse: 49.6923 - val_loss: 120.1767 - val_mse: 120.1767 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 55.2463 - mse: 55.2463\n",
      "Epoch 28: val_loss did not improve from 80.89634\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 55.2463 - mse: 55.2463 - val_loss: 90.0022 - val_mse: 90.0022 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 46.7259 - mse: 46.7259\n",
      "Epoch 29: val_loss improved from 80.89634 to 78.94762, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 68s 719ms/step - loss: 46.7259 - mse: 46.7259 - val_loss: 78.9476 - val_mse: 78.9476 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 42.4885 - mse: 42.4885\n",
      "Epoch 30: val_loss did not improve from 78.94762\n",
      "95/95 [==============================] - 66s 700ms/step - loss: 42.4885 - mse: 42.4885 - val_loss: 129.5267 - val_mse: 129.5267 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 39.8632 - mse: 39.8632\n",
      "Epoch 31: val_loss improved from 78.94762 to 72.44141, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 39.8632 - mse: 39.8632 - val_loss: 72.4414 - val_mse: 72.4414 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 44.1423 - mse: 44.1423\n",
      "Epoch 32: val_loss improved from 72.44141 to 72.09921, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 44.1423 - mse: 44.1423 - val_loss: 72.0992 - val_mse: 72.0992 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.6949 - mse: 26.6949\n",
      "Epoch 33: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 26.6949 - mse: 26.6949 - val_loss: 98.7866 - val_mse: 98.7866 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 29.9081 - mse: 29.9081\n",
      "Epoch 34: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 29.9081 - mse: 29.9081 - val_loss: 77.3989 - val_mse: 77.3989 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 31.6074 - mse: 31.6074\n",
      "Epoch 35: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 31.6074 - mse: 31.6074 - val_loss: 107.9596 - val_mse: 107.9596 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 38.4902 - mse: 38.4902\n",
      "Epoch 36: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 67s 706ms/step - loss: 38.4902 - mse: 38.4902 - val_loss: 72.1609 - val_mse: 72.1609 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 44.8465 - mse: 44.8465\n",
      "Epoch 37: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 44.8465 - mse: 44.8465 - val_loss: 126.0167 - val_mse: 126.0167 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 55.2705 - mse: 55.2705\n",
      "Epoch 38: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 67s 703ms/step - loss: 55.2705 - mse: 55.2705 - val_loss: 72.1038 - val_mse: 72.1038 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.4546 - mse: 25.4546\n",
      "Epoch 39: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 65s 684ms/step - loss: 25.4546 - mse: 25.4546 - val_loss: 85.2156 - val_mse: 85.2156 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 31.7160 - mse: 31.7160\n",
      "Epoch 40: val_loss did not improve from 72.09921\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 31.7160 - mse: 31.7160 - val_loss: 76.3400 - val_mse: 76.3400 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.0343 - mse: 20.0343\n",
      "Epoch 41: val_loss improved from 72.09921 to 68.54121, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 65s 684ms/step - loss: 20.0343 - mse: 20.0343 - val_loss: 68.5412 - val_mse: 68.5412 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.0176 - mse: 20.0176\n",
      "Epoch 42: val_loss did not improve from 68.54121\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 20.0176 - mse: 20.0176 - val_loss: 78.8730 - val_mse: 78.8730 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.4586 - mse: 18.4586\n",
      "Epoch 43: val_loss did not improve from 68.54121\n",
      "95/95 [==============================] - 67s 706ms/step - loss: 18.4586 - mse: 18.4586 - val_loss: 75.8551 - val_mse: 75.8551 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 34.0622 - mse: 34.0622\n",
      "Epoch 44: val_loss did not improve from 68.54121\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 34.0622 - mse: 34.0622 - val_loss: 69.4816 - val_mse: 69.4816 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.6100 - mse: 21.6100\n",
      "Epoch 45: val_loss did not improve from 68.54121\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 21.6100 - mse: 21.6100 - val_loss: 83.1713 - val_mse: 83.1713 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.6432 - mse: 24.6432\n",
      "Epoch 46: val_loss did not improve from 68.54121\n",
      "95/95 [==============================] - 67s 707ms/step - loss: 24.6432 - mse: 24.6432 - val_loss: 89.4085 - val_mse: 89.4085 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.5946 - mse: 26.5946\n",
      "Epoch 47: val_loss improved from 68.54121 to 68.24675, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 26.5946 - mse: 26.5946 - val_loss: 68.2467 - val_mse: 68.2467 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.1342 - mse: 19.1342\n",
      "Epoch 48: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 65s 684ms/step - loss: 19.1342 - mse: 19.1342 - val_loss: 70.6070 - val_mse: 70.6070 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.7016 - mse: 22.7016\n",
      "Epoch 49: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 65s 689ms/step - loss: 22.7016 - mse: 22.7016 - val_loss: 91.7343 - val_mse: 91.7343 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.4038 - mse: 19.4038\n",
      "Epoch 50: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 67s 703ms/step - loss: 19.4038 - mse: 19.4038 - val_loss: 72.9734 - val_mse: 72.9734 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.0943 - mse: 14.0943\n",
      "Epoch 51: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 14.0943 - mse: 14.0943 - val_loss: 76.0633 - val_mse: 76.0633 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.4811 - mse: 17.4811\n",
      "Epoch 52: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 67s 710ms/step - loss: 17.4811 - mse: 17.4811 - val_loss: 71.7733 - val_mse: 71.7733 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.6877 - mse: 19.6877\n",
      "Epoch 53: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 68s 715ms/step - loss: 19.6877 - mse: 19.6877 - val_loss: 75.1005 - val_mse: 75.1005 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.2565 - mse: 24.2565\n",
      "Epoch 54: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 24.2565 - mse: 24.2565 - val_loss: 84.2497 - val_mse: 84.2497 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2088 - mse: 15.2088\n",
      "Epoch 55: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 15.2088 - mse: 15.2088 - val_loss: 74.6848 - val_mse: 74.6848 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.3833 - mse: 13.3833\n",
      "Epoch 56: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 64s 674ms/step - loss: 13.3833 - mse: 13.3833 - val_loss: 73.3996 - val_mse: 73.3996 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.5083 - mse: 17.5083\n",
      "Epoch 57: val_loss did not improve from 68.24675\n",
      "95/95 [==============================] - 67s 709ms/step - loss: 17.5083 - mse: 17.5083 - val_loss: 71.8951 - val_mse: 71.8951 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.6706 - mse: 9.6706\n",
      "Epoch 58: val_loss improved from 68.24675 to 65.57190, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 9.6706 - mse: 9.6706 - val_loss: 65.5719 - val_mse: 65.5719 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6902 - mse: 7.6902\n",
      "Epoch 59: val_loss improved from 65.57190 to 64.81406, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 66s 700ms/step - loss: 7.6902 - mse: 7.6902 - val_loss: 64.8141 - val_mse: 64.8141 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.4576 - mse: 7.4576\n",
      "Epoch 60: val_loss improved from 64.81406 to 64.65368, saving model to E-scale2/E2-scale_run1.h5\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 7.4576 - mse: 7.4576 - val_loss: 64.6537 - val_mse: 64.6537 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.1750 - mse: 7.1750\n",
      "Epoch 61: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 7.1750 - mse: 7.1750 - val_loss: 65.2881 - val_mse: 65.2881 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 6.6141 - mse: 6.6141\n",
      "Epoch 62: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 706ms/step - loss: 6.6141 - mse: 6.6141 - val_loss: 66.2195 - val_mse: 66.2195 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 6.5537 - mse: 6.5537\n",
      "Epoch 63: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 6.5537 - mse: 6.5537 - val_loss: 65.8860 - val_mse: 65.8860 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 6.7658 - mse: 6.7658\n",
      "Epoch 64: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 6.7658 - mse: 6.7658 - val_loss: 65.9352 - val_mse: 65.9352 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.8558 - mse: 5.8558\n",
      "Epoch 65: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 5.8558 - mse: 5.8558 - val_loss: 66.9111 - val_mse: 66.9111 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 6.0366 - mse: 6.0366\n",
      "Epoch 66: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 699ms/step - loss: 6.0366 - mse: 6.0366 - val_loss: 66.3933 - val_mse: 66.3933 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.9048 - mse: 5.9048\n",
      "Epoch 67: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 709ms/step - loss: 5.9048 - mse: 5.9048 - val_loss: 65.7171 - val_mse: 65.7171 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 6.6526 - mse: 6.6526\n",
      "Epoch 68: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 6.6526 - mse: 6.6526 - val_loss: 66.7770 - val_mse: 66.7770 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.8025 - mse: 5.8025\n",
      "Epoch 69: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 707ms/step - loss: 5.8025 - mse: 5.8025 - val_loss: 66.9879 - val_mse: 66.9879 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.2027 - mse: 5.2027\n",
      "Epoch 70: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 691ms/step - loss: 5.2027 - mse: 5.2027 - val_loss: 68.9046 - val_mse: 68.9046 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.2077 - mse: 5.2077\n",
      "Epoch 71: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 5.2077 - mse: 5.2077 - val_loss: 66.8627 - val_mse: 66.8627 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.9912 - mse: 5.9912\n",
      "Epoch 72: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 708ms/step - loss: 5.9912 - mse: 5.9912 - val_loss: 66.8116 - val_mse: 66.8116 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.8849 - mse: 4.8849\n",
      "Epoch 73: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 4.8849 - mse: 4.8849 - val_loss: 66.7843 - val_mse: 66.7843 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.9764 - mse: 4.9764\n",
      "Epoch 74: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 4.9764 - mse: 4.9764 - val_loss: 66.8542 - val_mse: 66.8542 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.7664 - mse: 4.7664\n",
      "Epoch 75: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 56s 592ms/step - loss: 4.7664 - mse: 4.7664 - val_loss: 66.9846 - val_mse: 66.9846 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.7034 - mse: 4.7034\n",
      "Epoch 76: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 680ms/step - loss: 4.7034 - mse: 4.7034 - val_loss: 66.8266 - val_mse: 66.8266 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.0961 - mse: 5.0961\n",
      "Epoch 77: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 5.0961 - mse: 5.0961 - val_loss: 67.1245 - val_mse: 67.1245 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.3575 - mse: 5.3575\n",
      "Epoch 78: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 5.3575 - mse: 5.3575 - val_loss: 66.9534 - val_mse: 66.9534 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.0968 - mse: 5.0968\n",
      "Epoch 79: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 5.0968 - mse: 5.0968 - val_loss: 67.6025 - val_mse: 67.6025 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.8385 - mse: 4.8385\n",
      "Epoch 80: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 703ms/step - loss: 4.8385 - mse: 4.8385 - val_loss: 66.7327 - val_mse: 66.7327 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.2401 - mse: 5.2401\n",
      "Epoch 81: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 5.2401 - mse: 5.2401 - val_loss: 66.9306 - val_mse: 66.9306 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.1325 - mse: 5.1325\n",
      "Epoch 82: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 689ms/step - loss: 5.1325 - mse: 5.1325 - val_loss: 66.8327 - val_mse: 66.8327 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.8790 - mse: 4.8790\n",
      "Epoch 83: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 4.8790 - mse: 4.8790 - val_loss: 66.6393 - val_mse: 66.6393 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.4671 - mse: 5.4671\n",
      "Epoch 84: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 684ms/step - loss: 5.4671 - mse: 5.4671 - val_loss: 66.8121 - val_mse: 66.8121 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.1152 - mse: 5.1152\n",
      "Epoch 85: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 689ms/step - loss: 5.1152 - mse: 5.1152 - val_loss: 66.9364 - val_mse: 66.9364 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.0147 - mse: 5.0147\n",
      "Epoch 86: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 5.0147 - mse: 5.0147 - val_loss: 67.2969 - val_mse: 67.2969 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.0227 - mse: 5.0227\n",
      "Epoch 87: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 703ms/step - loss: 5.0227 - mse: 5.0227 - val_loss: 67.8994 - val_mse: 67.8994 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.7969 - mse: 4.7969\n",
      "Epoch 88: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 4.7969 - mse: 4.7969 - val_loss: 67.7506 - val_mse: 67.7506 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.6513 - mse: 4.6513\n",
      "Epoch 89: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 690ms/step - loss: 4.6513 - mse: 4.6513 - val_loss: 67.3830 - val_mse: 67.3830 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.8676 - mse: 4.8676\n",
      "Epoch 90: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 699ms/step - loss: 4.8676 - mse: 4.8676 - val_loss: 67.2488 - val_mse: 67.2488 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.2039 - mse: 5.2039\n",
      "Epoch 91: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 5.2039 - mse: 5.2039 - val_loss: 67.2074 - val_mse: 67.2074 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.6728 - mse: 4.6728\n",
      "Epoch 92: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 690ms/step - loss: 4.6728 - mse: 4.6728 - val_loss: 67.5872 - val_mse: 67.5872 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.3518 - mse: 5.3518\n",
      "Epoch 93: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 5.3518 - mse: 5.3518 - val_loss: 66.9360 - val_mse: 66.9360 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 5.0887 - mse: 5.0887\n",
      "Epoch 94: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 687ms/step - loss: 5.0887 - mse: 5.0887 - val_loss: 67.2116 - val_mse: 67.2116 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.6427 - mse: 4.6427\n",
      "Epoch 95: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 682ms/step - loss: 4.6427 - mse: 4.6427 - val_loss: 67.3023 - val_mse: 67.3023 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.6128 - mse: 4.6128\n",
      "Epoch 96: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 4.6128 - mse: 4.6128 - val_loss: 67.4219 - val_mse: 67.4219 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.6462 - mse: 4.6462\n",
      "Epoch 97: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 4.6462 - mse: 4.6462 - val_loss: 67.3619 - val_mse: 67.3619 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.4737 - mse: 4.4737\n",
      "Epoch 98: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 63s 658ms/step - loss: 4.4737 - mse: 4.4737 - val_loss: 67.4447 - val_mse: 67.4447 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.8087 - mse: 4.8087\n",
      "Epoch 99: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 4.8087 - mse: 4.8087 - val_loss: 67.0805 - val_mse: 67.0805 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 4.8136 - mse: 4.8136\n",
      "Epoch 100: val_loss did not improve from 64.65368\n",
      "95/95 [==============================] - 64s 669ms/step - loss: 4.8136 - mse: 4.8136 - val_loss: 66.8995 - val_mse: 66.8995 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 20:53:07.729613: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 4769.7524 - mse: 4769.7524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 20:54:10.342963: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 7520.13281, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 68s 694ms/step - loss: 4769.7524 - mse: 4769.7524 - val_loss: 7520.1328 - val_mse: 7520.1328 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 432.3817 - mse: 432.3817\n",
      "Epoch 2: val_loss improved from 7520.13281 to 5818.57080, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 432.3817 - mse: 432.3817 - val_loss: 5818.5708 - val_mse: 5818.5708 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 255.7099 - mse: 255.7099\n",
      "Epoch 3: val_loss improved from 5818.57080 to 4785.70361, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 255.7099 - mse: 255.7099 - val_loss: 4785.7036 - val_mse: 4785.7036 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 203.1617 - mse: 203.1617\n",
      "Epoch 4: val_loss improved from 4785.70361 to 2827.33789, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 203.1617 - mse: 203.1617 - val_loss: 2827.3379 - val_mse: 2827.3379 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 209.8360 - mse: 209.8360\n",
      "Epoch 5: val_loss improved from 2827.33789 to 1790.65723, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 209.8360 - mse: 209.8360 - val_loss: 1790.6572 - val_mse: 1790.6572 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 131.6561 - mse: 131.6561\n",
      "Epoch 6: val_loss improved from 1790.65723 to 1586.94373, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 131.6561 - mse: 131.6561 - val_loss: 1586.9437 - val_mse: 1586.9437 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 125.3548 - mse: 125.3548\n",
      "Epoch 7: val_loss improved from 1586.94373 to 754.27704, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 66s 691ms/step - loss: 125.3548 - mse: 125.3548 - val_loss: 754.2770 - val_mse: 754.2770 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 178.9840 - mse: 178.9840\n",
      "Epoch 8: val_loss improved from 754.27704 to 287.50372, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 178.9840 - mse: 178.9840 - val_loss: 287.5037 - val_mse: 287.5037 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 185.8701 - mse: 185.8701\n",
      "Epoch 9: val_loss improved from 287.50372 to 125.64954, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 66s 691ms/step - loss: 185.8701 - mse: 185.8701 - val_loss: 125.6495 - val_mse: 125.6495 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 98.7871 - mse: 98.7871\n",
      "Epoch 10: val_loss improved from 125.64954 to 108.71046, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 65s 687ms/step - loss: 98.7871 - mse: 98.7871 - val_loss: 108.7105 - val_mse: 108.7105 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 132.5564 - mse: 132.5564\n",
      "Epoch 11: val_loss improved from 108.71046 to 94.00452, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 132.5564 - mse: 132.5564 - val_loss: 94.0045 - val_mse: 94.0045 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 124.8186 - mse: 124.8186\n",
      "Epoch 12: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 124.8186 - mse: 124.8186 - val_loss: 180.8307 - val_mse: 180.8307 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 120.1198 - mse: 120.1198\n",
      "Epoch 13: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 120.1198 - mse: 120.1198 - val_loss: 258.8589 - val_mse: 258.8589 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 92.8859 - mse: 92.8859\n",
      "Epoch 14: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 66s 689ms/step - loss: 92.8859 - mse: 92.8859 - val_loss: 136.0142 - val_mse: 136.0142 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 102.5202 - mse: 102.5202\n",
      "Epoch 15: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 102.5202 - mse: 102.5202 - val_loss: 328.8933 - val_mse: 328.8933 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 77.4666 - mse: 77.4666\n",
      "Epoch 16: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 66s 691ms/step - loss: 77.4666 - mse: 77.4666 - val_loss: 101.0834 - val_mse: 101.0834 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 72.4538 - mse: 72.4538\n",
      "Epoch 17: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 72.4538 - mse: 72.4538 - val_loss: 106.0895 - val_mse: 106.0895 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 87.9653 - mse: 87.9653\n",
      "Epoch 18: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 87.9653 - mse: 87.9653 - val_loss: 200.7375 - val_mse: 200.7375 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 101.9952 - mse: 101.9952\n",
      "Epoch 19: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 101.9952 - mse: 101.9952 - val_loss: 102.3698 - val_mse: 102.3698 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 80.4660 - mse: 80.4660\n",
      "Epoch 20: val_loss did not improve from 94.00452\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 80.4660 - mse: 80.4660 - val_loss: 95.1572 - val_mse: 95.1572 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 111.7980 - mse: 111.7980\n",
      "Epoch 21: val_loss improved from 94.00452 to 88.34344, saving model to E-scale2/E2-scale_run2.h5\n",
      "95/95 [==============================] - 66s 689ms/step - loss: 111.7980 - mse: 111.7980 - val_loss: 88.3434 - val_mse: 88.3434 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 48.6887 - mse: 48.6887\n",
      "Epoch 22: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 48.6887 - mse: 48.6887 - val_loss: 104.7044 - val_mse: 104.7044 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 60.3278 - mse: 60.3278\n",
      "Epoch 23: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 60.3278 - mse: 60.3278 - val_loss: 99.7449 - val_mse: 99.7449 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 49.6043 - mse: 49.6043\n",
      "Epoch 24: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 49.6043 - mse: 49.6043 - val_loss: 107.5281 - val_mse: 107.5281 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 47.1391 - mse: 47.1391\n",
      "Epoch 25: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 688ms/step - loss: 47.1391 - mse: 47.1391 - val_loss: 103.1943 - val_mse: 103.1943 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 48.2069 - mse: 48.2069\n",
      "Epoch 26: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 48.2069 - mse: 48.2069 - val_loss: 97.3201 - val_mse: 97.3201 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 38.0828 - mse: 38.0828\n",
      "Epoch 27: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 38.0828 - mse: 38.0828 - val_loss: 94.8590 - val_mse: 94.8590 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 88.4840 - mse: 88.4840\n",
      "Epoch 28: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 88.4840 - mse: 88.4840 - val_loss: 192.3710 - val_mse: 192.3710 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 44.9456 - mse: 44.9456\n",
      "Epoch 29: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 689ms/step - loss: 44.9456 - mse: 44.9456 - val_loss: 114.2160 - val_mse: 114.2160 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 73.6998 - mse: 73.6998\n",
      "Epoch 30: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 689ms/step - loss: 73.6998 - mse: 73.6998 - val_loss: 144.8642 - val_mse: 144.8642 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 37.7838 - mse: 37.7838\n",
      "Epoch 31: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 677ms/step - loss: 37.7838 - mse: 37.7838 - val_loss: 95.9356 - val_mse: 95.9356 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.1433 - mse: 25.1433\n",
      "Epoch 32: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 25.1433 - mse: 25.1433 - val_loss: 105.2508 - val_mse: 105.2508 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.6782 - mse: 23.6782\n",
      "Epoch 33: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 23.6782 - mse: 23.6782 - val_loss: 88.5803 - val_mse: 88.5803 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.2284 - mse: 20.2284\n",
      "Epoch 34: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 20.2284 - mse: 20.2284 - val_loss: 89.4785 - val_mse: 89.4785 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.9540 - mse: 22.9540\n",
      "Epoch 35: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 22.9540 - mse: 22.9540 - val_loss: 88.9250 - val_mse: 88.9250 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.2052 - mse: 20.2052\n",
      "Epoch 36: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 20.2052 - mse: 20.2052 - val_loss: 89.4852 - val_mse: 89.4852 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.6558 - mse: 18.6558\n",
      "Epoch 37: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 18.6558 - mse: 18.6558 - val_loss: 92.2343 - val_mse: 92.2343 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.9211 - mse: 27.9211\n",
      "Epoch 38: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 690ms/step - loss: 27.9211 - mse: 27.9211 - val_loss: 89.9461 - val_mse: 89.9461 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.9186 - mse: 18.9186\n",
      "Epoch 39: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 682ms/step - loss: 18.9186 - mse: 18.9186 - val_loss: 92.4522 - val_mse: 92.4522 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.7772 - mse: 27.7772\n",
      "Epoch 40: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 660ms/step - loss: 27.7772 - mse: 27.7772 - val_loss: 91.7618 - val_mse: 91.7618 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.7433 - mse: 22.7433\n",
      "Epoch 41: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 670ms/step - loss: 22.7433 - mse: 22.7433 - val_loss: 98.5719 - val_mse: 98.5719 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.4056 - mse: 17.4056\n",
      "Epoch 42: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 668ms/step - loss: 17.4056 - mse: 17.4056 - val_loss: 89.7409 - val_mse: 89.7409 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.6154 - mse: 17.6154\n",
      "Epoch 43: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 677ms/step - loss: 17.6154 - mse: 17.6154 - val_loss: 89.5698 - val_mse: 89.5698 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.3654 - mse: 15.3654\n",
      "Epoch 44: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 672ms/step - loss: 15.3654 - mse: 15.3654 - val_loss: 89.6532 - val_mse: 89.6532 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.6880 - mse: 16.6880\n",
      "Epoch 45: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 16.6880 - mse: 16.6880 - val_loss: 89.5142 - val_mse: 89.5142 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.7470 - mse: 15.7470\n",
      "Epoch 46: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 670ms/step - loss: 15.7470 - mse: 15.7470 - val_loss: 89.4954 - val_mse: 89.4954 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.1571 - mse: 18.1571\n",
      "Epoch 47: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 668ms/step - loss: 18.1571 - mse: 18.1571 - val_loss: 89.2917 - val_mse: 89.2917 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.6437 - mse: 17.6437\n",
      "Epoch 48: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 669ms/step - loss: 17.6437 - mse: 17.6437 - val_loss: 89.4062 - val_mse: 89.4062 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.5355 - mse: 15.5355\n",
      "Epoch 49: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 57s 593ms/step - loss: 15.5355 - mse: 15.5355 - val_loss: 89.5375 - val_mse: 89.5375 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.0398 - mse: 18.0398\n",
      "Epoch 50: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 678ms/step - loss: 18.0398 - mse: 18.0398 - val_loss: 89.7676 - val_mse: 89.7676 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.8253 - mse: 20.8253\n",
      "Epoch 51: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 677ms/step - loss: 20.8253 - mse: 20.8253 - val_loss: 90.9063 - val_mse: 90.9063 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.2043 - mse: 16.2043\n",
      "Epoch 52: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 683ms/step - loss: 16.2043 - mse: 16.2043 - val_loss: 89.5950 - val_mse: 89.5950 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.7783 - mse: 15.7783\n",
      "Epoch 53: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 683ms/step - loss: 15.7783 - mse: 15.7783 - val_loss: 89.4982 - val_mse: 89.4982 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.4156 - mse: 17.4156\n",
      "Epoch 54: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 665ms/step - loss: 17.4156 - mse: 17.4156 - val_loss: 89.4694 - val_mse: 89.4694 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.6475 - mse: 15.6475\n",
      "Epoch 55: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 674ms/step - loss: 15.6475 - mse: 15.6475 - val_loss: 89.6847 - val_mse: 89.6847 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.7946 - mse: 17.7946\n",
      "Epoch 56: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 678ms/step - loss: 17.7946 - mse: 17.7946 - val_loss: 89.4782 - val_mse: 89.4782 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.4183 - mse: 18.4183\n",
      "Epoch 57: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 664ms/step - loss: 18.4183 - mse: 18.4183 - val_loss: 89.6381 - val_mse: 89.6381 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.6007 - mse: 18.6007\n",
      "Epoch 58: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 676ms/step - loss: 18.6007 - mse: 18.6007 - val_loss: 89.8901 - val_mse: 89.8901 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.7352 - mse: 15.7352\n",
      "Epoch 59: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 66s 688ms/step - loss: 15.7352 - mse: 15.7352 - val_loss: 89.5014 - val_mse: 89.5014 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.9014 - mse: 14.9014\n",
      "Epoch 60: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 683ms/step - loss: 14.9014 - mse: 14.9014 - val_loss: 89.4621 - val_mse: 89.4621 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.0973 - mse: 16.0973\n",
      "Epoch 61: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 682ms/step - loss: 16.0973 - mse: 16.0973 - val_loss: 89.8287 - val_mse: 89.8287 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.8866 - mse: 16.8866\n",
      "Epoch 62: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 678ms/step - loss: 16.8866 - mse: 16.8866 - val_loss: 89.3335 - val_mse: 89.3335 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.3693 - mse: 16.3693\n",
      "Epoch 63: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 664ms/step - loss: 16.3693 - mse: 16.3693 - val_loss: 90.2871 - val_mse: 90.2871 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.3106 - mse: 16.3106\n",
      "Epoch 64: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 672ms/step - loss: 16.3106 - mse: 16.3106 - val_loss: 89.3379 - val_mse: 89.3379 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.7685 - mse: 18.7685\n",
      "Epoch 65: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 671ms/step - loss: 18.7685 - mse: 18.7685 - val_loss: 89.7312 - val_mse: 89.7312 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.3216 - mse: 19.3216\n",
      "Epoch 66: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 680ms/step - loss: 19.3216 - mse: 19.3216 - val_loss: 89.8661 - val_mse: 89.8661 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.3687 - mse: 15.3687\n",
      "Epoch 67: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 671ms/step - loss: 15.3687 - mse: 15.3687 - val_loss: 89.7293 - val_mse: 89.7293 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.3908 - mse: 18.3908\n",
      "Epoch 68: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 676ms/step - loss: 18.3908 - mse: 18.3908 - val_loss: 90.4469 - val_mse: 90.4469 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.4329 - mse: 21.4329\n",
      "Epoch 69: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 683ms/step - loss: 21.4329 - mse: 21.4329 - val_loss: 89.7615 - val_mse: 89.7615 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.3824 - mse: 18.3824\n",
      "Epoch 70: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 668ms/step - loss: 18.3824 - mse: 18.3824 - val_loss: 89.5949 - val_mse: 89.5949 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.8117 - mse: 20.8117\n",
      "Epoch 71: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 678ms/step - loss: 20.8117 - mse: 20.8117 - val_loss: 89.3738 - val_mse: 89.3738 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.3459 - mse: 14.3459\n",
      "Epoch 72: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 668ms/step - loss: 14.3459 - mse: 14.3459 - val_loss: 89.3193 - val_mse: 89.3193 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.2681 - mse: 16.2681\n",
      "Epoch 73: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 688ms/step - loss: 16.2681 - mse: 16.2681 - val_loss: 89.9449 - val_mse: 89.9449 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.1647 - mse: 19.1647\n",
      "Epoch 74: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 678ms/step - loss: 19.1647 - mse: 19.1647 - val_loss: 89.8406 - val_mse: 89.8406 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.2879 - mse: 18.2879\n",
      "Epoch 75: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 678ms/step - loss: 18.2879 - mse: 18.2879 - val_loss: 89.6196 - val_mse: 89.6196 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.0136 - mse: 15.0136\n",
      "Epoch 76: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 668ms/step - loss: 15.0136 - mse: 15.0136 - val_loss: 89.6203 - val_mse: 89.6203 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.2405 - mse: 17.2405\n",
      "Epoch 77: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 684ms/step - loss: 17.2405 - mse: 17.2405 - val_loss: 89.6047 - val_mse: 89.6047 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.0455 - mse: 16.0455\n",
      "Epoch 78: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 16.0455 - mse: 16.0455 - val_loss: 89.5315 - val_mse: 89.5315 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.1840 - mse: 14.1840\n",
      "Epoch 79: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 676ms/step - loss: 14.1840 - mse: 14.1840 - val_loss: 89.7479 - val_mse: 89.7479 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.2549 - mse: 16.2549\n",
      "Epoch 80: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 16.2549 - mse: 16.2549 - val_loss: 89.5238 - val_mse: 89.5238 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2279 - mse: 15.2279\n",
      "Epoch 81: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 677ms/step - loss: 15.2279 - mse: 15.2279 - val_loss: 89.6157 - val_mse: 89.6157 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.0474 - mse: 15.0474\n",
      "Epoch 82: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 673ms/step - loss: 15.0474 - mse: 15.0474 - val_loss: 89.7199 - val_mse: 89.7199 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.0945 - mse: 16.0945\n",
      "Epoch 83: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 16.0945 - mse: 16.0945 - val_loss: 89.8211 - val_mse: 89.8211 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.5857 - mse: 17.5857\n",
      "Epoch 84: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 17.5857 - mse: 17.5857 - val_loss: 89.6580 - val_mse: 89.6580 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.2134 - mse: 14.2134\n",
      "Epoch 85: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 680ms/step - loss: 14.2134 - mse: 14.2134 - val_loss: 89.7501 - val_mse: 89.7501 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.4519 - mse: 19.4519\n",
      "Epoch 86: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 676ms/step - loss: 19.4519 - mse: 19.4519 - val_loss: 89.6312 - val_mse: 89.6312 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.4931 - mse: 15.4931\n",
      "Epoch 87: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 678ms/step - loss: 15.4931 - mse: 15.4931 - val_loss: 89.7807 - val_mse: 89.7807 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.5921 - mse: 13.5921\n",
      "Epoch 88: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 678ms/step - loss: 13.5921 - mse: 13.5921 - val_loss: 89.7814 - val_mse: 89.7814 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.3644 - mse: 15.3644\n",
      "Epoch 89: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 666ms/step - loss: 15.3644 - mse: 15.3644 - val_loss: 91.5979 - val_mse: 91.5979 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.7260 - mse: 13.7260\n",
      "Epoch 90: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 664ms/step - loss: 13.7260 - mse: 13.7260 - val_loss: 89.4632 - val_mse: 89.4632 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.7649 - mse: 17.7649\n",
      "Epoch 91: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 672ms/step - loss: 17.7649 - mse: 17.7649 - val_loss: 89.4270 - val_mse: 89.4270 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.7869 - mse: 13.7869\n",
      "Epoch 92: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 665ms/step - loss: 13.7869 - mse: 13.7869 - val_loss: 89.4146 - val_mse: 89.4146 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.5179 - mse: 15.5179\n",
      "Epoch 93: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 15.5179 - mse: 15.5179 - val_loss: 90.1636 - val_mse: 90.1636 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.7600 - mse: 13.7600\n",
      "Epoch 94: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 64s 671ms/step - loss: 13.7600 - mse: 13.7600 - val_loss: 89.7204 - val_mse: 89.7204 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.3376 - mse: 13.3376\n",
      "Epoch 95: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 660ms/step - loss: 13.3376 - mse: 13.3376 - val_loss: 90.4276 - val_mse: 90.4276 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.6613 - mse: 17.6613\n",
      "Epoch 96: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 688ms/step - loss: 17.6613 - mse: 17.6613 - val_loss: 90.9649 - val_mse: 90.9649 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.1456 - mse: 13.1456\n",
      "Epoch 97: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 63s 663ms/step - loss: 13.1456 - mse: 13.1456 - val_loss: 89.7571 - val_mse: 89.7571 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9925 - mse: 12.9925\n",
      "Epoch 98: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 62s 657ms/step - loss: 12.9925 - mse: 12.9925 - val_loss: 89.8889 - val_mse: 89.8889 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.7350 - mse: 18.7350\n",
      "Epoch 99: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 62s 656ms/step - loss: 18.7350 - mse: 18.7350 - val_loss: 89.8100 - val_mse: 89.8100 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.5223 - mse: 17.5223\n",
      "Epoch 100: val_loss did not improve from 88.34344\n",
      "95/95 [==============================] - 65s 689ms/step - loss: 17.5223 - mse: 17.5223 - val_loss: 89.7145 - val_mse: 89.7145 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 22:41:07.422110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 4876.7715 - mse: 4876.7715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 22:42:13.667081: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 8828.10840, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 73s 736ms/step - loss: 4876.7715 - mse: 4876.7715 - val_loss: 8828.1084 - val_mse: 8828.1084 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 461.5656 - mse: 461.5656\n",
      "Epoch 2: val_loss improved from 8828.10840 to 7747.95557, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 64s 674ms/step - loss: 461.5656 - mse: 461.5656 - val_loss: 7747.9556 - val_mse: 7747.9556 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 273.3821 - mse: 273.3821\n",
      "Epoch 3: val_loss improved from 7747.95557 to 6498.12158, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 273.3821 - mse: 273.3821 - val_loss: 6498.1216 - val_mse: 6498.1216 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 213.7821 - mse: 213.7821\n",
      "Epoch 4: val_loss improved from 6498.12158 to 4917.21436, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 61s 636ms/step - loss: 213.7821 - mse: 213.7821 - val_loss: 4917.2144 - val_mse: 4917.2144 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 168.5022 - mse: 168.5022\n",
      "Epoch 5: val_loss improved from 4917.21436 to 3687.32397, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 168.5022 - mse: 168.5022 - val_loss: 3687.3240 - val_mse: 3687.3240 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 161.4468 - mse: 161.4468\n",
      "Epoch 6: val_loss improved from 3687.32397 to 1304.79028, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 61s 644ms/step - loss: 161.4468 - mse: 161.4468 - val_loss: 1304.7903 - val_mse: 1304.7903 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 140.0940 - mse: 140.0940\n",
      "Epoch 7: val_loss improved from 1304.79028 to 613.41504, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 63s 664ms/step - loss: 140.0940 - mse: 140.0940 - val_loss: 613.4150 - val_mse: 613.4150 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 111.0302 - mse: 111.0302\n",
      "Epoch 8: val_loss improved from 613.41504 to 151.37836, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 65s 682ms/step - loss: 111.0302 - mse: 111.0302 - val_loss: 151.3784 - val_mse: 151.3784 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 117.5856 - mse: 117.5856\n",
      "Epoch 9: val_loss improved from 151.37836 to 137.34581, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 117.5856 - mse: 117.5856 - val_loss: 137.3458 - val_mse: 137.3458 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 112.9394 - mse: 112.9394\n",
      "Epoch 10: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 112.9394 - mse: 112.9394 - val_loss: 292.4914 - val_mse: 292.4914 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 114.0902 - mse: 114.0902\n",
      "Epoch 11: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 63s 659ms/step - loss: 114.0902 - mse: 114.0902 - val_loss: 192.2595 - val_mse: 192.2595 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 125.0367 - mse: 125.0367\n",
      "Epoch 12: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 62s 650ms/step - loss: 125.0367 - mse: 125.0367 - val_loss: 141.7653 - val_mse: 141.7653 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 85.4754 - mse: 85.4754\n",
      "Epoch 13: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 61s 642ms/step - loss: 85.4754 - mse: 85.4754 - val_loss: 190.6145 - val_mse: 190.6145 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 118.6932 - mse: 118.6932\n",
      "Epoch 14: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 65s 684ms/step - loss: 118.6932 - mse: 118.6932 - val_loss: 223.6724 - val_mse: 223.6724 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 84.0527 - mse: 84.0527\n",
      "Epoch 15: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 64s 667ms/step - loss: 84.0527 - mse: 84.0527 - val_loss: 157.6194 - val_mse: 157.6194 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 118.6936 - mse: 118.6936\n",
      "Epoch 16: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 64s 670ms/step - loss: 118.6936 - mse: 118.6936 - val_loss: 174.7877 - val_mse: 174.7877 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 78.3682 - mse: 78.3682\n",
      "Epoch 17: val_loss did not improve from 137.34581\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 78.3682 - mse: 78.3682 - val_loss: 146.8372 - val_mse: 146.8372 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 75.9635 - mse: 75.9635\n",
      "Epoch 18: val_loss improved from 137.34581 to 136.23473, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 65s 688ms/step - loss: 75.9635 - mse: 75.9635 - val_loss: 136.2347 - val_mse: 136.2347 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 85.9409 - mse: 85.9409\n",
      "Epoch 19: val_loss did not improve from 136.23473\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 85.9409 - mse: 85.9409 - val_loss: 137.3665 - val_mse: 137.3665 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 118.8524 - mse: 118.8524\n",
      "Epoch 20: val_loss improved from 136.23473 to 126.61148, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 64s 671ms/step - loss: 118.8524 - mse: 118.8524 - val_loss: 126.6115 - val_mse: 126.6115 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 56.5079 - mse: 56.5079\n",
      "Epoch 21: val_loss did not improve from 126.61148\n",
      "95/95 [==============================] - 64s 671ms/step - loss: 56.5079 - mse: 56.5079 - val_loss: 168.6708 - val_mse: 168.6708 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 88.7311 - mse: 88.7311\n",
      "Epoch 22: val_loss improved from 126.61148 to 126.36334, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 88.7311 - mse: 88.7311 - val_loss: 126.3633 - val_mse: 126.3633 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 73.6983 - mse: 73.6983\n",
      "Epoch 23: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 55s 582ms/step - loss: 73.6983 - mse: 73.6983 - val_loss: 192.0286 - val_mse: 192.0286 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 54.7321 - mse: 54.7321\n",
      "Epoch 24: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 54.7321 - mse: 54.7321 - val_loss: 128.8022 - val_mse: 128.8022 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 54.1214 - mse: 54.1214\n",
      "Epoch 25: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 54.1214 - mse: 54.1214 - val_loss: 138.7504 - val_mse: 138.7504 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 57.1835 - mse: 57.1835\n",
      "Epoch 26: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 66s 690ms/step - loss: 57.1835 - mse: 57.1835 - val_loss: 152.8583 - val_mse: 152.8583 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 51.6856 - mse: 51.6856\n",
      "Epoch 27: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 677ms/step - loss: 51.6856 - mse: 51.6856 - val_loss: 169.2474 - val_mse: 169.2474 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 52.0989 - mse: 52.0989\n",
      "Epoch 28: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 63s 668ms/step - loss: 52.0989 - mse: 52.0989 - val_loss: 255.4930 - val_mse: 255.4930 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 56.6410 - mse: 56.6410\n",
      "Epoch 29: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 677ms/step - loss: 56.6410 - mse: 56.6410 - val_loss: 135.2250 - val_mse: 135.2250 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 38.7844 - mse: 38.7844\n",
      "Epoch 30: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 676ms/step - loss: 38.7844 - mse: 38.7844 - val_loss: 150.6572 - val_mse: 150.6572 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 69.4982 - mse: 69.4982\n",
      "Epoch 31: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 69.4982 - mse: 69.4982 - val_loss: 133.8233 - val_mse: 133.8233 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 59.3321 - mse: 59.3321\n",
      "Epoch 32: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 65s 680ms/step - loss: 59.3321 - mse: 59.3321 - val_loss: 135.9427 - val_mse: 135.9427 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.6414 - mse: 25.6414\n",
      "Epoch 33: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 673ms/step - loss: 25.6414 - mse: 25.6414 - val_loss: 126.9771 - val_mse: 126.9771 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.6837 - mse: 27.6837\n",
      "Epoch 34: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 675ms/step - loss: 27.6837 - mse: 27.6837 - val_loss: 132.9808 - val_mse: 132.9808 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.6938 - mse: 20.6938\n",
      "Epoch 35: val_loss did not improve from 126.36334\n",
      "95/95 [==============================] - 64s 673ms/step - loss: 20.6938 - mse: 20.6938 - val_loss: 126.8156 - val_mse: 126.8156 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.1857 - mse: 24.1857\n",
      "Epoch 36: val_loss improved from 126.36334 to 125.85677, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 64s 673ms/step - loss: 24.1857 - mse: 24.1857 - val_loss: 125.8568 - val_mse: 125.8568 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.8529 - mse: 21.8529\n",
      "Epoch 37: val_loss improved from 125.85677 to 124.06381, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 64s 672ms/step - loss: 21.8529 - mse: 21.8529 - val_loss: 124.0638 - val_mse: 124.0638 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.6323 - mse: 21.6323\n",
      "Epoch 38: val_loss did not improve from 124.06381\n",
      "95/95 [==============================] - 65s 687ms/step - loss: 21.6323 - mse: 21.6323 - val_loss: 124.5695 - val_mse: 124.5695 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.8299 - mse: 19.8299\n",
      "Epoch 39: val_loss did not improve from 124.06381\n",
      "95/95 [==============================] - 64s 672ms/step - loss: 19.8299 - mse: 19.8299 - val_loss: 124.1130 - val_mse: 124.1130 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.0332 - mse: 19.0332\n",
      "Epoch 40: val_loss improved from 124.06381 to 123.08598, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 65s 681ms/step - loss: 19.0332 - mse: 19.0332 - val_loss: 123.0860 - val_mse: 123.0860 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.3809 - mse: 18.3809\n",
      "Epoch 41: val_loss did not improve from 123.08598\n",
      "95/95 [==============================] - 64s 676ms/step - loss: 18.3809 - mse: 18.3809 - val_loss: 124.0485 - val_mse: 124.0485 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.4396 - mse: 21.4396\n",
      "Epoch 42: val_loss improved from 123.08598 to 123.05128, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 64s 673ms/step - loss: 21.4396 - mse: 21.4396 - val_loss: 123.0513 - val_mse: 123.0513 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.3162 - mse: 26.3162\n",
      "Epoch 43: val_loss improved from 123.05128 to 122.37967, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 64s 672ms/step - loss: 26.3162 - mse: 26.3162 - val_loss: 122.3797 - val_mse: 122.3797 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.4895 - mse: 18.4895\n",
      "Epoch 44: val_loss did not improve from 122.37967\n",
      "95/95 [==============================] - 64s 677ms/step - loss: 18.4895 - mse: 18.4895 - val_loss: 124.0687 - val_mse: 124.0687 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.2888 - mse: 27.2888\n",
      "Epoch 45: val_loss did not improve from 122.37967\n",
      "95/95 [==============================] - 65s 682ms/step - loss: 27.2888 - mse: 27.2888 - val_loss: 123.1553 - val_mse: 123.1553 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.6866 - mse: 20.6866\n",
      "Epoch 46: val_loss did not improve from 122.37967\n",
      "95/95 [==============================] - 65s 680ms/step - loss: 20.6866 - mse: 20.6866 - val_loss: 126.8711 - val_mse: 126.8711 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.3308 - mse: 17.3308\n",
      "Epoch 47: val_loss improved from 122.37967 to 121.39330, saving model to E-scale2/E2-scale_run3.h5\n",
      "95/95 [==============================] - 63s 665ms/step - loss: 17.3308 - mse: 17.3308 - val_loss: 121.3933 - val_mse: 121.3933 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.1905 - mse: 19.1905\n",
      "Epoch 48: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 19.1905 - mse: 19.1905 - val_loss: 124.1046 - val_mse: 124.1046 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.3974 - mse: 17.3974\n",
      "Epoch 49: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 17.3974 - mse: 17.3974 - val_loss: 124.8976 - val_mse: 124.8976 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.6629 - mse: 15.6629\n",
      "Epoch 50: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 15.6629 - mse: 15.6629 - val_loss: 123.9197 - val_mse: 123.9197 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.7719 - mse: 19.7719\n",
      "Epoch 51: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 19.7719 - mse: 19.7719 - val_loss: 125.2174 - val_mse: 125.2174 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.8830 - mse: 17.8830\n",
      "Epoch 52: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 607ms/step - loss: 17.8830 - mse: 17.8830 - val_loss: 123.9943 - val_mse: 123.9943 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2654 - mse: 15.2654\n",
      "Epoch 53: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 15.2654 - mse: 15.2654 - val_loss: 129.1982 - val_mse: 129.1982 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.3962 - mse: 18.3962\n",
      "Epoch 54: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 18.3962 - mse: 18.3962 - val_loss: 125.5918 - val_mse: 125.5918 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.8915 - mse: 16.8915\n",
      "Epoch 55: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 16.8915 - mse: 16.8915 - val_loss: 126.6236 - val_mse: 126.6236 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.6907 - mse: 16.6907\n",
      "Epoch 56: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 603ms/step - loss: 16.6907 - mse: 16.6907 - val_loss: 152.2349 - val_mse: 152.2349 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.4199 - mse: 21.4199\n",
      "Epoch 57: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 605ms/step - loss: 21.4199 - mse: 21.4199 - val_loss: 129.2202 - val_mse: 129.2202 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.0946 - mse: 15.0946\n",
      "Epoch 58: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 605ms/step - loss: 15.0946 - mse: 15.0946 - val_loss: 124.9547 - val_mse: 124.9547 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.5717 - mse: 13.5717\n",
      "Epoch 59: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 13.5717 - mse: 13.5717 - val_loss: 124.8894 - val_mse: 124.8894 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.4303 - mse: 17.4303\n",
      "Epoch 60: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 59s 616ms/step - loss: 17.4303 - mse: 17.4303 - val_loss: 126.7420 - val_mse: 126.7420 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.1996 - mse: 13.1996\n",
      "Epoch 61: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 605ms/step - loss: 13.1996 - mse: 13.1996 - val_loss: 125.2125 - val_mse: 125.2125 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.1462 - mse: 16.1462\n",
      "Epoch 62: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 605ms/step - loss: 16.1462 - mse: 16.1462 - val_loss: 124.6922 - val_mse: 124.6922 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.1867 - mse: 14.1867\n",
      "Epoch 63: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 607ms/step - loss: 14.1867 - mse: 14.1867 - val_loss: 125.0040 - val_mse: 125.0040 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.9962 - mse: 14.9962\n",
      "Epoch 64: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 604ms/step - loss: 14.9962 - mse: 14.9962 - val_loss: 124.5081 - val_mse: 124.5081 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.0310 - mse: 15.0310\n",
      "Epoch 65: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 607ms/step - loss: 15.0310 - mse: 15.0310 - val_loss: 125.1186 - val_mse: 125.1186 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.7046 - mse: 13.7046\n",
      "Epoch 66: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 13.7046 - mse: 13.7046 - val_loss: 125.2015 - val_mse: 125.2015 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.2580 - mse: 13.2580\n",
      "Epoch 67: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 608ms/step - loss: 13.2580 - mse: 13.2580 - val_loss: 125.2287 - val_mse: 125.2287 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.0524 - mse: 14.0524\n",
      "Epoch 68: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 14.0524 - mse: 14.0524 - val_loss: 126.8431 - val_mse: 126.8431 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.4249 - mse: 13.4249\n",
      "Epoch 69: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 13.4249 - mse: 13.4249 - val_loss: 124.6975 - val_mse: 124.6975 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.1226 - mse: 13.1226\n",
      "Epoch 70: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 59s 616ms/step - loss: 13.1226 - mse: 13.1226 - val_loss: 124.2185 - val_mse: 124.2185 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.5868 - mse: 15.5868\n",
      "Epoch 71: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 605ms/step - loss: 15.5868 - mse: 15.5868 - val_loss: 125.1885 - val_mse: 125.1885 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.2933 - mse: 13.2933\n",
      "Epoch 72: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 607ms/step - loss: 13.2933 - mse: 13.2933 - val_loss: 123.7284 - val_mse: 123.7284 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.2591 - mse: 13.2591\n",
      "Epoch 73: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 604ms/step - loss: 13.2591 - mse: 13.2591 - val_loss: 124.0001 - val_mse: 124.0001 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.6694 - mse: 12.6694\n",
      "Epoch 74: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 12.6694 - mse: 12.6694 - val_loss: 124.5594 - val_mse: 124.5594 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.1382 - mse: 12.1382\n",
      "Epoch 75: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 604ms/step - loss: 12.1382 - mse: 12.1382 - val_loss: 125.0647 - val_mse: 125.0647 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.6689 - mse: 13.6689\n",
      "Epoch 76: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 13.6689 - mse: 13.6689 - val_loss: 125.1518 - val_mse: 125.1518 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.0055 - mse: 13.0055\n",
      "Epoch 77: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 13.0055 - mse: 13.0055 - val_loss: 124.5063 - val_mse: 124.5063 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.8569 - mse: 13.8569\n",
      "Epoch 78: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 13.8569 - mse: 13.8569 - val_loss: 124.2497 - val_mse: 124.2497 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.2516 - mse: 17.2516\n",
      "Epoch 79: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 17.2516 - mse: 17.2516 - val_loss: 125.0668 - val_mse: 125.0668 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.6539 - mse: 14.6539\n",
      "Epoch 80: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 14.6539 - mse: 14.6539 - val_loss: 124.8349 - val_mse: 124.8349 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.2829 - mse: 13.2829\n",
      "Epoch 81: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 606ms/step - loss: 13.2829 - mse: 13.2829 - val_loss: 125.1039 - val_mse: 125.1039 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.0119 - mse: 13.0119\n",
      "Epoch 82: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 603ms/step - loss: 13.0119 - mse: 13.0119 - val_loss: 124.5559 - val_mse: 124.5559 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.0401 - mse: 12.0401\n",
      "Epoch 83: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 12.0401 - mse: 12.0401 - val_loss: 124.5498 - val_mse: 124.5498 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.0199 - mse: 14.0199\n",
      "Epoch 84: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 613ms/step - loss: 14.0199 - mse: 14.0199 - val_loss: 124.6869 - val_mse: 124.6869 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.3582 - mse: 12.3582\n",
      "Epoch 85: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 610ms/step - loss: 12.3582 - mse: 12.3582 - val_loss: 123.8139 - val_mse: 123.8139 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.9409 - mse: 18.9409\n",
      "Epoch 86: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 605ms/step - loss: 18.9409 - mse: 18.9409 - val_loss: 127.1678 - val_mse: 127.1678 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.5756 - mse: 12.5756\n",
      "Epoch 87: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 610ms/step - loss: 12.5756 - mse: 12.5756 - val_loss: 124.5121 - val_mse: 124.5121 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.2413 - mse: 14.2413\n",
      "Epoch 88: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 607ms/step - loss: 14.2413 - mse: 14.2413 - val_loss: 126.1930 - val_mse: 126.1930 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.8664 - mse: 12.8664\n",
      "Epoch 89: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 605ms/step - loss: 12.8664 - mse: 12.8664 - val_loss: 126.2199 - val_mse: 126.2199 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.6722 - mse: 12.6722\n",
      "Epoch 90: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 606ms/step - loss: 12.6722 - mse: 12.6722 - val_loss: 124.8041 - val_mse: 124.8041 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.8877 - mse: 12.8877\n",
      "Epoch 91: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 12.8877 - mse: 12.8877 - val_loss: 125.0917 - val_mse: 125.0917 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.6119 - mse: 15.6119\n",
      "Epoch 92: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 15.6119 - mse: 15.6119 - val_loss: 124.4076 - val_mse: 124.4076 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.4865 - mse: 14.4865\n",
      "Epoch 93: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 14.4865 - mse: 14.4865 - val_loss: 125.8905 - val_mse: 125.8905 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.3894 - mse: 14.3894\n",
      "Epoch 94: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 606ms/step - loss: 14.3894 - mse: 14.3894 - val_loss: 124.0399 - val_mse: 124.0399 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.1190 - mse: 12.1190\n",
      "Epoch 95: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 57s 603ms/step - loss: 12.1190 - mse: 12.1190 - val_loss: 126.6750 - val_mse: 126.6750 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9780 - mse: 12.9780\n",
      "Epoch 96: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 607ms/step - loss: 12.9780 - mse: 12.9780 - val_loss: 125.1399 - val_mse: 125.1399 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.2436 - mse: 12.2436\n",
      "Epoch 97: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 12.2436 - mse: 12.2436 - val_loss: 126.8415 - val_mse: 126.8415 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.6298 - mse: 11.6298\n",
      "Epoch 98: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 55s 576ms/step - loss: 11.6298 - mse: 11.6298 - val_loss: 124.3135 - val_mse: 124.3135 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.7903 - mse: 11.7903\n",
      "Epoch 99: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 11.7903 - mse: 11.7903 - val_loss: 125.4921 - val_mse: 125.4921 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.8571 - mse: 10.8571\n",
      "Epoch 100: val_loss did not improve from 121.39330\n",
      "95/95 [==============================] - 59s 621ms/step - loss: 10.8571 - mse: 10.8571 - val_loss: 124.9334 - val_mse: 124.9334 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 00:22:27.699662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 4231.1763 - mse: 4231.1763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 00:23:27.102050: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 8636.24219, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 65s 653ms/step - loss: 4231.1763 - mse: 4231.1763 - val_loss: 8636.2422 - val_mse: 8636.2422 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 487.4258 - mse: 487.4258\n",
      "Epoch 2: val_loss improved from 8636.24219 to 7213.93457, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 61s 643ms/step - loss: 487.4258 - mse: 487.4258 - val_loss: 7213.9346 - val_mse: 7213.9346 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 267.2319 - mse: 267.2319\n",
      "Epoch 3: val_loss improved from 7213.93457 to 5928.41504, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 61s 646ms/step - loss: 267.2319 - mse: 267.2319 - val_loss: 5928.4150 - val_mse: 5928.4150 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 153.0669 - mse: 153.0669\n",
      "Epoch 4: val_loss improved from 5928.41504 to 4578.68994, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 62s 647ms/step - loss: 153.0669 - mse: 153.0669 - val_loss: 4578.6899 - val_mse: 4578.6899 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 251.6370 - mse: 251.6370\n",
      "Epoch 5: val_loss improved from 4578.68994 to 3067.65454, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 61s 642ms/step - loss: 251.6370 - mse: 251.6370 - val_loss: 3067.6545 - val_mse: 3067.6545 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 170.4465 - mse: 170.4465\n",
      "Epoch 6: val_loss improved from 3067.65454 to 751.53607, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 62s 647ms/step - loss: 170.4465 - mse: 170.4465 - val_loss: 751.5361 - val_mse: 751.5361 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 129.5330 - mse: 129.5330\n",
      "Epoch 7: val_loss improved from 751.53607 to 676.71106, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 61s 643ms/step - loss: 129.5330 - mse: 129.5330 - val_loss: 676.7111 - val_mse: 676.7111 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 147.6089 - mse: 147.6089\n",
      "Epoch 8: val_loss improved from 676.71106 to 131.95146, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 61s 643ms/step - loss: 147.6089 - mse: 147.6089 - val_loss: 131.9515 - val_mse: 131.9515 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 130.4112 - mse: 130.4112\n",
      "Epoch 9: val_loss did not improve from 131.95146\n",
      "95/95 [==============================] - 61s 642ms/step - loss: 130.4112 - mse: 130.4112 - val_loss: 138.6796 - val_mse: 138.6796 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 101.7785 - mse: 101.7785\n",
      "Epoch 10: val_loss did not improve from 131.95146\n",
      "95/95 [==============================] - 61s 635ms/step - loss: 101.7785 - mse: 101.7785 - val_loss: 164.8991 - val_mse: 164.8991 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 109.8537 - mse: 109.8537\n",
      "Epoch 11: val_loss did not improve from 131.95146\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 109.8537 - mse: 109.8537 - val_loss: 142.0125 - val_mse: 142.0125 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 162.6405 - mse: 162.6405\n",
      "Epoch 12: val_loss improved from 131.95146 to 119.84333, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 61s 644ms/step - loss: 162.6405 - mse: 162.6405 - val_loss: 119.8433 - val_mse: 119.8433 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 84.0129 - mse: 84.0129\n",
      "Epoch 13: val_loss did not improve from 119.84333\n",
      "95/95 [==============================] - 61s 646ms/step - loss: 84.0129 - mse: 84.0129 - val_loss: 121.0348 - val_mse: 121.0348 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 102.7149 - mse: 102.7149\n",
      "Epoch 14: val_loss improved from 119.84333 to 118.74836, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 102.7149 - mse: 102.7149 - val_loss: 118.7484 - val_mse: 118.7484 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 77.7161 - mse: 77.7161\n",
      "Epoch 15: val_loss did not improve from 118.74836\n",
      "95/95 [==============================] - 62s 650ms/step - loss: 77.7161 - mse: 77.7161 - val_loss: 248.7933 - val_mse: 248.7933 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 92.8361 - mse: 92.8361\n",
      "Epoch 16: val_loss did not improve from 118.74836\n",
      "95/95 [==============================] - 62s 653ms/step - loss: 92.8361 - mse: 92.8361 - val_loss: 147.5321 - val_mse: 147.5321 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 102.2035 - mse: 102.2035\n",
      "Epoch 17: val_loss improved from 118.74836 to 107.92835, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 64s 673ms/step - loss: 102.2035 - mse: 102.2035 - val_loss: 107.9284 - val_mse: 107.9284 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 70.9632 - mse: 70.9632\n",
      "Epoch 18: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 62s 655ms/step - loss: 70.9632 - mse: 70.9632 - val_loss: 133.0221 - val_mse: 133.0221 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 91.7783 - mse: 91.7783\n",
      "Epoch 19: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 63s 665ms/step - loss: 91.7783 - mse: 91.7783 - val_loss: 120.6973 - val_mse: 120.6973 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 89.1388 - mse: 89.1388\n",
      "Epoch 20: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 63s 662ms/step - loss: 89.1388 - mse: 89.1388 - val_loss: 108.3904 - val_mse: 108.3904 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 74.0063 - mse: 74.0063\n",
      "Epoch 21: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 62s 651ms/step - loss: 74.0063 - mse: 74.0063 - val_loss: 128.2643 - val_mse: 128.2643 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 64.6805 - mse: 64.6805\n",
      "Epoch 22: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 63s 660ms/step - loss: 64.6805 - mse: 64.6805 - val_loss: 109.7898 - val_mse: 109.7898 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "78/95 [=======================>......] - ETA: 10s - loss: 83.4181 - mse: 83.4181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x2ed9b9c80>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x14c2b9400>\n",
      "        name = Apple M1 Max \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x11c81f200>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x14c2b9400>\n",
      "            name = Apple M1 Max \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 84.9824 - mse: 84.9824\n",
      "Epoch 23: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 64s 670ms/step - loss: 84.9824 - mse: 84.9824 - val_loss: 111.8505 - val_mse: 111.8505 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 58.4346 - mse: 58.4346\n",
      "Epoch 24: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 62s 651ms/step - loss: 58.4346 - mse: 58.4346 - val_loss: 111.8345 - val_mse: 111.8345 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 53.1786 - mse: 53.1786\n",
      "Epoch 25: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 62s 657ms/step - loss: 53.1786 - mse: 53.1786 - val_loss: 166.0718 - val_mse: 166.0718 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 60.8899 - mse: 60.8899\n",
      "Epoch 26: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 63s 664ms/step - loss: 60.8899 - mse: 60.8899 - val_loss: 145.2552 - val_mse: 145.2552 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 91.3485 - mse: 91.3485\n",
      "Epoch 27: val_loss did not improve from 107.92835\n",
      "95/95 [==============================] - 62s 648ms/step - loss: 91.3485 - mse: 91.3485 - val_loss: 232.0493 - val_mse: 232.0493 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 39.6337 - mse: 39.6337\n",
      "Epoch 28: val_loss improved from 107.92835 to 97.56347, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 62s 657ms/step - loss: 39.6337 - mse: 39.6337 - val_loss: 97.5635 - val_mse: 97.5635 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 33.9854 - mse: 33.9854\n",
      "Epoch 29: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 64s 669ms/step - loss: 33.9854 - mse: 33.9854 - val_loss: 97.8156 - val_mse: 97.8156 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 31.3254 - mse: 31.3254\n",
      "Epoch 30: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 31.3254 - mse: 31.3254 - val_loss: 98.4442 - val_mse: 98.4442 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.7339 - mse: 30.7339\n",
      "Epoch 31: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 62s 655ms/step - loss: 30.7339 - mse: 30.7339 - val_loss: 101.3901 - val_mse: 101.3901 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 28.3917 - mse: 28.3917\n",
      "Epoch 32: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 63s 668ms/step - loss: 28.3917 - mse: 28.3917 - val_loss: 100.4599 - val_mse: 100.4599 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.1349 - mse: 30.1349\n",
      "Epoch 33: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 62s 654ms/step - loss: 30.1349 - mse: 30.1349 - val_loss: 98.1529 - val_mse: 98.1529 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 28.5622 - mse: 28.5622\n",
      "Epoch 34: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 62s 651ms/step - loss: 28.5622 - mse: 28.5622 - val_loss: 112.5676 - val_mse: 112.5676 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 34.9990 - mse: 34.9990\n",
      "Epoch 35: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 64s 672ms/step - loss: 34.9990 - mse: 34.9990 - val_loss: 101.1676 - val_mse: 101.1676 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.1148 - mse: 26.1148\n",
      "Epoch 36: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 62s 654ms/step - loss: 26.1148 - mse: 26.1148 - val_loss: 98.7336 - val_mse: 98.7336 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.6563 - mse: 25.6563\n",
      "Epoch 37: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 61s 646ms/step - loss: 25.6563 - mse: 25.6563 - val_loss: 98.6819 - val_mse: 98.6819 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.0980 - mse: 24.0980\n",
      "Epoch 38: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 64s 676ms/step - loss: 24.0980 - mse: 24.0980 - val_loss: 97.7402 - val_mse: 97.7402 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.1807 - mse: 23.1807\n",
      "Epoch 39: val_loss did not improve from 97.56347\n",
      "95/95 [==============================] - 63s 659ms/step - loss: 23.1807 - mse: 23.1807 - val_loss: 97.6276 - val_mse: 97.6276 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.9978 - mse: 21.9978\n",
      "Epoch 40: val_loss improved from 97.56347 to 97.49460, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 21.9978 - mse: 21.9978 - val_loss: 97.4946 - val_mse: 97.4946 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.5287 - mse: 24.5287\n",
      "Epoch 41: val_loss did not improve from 97.49460\n",
      "95/95 [==============================] - 64s 670ms/step - loss: 24.5287 - mse: 24.5287 - val_loss: 99.3727 - val_mse: 99.3727 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.1073 - mse: 22.1073\n",
      "Epoch 42: val_loss improved from 97.49460 to 97.39046, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 63s 662ms/step - loss: 22.1073 - mse: 22.1073 - val_loss: 97.3905 - val_mse: 97.3905 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.5773 - mse: 22.5773\n",
      "Epoch 43: val_loss did not improve from 97.39046\n",
      "95/95 [==============================] - 62s 648ms/step - loss: 22.5773 - mse: 22.5773 - val_loss: 97.5165 - val_mse: 97.5165 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.9522 - mse: 23.9522\n",
      "Epoch 44: val_loss did not improve from 97.39046\n",
      "95/95 [==============================] - 63s 662ms/step - loss: 23.9522 - mse: 23.9522 - val_loss: 98.0478 - val_mse: 98.0478 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.2651 - mse: 22.2651\n",
      "Epoch 45: val_loss did not improve from 97.39046\n",
      "95/95 [==============================] - 63s 662ms/step - loss: 22.2651 - mse: 22.2651 - val_loss: 97.4197 - val_mse: 97.4197 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.8118 - mse: 22.8118\n",
      "Epoch 46: val_loss did not improve from 97.39046\n",
      "95/95 [==============================] - 61s 645ms/step - loss: 22.8118 - mse: 22.8118 - val_loss: 97.9142 - val_mse: 97.9142 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.6856 - mse: 23.6856\n",
      "Epoch 47: val_loss improved from 97.39046 to 97.32435, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 64s 668ms/step - loss: 23.6856 - mse: 23.6856 - val_loss: 97.3243 - val_mse: 97.3243 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.4673 - mse: 23.4673\n",
      "Epoch 48: val_loss did not improve from 97.32435\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 23.4673 - mse: 23.4673 - val_loss: 97.7850 - val_mse: 97.7850 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.8815 - mse: 22.8815\n",
      "Epoch 49: val_loss did not improve from 97.32435\n",
      "95/95 [==============================] - 62s 654ms/step - loss: 22.8815 - mse: 22.8815 - val_loss: 97.4937 - val_mse: 97.4937 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.9238 - mse: 22.9238\n",
      "Epoch 50: val_loss improved from 97.32435 to 97.11970, saving model to E-scale2/E2-scale_run4.h5\n",
      "95/95 [==============================] - 63s 668ms/step - loss: 22.9238 - mse: 22.9238 - val_loss: 97.1197 - val_mse: 97.1197 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.1883 - mse: 22.1883\n",
      "Epoch 51: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 662ms/step - loss: 22.1883 - mse: 22.1883 - val_loss: 99.0150 - val_mse: 99.0150 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.9020 - mse: 22.9020\n",
      "Epoch 52: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 646ms/step - loss: 22.9020 - mse: 22.9020 - val_loss: 97.2321 - val_mse: 97.2321 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.4720 - mse: 23.4720\n",
      "Epoch 53: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 64s 668ms/step - loss: 23.4720 - mse: 23.4720 - val_loss: 97.1763 - val_mse: 97.1763 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.5826 - mse: 22.5826\n",
      "Epoch 54: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 657ms/step - loss: 22.5826 - mse: 22.5826 - val_loss: 98.4421 - val_mse: 98.4421 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.3776 - mse: 21.3776\n",
      "Epoch 55: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 61s 644ms/step - loss: 21.3776 - mse: 21.3776 - val_loss: 97.4260 - val_mse: 97.4260 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.5479 - mse: 21.5479\n",
      "Epoch 56: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 662ms/step - loss: 21.5479 - mse: 21.5479 - val_loss: 97.4319 - val_mse: 97.4319 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.8875 - mse: 23.8875\n",
      "Epoch 57: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 23.8875 - mse: 23.8875 - val_loss: 98.1095 - val_mse: 98.1095 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.0189 - mse: 25.0189\n",
      "Epoch 58: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 653ms/step - loss: 25.0189 - mse: 25.0189 - val_loss: 97.7670 - val_mse: 97.7670 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.2621 - mse: 23.2621\n",
      "Epoch 59: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 659ms/step - loss: 23.2621 - mse: 23.2621 - val_loss: 97.5245 - val_mse: 97.5245 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.4036 - mse: 24.4036\n",
      "Epoch 60: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 24.4036 - mse: 24.4036 - val_loss: 97.9625 - val_mse: 97.9625 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.7023 - mse: 21.7023\n",
      "Epoch 61: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 21.7023 - mse: 21.7023 - val_loss: 98.3215 - val_mse: 98.3215 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.7352 - mse: 20.7352\n",
      "Epoch 62: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 657ms/step - loss: 20.7352 - mse: 20.7352 - val_loss: 97.8445 - val_mse: 97.8445 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.9307 - mse: 21.9307\n",
      "Epoch 63: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 662ms/step - loss: 21.9307 - mse: 21.9307 - val_loss: 97.7803 - val_mse: 97.7803 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.8226 - mse: 21.8226\n",
      "Epoch 64: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 649ms/step - loss: 21.8226 - mse: 21.8226 - val_loss: 97.7439 - val_mse: 97.7439 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.4690 - mse: 20.4690\n",
      "Epoch 65: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 650ms/step - loss: 20.4690 - mse: 20.4690 - val_loss: 97.8388 - val_mse: 97.8388 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.1409 - mse: 22.1409\n",
      "Epoch 66: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 665ms/step - loss: 22.1409 - mse: 22.1409 - val_loss: 98.4752 - val_mse: 98.4752 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.5121 - mse: 22.5121\n",
      "Epoch 67: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 656ms/step - loss: 22.5121 - mse: 22.5121 - val_loss: 97.7633 - val_mse: 97.7633 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.9075 - mse: 19.9075\n",
      "Epoch 68: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 650ms/step - loss: 19.9075 - mse: 19.9075 - val_loss: 97.9491 - val_mse: 97.9491 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.6584 - mse: 23.6584\n",
      "Epoch 69: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 667ms/step - loss: 23.6584 - mse: 23.6584 - val_loss: 98.7719 - val_mse: 98.7719 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.4195 - mse: 20.4195\n",
      "Epoch 70: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 661ms/step - loss: 20.4195 - mse: 20.4195 - val_loss: 98.6173 - val_mse: 98.6173 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.2831 - mse: 20.2831\n",
      "Epoch 71: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 62s 651ms/step - loss: 20.2831 - mse: 20.2831 - val_loss: 98.1778 - val_mse: 98.1778 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.5199 - mse: 21.5199\n",
      "Epoch 72: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 668ms/step - loss: 21.5199 - mse: 21.5199 - val_loss: 98.3218 - val_mse: 98.3218 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.6909 - mse: 19.6909\n",
      "Epoch 73: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 50s 525ms/step - loss: 19.6909 - mse: 19.6909 - val_loss: 97.8219 - val_mse: 97.8219 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.1477 - mse: 20.1477\n",
      "Epoch 74: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 628ms/step - loss: 20.1477 - mse: 20.1477 - val_loss: 98.3018 - val_mse: 98.3018 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.2276 - mse: 22.2276\n",
      "Epoch 75: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 622ms/step - loss: 22.2276 - mse: 22.2276 - val_loss: 98.3516 - val_mse: 98.3516 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.0978 - mse: 22.0978\n",
      "Epoch 76: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 627ms/step - loss: 22.0978 - mse: 22.0978 - val_loss: 98.6618 - val_mse: 98.6618 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.8149 - mse: 21.8149\n",
      "Epoch 77: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 632ms/step - loss: 21.8149 - mse: 21.8149 - val_loss: 98.9132 - val_mse: 98.9132 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.2722 - mse: 19.2722\n",
      "Epoch 78: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 623ms/step - loss: 19.2722 - mse: 19.2722 - val_loss: 98.0786 - val_mse: 98.0786 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.8640 - mse: 19.8640\n",
      "Epoch 79: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 19.8640 - mse: 19.8640 - val_loss: 98.2383 - val_mse: 98.2383 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.3685 - mse: 19.3685\n",
      "Epoch 80: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 623ms/step - loss: 19.3685 - mse: 19.3685 - val_loss: 99.5209 - val_mse: 99.5209 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.4148 - mse: 19.4148\n",
      "Epoch 81: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 627ms/step - loss: 19.4148 - mse: 19.4148 - val_loss: 98.3220 - val_mse: 98.3220 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.1042 - mse: 20.1042\n",
      "Epoch 82: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 20.1042 - mse: 20.1042 - val_loss: 98.4469 - val_mse: 98.4469 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.4591 - mse: 23.4591\n",
      "Epoch 83: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 23.4591 - mse: 23.4591 - val_loss: 98.5693 - val_mse: 98.5693 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.4821 - mse: 20.4821\n",
      "Epoch 84: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 625ms/step - loss: 20.4821 - mse: 20.4821 - val_loss: 97.9309 - val_mse: 97.9309 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.9320 - mse: 20.9320\n",
      "Epoch 85: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 20.9320 - mse: 20.9320 - val_loss: 97.7867 - val_mse: 97.7867 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.9449 - mse: 18.9449\n",
      "Epoch 86: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 18.9449 - mse: 18.9449 - val_loss: 98.2134 - val_mse: 98.2134 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.8968 - mse: 17.8968\n",
      "Epoch 87: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 17.8968 - mse: 17.8968 - val_loss: 98.0249 - val_mse: 98.0249 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.9422 - mse: 17.9422\n",
      "Epoch 88: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 17.9422 - mse: 17.9422 - val_loss: 98.4670 - val_mse: 98.4670 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.2568 - mse: 19.2568\n",
      "Epoch 89: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 19.2568 - mse: 19.2568 - val_loss: 98.2701 - val_mse: 98.2701 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.6562 - mse: 18.6562\n",
      "Epoch 90: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 18.6562 - mse: 18.6562 - val_loss: 97.8764 - val_mse: 97.8764 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.8708 - mse: 17.8708\n",
      "Epoch 91: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 621ms/step - loss: 17.8708 - mse: 17.8708 - val_loss: 98.5213 - val_mse: 98.5213 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.2962 - mse: 21.2962\n",
      "Epoch 92: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 21.2962 - mse: 21.2962 - val_loss: 98.3225 - val_mse: 98.3225 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.9281 - mse: 18.9281\n",
      "Epoch 93: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 18.9281 - mse: 18.9281 - val_loss: 98.0216 - val_mse: 98.0216 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.4988 - mse: 18.4988\n",
      "Epoch 94: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 18.4988 - mse: 18.4988 - val_loss: 98.8727 - val_mse: 98.8727 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.4385 - mse: 17.4385\n",
      "Epoch 95: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 632ms/step - loss: 17.4385 - mse: 17.4385 - val_loss: 98.6349 - val_mse: 98.6349 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.3074 - mse: 20.3074\n",
      "Epoch 96: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 20.3074 - mse: 20.3074 - val_loss: 98.5138 - val_mse: 98.5138 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.1361 - mse: 17.1361\n",
      "Epoch 97: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 59s 622ms/step - loss: 17.1361 - mse: 17.1361 - val_loss: 98.6344 - val_mse: 98.6344 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.1561 - mse: 17.1561\n",
      "Epoch 98: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 63s 658ms/step - loss: 17.1561 - mse: 17.1561 - val_loss: 99.0847 - val_mse: 99.0847 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.1301 - mse: 18.1301\n",
      "Epoch 99: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 18.1301 - mse: 18.1301 - val_loss: 98.9761 - val_mse: 98.9761 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.9430 - mse: 18.9430\n",
      "Epoch 100: val_loss did not improve from 97.11970\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 18.9430 - mse: 18.9430 - val_loss: 98.4887 - val_mse: 98.4887 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 02:05:16.716445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 4454.0430 - mse: 4454.0430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 02:06:17.649905: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 7390.86865, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 69s 701ms/step - loss: 4454.0430 - mse: 4454.0430 - val_loss: 7390.8687 - val_mse: 7390.8687 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 364.0519 - mse: 364.0519\n",
      "Epoch 2: val_loss improved from 7390.86865 to 5980.56348, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 68s 712ms/step - loss: 364.0519 - mse: 364.0519 - val_loss: 5980.5635 - val_mse: 5980.5635 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 243.7432 - mse: 243.7432\n",
      "Epoch 3: val_loss improved from 5980.56348 to 4768.24951, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 68s 710ms/step - loss: 243.7432 - mse: 243.7432 - val_loss: 4768.2495 - val_mse: 4768.2495 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 219.2350 - mse: 219.2350\n",
      "Epoch 4: val_loss improved from 4768.24951 to 2943.46997, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 68s 714ms/step - loss: 219.2350 - mse: 219.2350 - val_loss: 2943.4700 - val_mse: 2943.4700 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 220.2504 - mse: 220.2504\n",
      "Epoch 5: val_loss did not improve from 2943.46997\n",
      "95/95 [==============================] - 67s 703ms/step - loss: 220.2504 - mse: 220.2504 - val_loss: 3045.6230 - val_mse: 3045.6230 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 208.9157 - mse: 208.9157\n",
      "Epoch 6: val_loss improved from 2943.46997 to 1341.64990, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 208.9157 - mse: 208.9157 - val_loss: 1341.6499 - val_mse: 1341.6499 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 183.0665 - mse: 183.0665\n",
      "Epoch 7: val_loss improved from 1341.64990 to 543.38818, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 68s 712ms/step - loss: 183.0665 - mse: 183.0665 - val_loss: 543.3882 - val_mse: 543.3882 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 156.6704 - mse: 156.6704\n",
      "Epoch 8: val_loss did not improve from 543.38818\n",
      "95/95 [==============================] - 68s 718ms/step - loss: 156.6704 - mse: 156.6704 - val_loss: 574.1591 - val_mse: 574.1591 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 158.1284 - mse: 158.1284\n",
      "Epoch 9: val_loss improved from 543.38818 to 143.89497, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 158.1284 - mse: 158.1284 - val_loss: 143.8950 - val_mse: 143.8950 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 170.0883 - mse: 170.0883\n",
      "Epoch 10: val_loss did not improve from 143.89497\n",
      "95/95 [==============================] - 68s 710ms/step - loss: 170.0883 - mse: 170.0883 - val_loss: 252.3215 - val_mse: 252.3215 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 168.6275 - mse: 168.6275\n",
      "Epoch 11: val_loss improved from 143.89497 to 110.57965, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 168.6275 - mse: 168.6275 - val_loss: 110.5797 - val_mse: 110.5797 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 134.0928 - mse: 134.0928\n",
      "Epoch 12: val_loss improved from 110.57965 to 107.56241, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 67s 710ms/step - loss: 134.0928 - mse: 134.0928 - val_loss: 107.5624 - val_mse: 107.5624 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 157.0727 - mse: 157.0727\n",
      "Epoch 13: val_loss did not improve from 107.56241\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 157.0727 - mse: 157.0727 - val_loss: 123.4472 - val_mse: 123.4472 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 119.9262 - mse: 119.9262\n",
      "Epoch 14: val_loss did not improve from 107.56241\n",
      "95/95 [==============================] - 66s 689ms/step - loss: 119.9262 - mse: 119.9262 - val_loss: 107.6097 - val_mse: 107.6097 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 109.1209 - mse: 109.1209\n",
      "Epoch 15: val_loss did not improve from 107.56241\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 109.1209 - mse: 109.1209 - val_loss: 120.8528 - val_mse: 120.8528 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 116.7781 - mse: 116.7781\n",
      "Epoch 16: val_loss did not improve from 107.56241\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 116.7781 - mse: 116.7781 - val_loss: 203.0343 - val_mse: 203.0343 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 139.3922 - mse: 139.3922\n",
      "Epoch 17: val_loss improved from 107.56241 to 96.85867, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 68s 719ms/step - loss: 139.3922 - mse: 139.3922 - val_loss: 96.8587 - val_mse: 96.8587 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 87.8093 - mse: 87.8093\n",
      "Epoch 18: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 87.8093 - mse: 87.8093 - val_loss: 280.6487 - val_mse: 280.6487 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 114.5857 - mse: 114.5857\n",
      "Epoch 19: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 114.5857 - mse: 114.5857 - val_loss: 171.5441 - val_mse: 171.5441 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 121.8660 - mse: 121.8660\n",
      "Epoch 20: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 121.8660 - mse: 121.8660 - val_loss: 224.8544 - val_mse: 224.8544 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 69.9756 - mse: 69.9756\n",
      "Epoch 21: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 66s 690ms/step - loss: 69.9756 - mse: 69.9756 - val_loss: 106.3572 - val_mse: 106.3572 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 82.1917 - mse: 82.1917\n",
      "Epoch 22: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 82.1917 - mse: 82.1917 - val_loss: 191.7274 - val_mse: 191.7274 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 86.6512 - mse: 86.6512\n",
      "Epoch 23: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 86.6512 - mse: 86.6512 - val_loss: 151.7197 - val_mse: 151.7197 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 63.7137 - mse: 63.7137\n",
      "Epoch 24: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 63.7137 - mse: 63.7137 - val_loss: 154.5148 - val_mse: 154.5148 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 70.2095 - mse: 70.2095\n",
      "Epoch 25: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 70.2095 - mse: 70.2095 - val_loss: 102.1399 - val_mse: 102.1399 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 54.2334 - mse: 54.2334\n",
      "Epoch 26: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 54.2334 - mse: 54.2334 - val_loss: 200.6777 - val_mse: 200.6777 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 113.4713 - mse: 113.4713\n",
      "Epoch 27: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 113.4713 - mse: 113.4713 - val_loss: 126.7565 - val_mse: 126.7565 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 48.1715 - mse: 48.1715\n",
      "Epoch 28: val_loss did not improve from 96.85867\n",
      "95/95 [==============================] - 67s 707ms/step - loss: 48.1715 - mse: 48.1715 - val_loss: 114.3596 - val_mse: 114.3596 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 42.5152 - mse: 42.5152\n",
      "Epoch 29: val_loss improved from 96.85867 to 96.47795, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 42.5152 - mse: 42.5152 - val_loss: 96.4780 - val_mse: 96.4780 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 43.9519 - mse: 43.9519\n",
      "Epoch 30: val_loss did not improve from 96.47795\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 43.9519 - mse: 43.9519 - val_loss: 98.7982 - val_mse: 98.7982 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 35.6078 - mse: 35.6078\n",
      "Epoch 31: val_loss did not improve from 96.47795\n",
      "95/95 [==============================] - 67s 699ms/step - loss: 35.6078 - mse: 35.6078 - val_loss: 97.4593 - val_mse: 97.4593 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 39.1345 - mse: 39.1345\n",
      "Epoch 32: val_loss improved from 96.47795 to 96.01392, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 39.1345 - mse: 39.1345 - val_loss: 96.0139 - val_mse: 96.0139 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      " 2/95 [..............................] - ETA: 55s - loss: 26.3596 - mse: 26.3596 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x2fdc1e610>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x14c2b9400>\n",
      "        name = Apple M1 Max \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x11c81f200>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x14c2b9400>\n",
      "            name = Apple M1 Max \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 34.0900 - mse: 34.0900\n",
      "Epoch 33: val_loss improved from 96.01392 to 94.94717, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 34.0900 - mse: 34.0900 - val_loss: 94.9472 - val_mse: 94.9472 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 35.4643 - mse: 35.4643\n",
      "Epoch 34: val_loss did not improve from 94.94717\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 35.4643 - mse: 35.4643 - val_loss: 95.7072 - val_mse: 95.7072 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 35.9496 - mse: 35.9496\n",
      "Epoch 35: val_loss did not improve from 94.94717\n",
      "95/95 [==============================] - 67s 707ms/step - loss: 35.9496 - mse: 35.9496 - val_loss: 97.1028 - val_mse: 97.1028 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 32.2379 - mse: 32.2379\n",
      "Epoch 36: val_loss did not improve from 94.94717\n",
      "95/95 [==============================] - 67s 706ms/step - loss: 32.2379 - mse: 32.2379 - val_loss: 99.3657 - val_mse: 99.3657 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 33.5992 - mse: 33.5992\n",
      "Epoch 37: val_loss did not improve from 94.94717\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 33.5992 - mse: 33.5992 - val_loss: 96.6192 - val_mse: 96.6192 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 35.5508 - mse: 35.5508\n",
      "Epoch 38: val_loss did not improve from 94.94717\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 35.5508 - mse: 35.5508 - val_loss: 97.3295 - val_mse: 97.3295 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 34.4507 - mse: 34.4507\n",
      "Epoch 39: val_loss did not improve from 94.94717\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 34.4507 - mse: 34.4507 - val_loss: 95.9882 - val_mse: 95.9882 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 33.1121 - mse: 33.1121\n",
      "Epoch 40: val_loss improved from 94.94717 to 94.42100, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 33.1121 - mse: 33.1121 - val_loss: 94.4210 - val_mse: 94.4210 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 29.9976 - mse: 29.9976\n",
      "Epoch 41: val_loss did not improve from 94.42100\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 29.9976 - mse: 29.9976 - val_loss: 96.4851 - val_mse: 96.4851 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.5953 - mse: 27.5953\n",
      "Epoch 42: val_loss did not improve from 94.42100\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 27.5953 - mse: 27.5953 - val_loss: 95.2812 - val_mse: 95.2812 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 32.0351 - mse: 32.0351\n",
      "Epoch 43: val_loss did not improve from 94.42100\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 32.0351 - mse: 32.0351 - val_loss: 95.9979 - val_mse: 95.9979 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 32.0447 - mse: 32.0447\n",
      "Epoch 44: val_loss did not improve from 94.42100\n",
      "95/95 [==============================] - 68s 709ms/step - loss: 32.0447 - mse: 32.0447 - val_loss: 98.4510 - val_mse: 98.4510 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 33.0509 - mse: 33.0509\n",
      "Epoch 45: val_loss improved from 94.42100 to 93.94556, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 33.0509 - mse: 33.0509 - val_loss: 93.9456 - val_mse: 93.9456 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.1420 - mse: 30.1420\n",
      "Epoch 46: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 30.1420 - mse: 30.1420 - val_loss: 93.9793 - val_mse: 93.9793 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 29.7931 - mse: 29.7931\n",
      "Epoch 47: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 698ms/step - loss: 29.7931 - mse: 29.7931 - val_loss: 95.4374 - val_mse: 95.4374 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.9112 - mse: 26.9112\n",
      "Epoch 48: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 26.9112 - mse: 26.9112 - val_loss: 95.0551 - val_mse: 95.0551 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.9616 - mse: 30.9616\n",
      "Epoch 49: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 706ms/step - loss: 30.9616 - mse: 30.9616 - val_loss: 103.6772 - val_mse: 103.6772 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.2399 - mse: 25.2399\n",
      "Epoch 50: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 25.2399 - mse: 25.2399 - val_loss: 98.0936 - val_mse: 98.0936 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.1569 - mse: 27.1569\n",
      "Epoch 51: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 27.1569 - mse: 27.1569 - val_loss: 98.4470 - val_mse: 98.4470 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 31.1101 - mse: 31.1101\n",
      "Epoch 52: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 31.1101 - mse: 31.1101 - val_loss: 98.9411 - val_mse: 98.9411 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.7280 - mse: 25.7280\n",
      "Epoch 53: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 25.7280 - mse: 25.7280 - val_loss: 95.3991 - val_mse: 95.3991 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.6714 - mse: 30.6714\n",
      "Epoch 54: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 30.6714 - mse: 30.6714 - val_loss: 95.8313 - val_mse: 95.8313 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.8891 - mse: 26.8891\n",
      "Epoch 55: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 26.8891 - mse: 26.8891 - val_loss: 97.1487 - val_mse: 97.1487 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.4772 - mse: 25.4772\n",
      "Epoch 56: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 25.4772 - mse: 25.4772 - val_loss: 94.5085 - val_mse: 94.5085 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.8213 - mse: 24.8213\n",
      "Epoch 57: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 24.8213 - mse: 24.8213 - val_loss: 94.1138 - val_mse: 94.1138 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.2404 - mse: 23.2404\n",
      "Epoch 58: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 23.2404 - mse: 23.2404 - val_loss: 93.9625 - val_mse: 93.9625 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.3073 - mse: 24.3073\n",
      "Epoch 59: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 24.3073 - mse: 24.3073 - val_loss: 94.1283 - val_mse: 94.1283 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.2530 - mse: 21.2530\n",
      "Epoch 60: val_loss did not improve from 93.94556\n",
      "95/95 [==============================] - 66s 691ms/step - loss: 21.2530 - mse: 21.2530 - val_loss: 94.1265 - val_mse: 94.1265 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.4147 - mse: 25.4147\n",
      "Epoch 61: val_loss improved from 93.94556 to 93.88268, saving model to E-scale2/E2-scale_run5.h5\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 25.4147 - mse: 25.4147 - val_loss: 93.8827 - val_mse: 93.8827 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.0799 - mse: 27.0799\n",
      "Epoch 62: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 27.0799 - mse: 27.0799 - val_loss: 94.1942 - val_mse: 94.1942 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.8293 - mse: 22.8293\n",
      "Epoch 63: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 698ms/step - loss: 22.8293 - mse: 22.8293 - val_loss: 94.3618 - val_mse: 94.3618 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.7666 - mse: 30.7666\n",
      "Epoch 64: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 30.7666 - mse: 30.7666 - val_loss: 94.3977 - val_mse: 94.3977 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.5799 - mse: 22.5799\n",
      "Epoch 65: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 706ms/step - loss: 22.5799 - mse: 22.5799 - val_loss: 94.1517 - val_mse: 94.1517 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.8466 - mse: 24.8466\n",
      "Epoch 66: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 689ms/step - loss: 24.8466 - mse: 24.8466 - val_loss: 94.3115 - val_mse: 94.3115 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.4143 - mse: 26.4143\n",
      "Epoch 67: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 26.4143 - mse: 26.4143 - val_loss: 94.6338 - val_mse: 94.6338 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.2691 - mse: 27.2691\n",
      "Epoch 68: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 27.2691 - mse: 27.2691 - val_loss: 95.6544 - val_mse: 95.6544 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.6272 - mse: 25.6272\n",
      "Epoch 69: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 25.6272 - mse: 25.6272 - val_loss: 94.1467 - val_mse: 94.1467 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.7491 - mse: 21.7491\n",
      "Epoch 70: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 65s 685ms/step - loss: 21.7491 - mse: 21.7491 - val_loss: 94.2797 - val_mse: 94.2797 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.6273 - mse: 21.6273\n",
      "Epoch 71: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 699ms/step - loss: 21.6273 - mse: 21.6273 - val_loss: 95.1446 - val_mse: 95.1446 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 28.3210 - mse: 28.3210\n",
      "Epoch 72: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 710ms/step - loss: 28.3210 - mse: 28.3210 - val_loss: 94.4383 - val_mse: 94.4383 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.7351 - mse: 19.7351\n",
      "Epoch 73: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 19.7351 - mse: 19.7351 - val_loss: 93.9199 - val_mse: 93.9199 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.7384 - mse: 27.7384\n",
      "Epoch 74: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 696ms/step - loss: 27.7384 - mse: 27.7384 - val_loss: 96.1455 - val_mse: 96.1455 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.2537 - mse: 21.2537\n",
      "Epoch 75: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 21.2537 - mse: 21.2537 - val_loss: 94.2662 - val_mse: 94.2662 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.9142 - mse: 24.9142\n",
      "Epoch 76: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 708ms/step - loss: 24.9142 - mse: 24.9142 - val_loss: 94.0298 - val_mse: 94.0298 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.6460 - mse: 21.6460\n",
      "Epoch 77: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 21.6460 - mse: 21.6460 - val_loss: 94.9698 - val_mse: 94.9698 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.3409 - mse: 24.3409\n",
      "Epoch 78: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 701ms/step - loss: 24.3409 - mse: 24.3409 - val_loss: 94.6989 - val_mse: 94.6989 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.0808 - mse: 20.0808\n",
      "Epoch 79: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 697ms/step - loss: 20.0808 - mse: 20.0808 - val_loss: 94.4213 - val_mse: 94.4213 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.7184 - mse: 20.7184\n",
      "Epoch 80: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 65s 687ms/step - loss: 20.7184 - mse: 20.7184 - val_loss: 94.4158 - val_mse: 94.4158 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.9998 - mse: 19.9998\n",
      "Epoch 81: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 692ms/step - loss: 19.9998 - mse: 19.9998 - val_loss: 94.2807 - val_mse: 94.2807 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.4440 - mse: 23.4440\n",
      "Epoch 82: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 689ms/step - loss: 23.4440 - mse: 23.4440 - val_loss: 94.4496 - val_mse: 94.4496 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.4771 - mse: 26.4771\n",
      "Epoch 83: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 26.4771 - mse: 26.4771 - val_loss: 99.0325 - val_mse: 99.0325 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.3429 - mse: 23.3429\n",
      "Epoch 84: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 65s 680ms/step - loss: 23.3429 - mse: 23.3429 - val_loss: 94.9722 - val_mse: 94.9722 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.1544 - mse: 24.1544\n",
      "Epoch 85: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 702ms/step - loss: 24.1544 - mse: 24.1544 - val_loss: 94.6785 - val_mse: 94.6785 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.3488 - mse: 25.3488\n",
      "Epoch 86: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 25.3488 - mse: 25.3488 - val_loss: 94.6832 - val_mse: 94.6832 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "60/95 [=================>............] - ETA: 21s - loss: 20.8293 - mse: 20.8293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13XFamilyCommandBuffer: 0x2c49d0910>\n",
      "    label = <none> \n",
      "    device = <AGXG13XDevice: 0x14c2b9400>\n",
      "        name = Apple M1 Max \n",
      "    commandQueue = <AGXG13XFamilyCommandQueue: 0x11c81f200>\n",
      "        label = <none> \n",
      "        device = <AGXG13XDevice: 0x14c2b9400>\n",
      "            name = Apple M1 Max \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 22.3962 - mse: 22.3962\n",
      "Epoch 87: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 65s 686ms/step - loss: 22.3962 - mse: 22.3962 - val_loss: 100.1920 - val_mse: 100.1920 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.0643 - mse: 23.0643\n",
      "Epoch 88: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 698ms/step - loss: 23.0643 - mse: 23.0643 - val_loss: 94.9015 - val_mse: 94.9015 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.2451 - mse: 21.2451\n",
      "Epoch 89: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 699ms/step - loss: 21.2451 - mse: 21.2451 - val_loss: 94.7646 - val_mse: 94.7646 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.0380 - mse: 19.0380\n",
      "Epoch 90: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 19.0380 - mse: 19.0380 - val_loss: 94.5210 - val_mse: 94.5210 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.0394 - mse: 23.0394\n",
      "Epoch 91: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 23.0394 - mse: 23.0394 - val_loss: 94.7347 - val_mse: 94.7347 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.9367 - mse: 21.9367\n",
      "Epoch 92: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 21.9367 - mse: 21.9367 - val_loss: 97.0732 - val_mse: 97.0732 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.4844 - mse: 21.4844\n",
      "Epoch 93: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 708ms/step - loss: 21.4844 - mse: 21.4844 - val_loss: 94.6323 - val_mse: 94.6323 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.0064 - mse: 24.0064\n",
      "Epoch 94: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 700ms/step - loss: 24.0064 - mse: 24.0064 - val_loss: 94.9835 - val_mse: 94.9835 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.6859 - mse: 18.6859\n",
      "Epoch 95: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 695ms/step - loss: 18.6859 - mse: 18.6859 - val_loss: 94.6646 - val_mse: 94.6646 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.3887 - mse: 22.3887\n",
      "Epoch 96: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 705ms/step - loss: 22.3887 - mse: 22.3887 - val_loss: 94.9217 - val_mse: 94.9217 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.6043 - mse: 18.6043\n",
      "Epoch 97: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 67s 704ms/step - loss: 18.6043 - mse: 18.6043 - val_loss: 94.2261 - val_mse: 94.2261 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.1513 - mse: 19.1513\n",
      "Epoch 98: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 68s 711ms/step - loss: 19.1513 - mse: 19.1513 - val_loss: 94.9231 - val_mse: 94.9231 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.8793 - mse: 18.8793\n",
      "Epoch 99: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 693ms/step - loss: 18.8793 - mse: 18.8793 - val_loss: 94.4285 - val_mse: 94.4285 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.2465 - mse: 26.2465\n",
      "Epoch 100: val_loss did not improve from 93.88268\n",
      "95/95 [==============================] - 66s 694ms/step - loss: 26.2465 - mse: 26.2465 - val_loss: 95.0422 - val_mse: 95.0422 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 03:56:27.748402: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 5030.0439 - mse: 5030.0439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 03:57:26.696666: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 6882.84668, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 68s 652ms/step - loss: 5030.0439 - mse: 5030.0439 - val_loss: 6882.8467 - val_mse: 6882.8467 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 541.7026 - mse: 541.7026\n",
      "Epoch 2: val_loss improved from 6882.84668 to 5848.44678, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 541.7026 - mse: 541.7026 - val_loss: 5848.4468 - val_mse: 5848.4468 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 245.2166 - mse: 245.2166\n",
      "Epoch 3: val_loss improved from 5848.44678 to 4667.62744, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 245.2166 - mse: 245.2166 - val_loss: 4667.6274 - val_mse: 4667.6274 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 212.0489 - mse: 212.0489\n",
      "Epoch 4: val_loss improved from 4667.62744 to 3923.63696, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 59s 617ms/step - loss: 212.0489 - mse: 212.0489 - val_loss: 3923.6370 - val_mse: 3923.6370 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 235.5948 - mse: 235.5948\n",
      "Epoch 5: val_loss improved from 3923.63696 to 2815.49414, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 58s 610ms/step - loss: 235.5948 - mse: 235.5948 - val_loss: 2815.4941 - val_mse: 2815.4941 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 232.8770 - mse: 232.8770\n",
      "Epoch 6: val_loss improved from 2815.49414 to 1082.64160, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 52s 546ms/step - loss: 232.8770 - mse: 232.8770 - val_loss: 1082.6416 - val_mse: 1082.6416 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 128.5742 - mse: 128.5742\n",
      "Epoch 7: val_loss improved from 1082.64160 to 687.38971, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 57s 600ms/step - loss: 128.5742 - mse: 128.5742 - val_loss: 687.3897 - val_mse: 687.3897 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 171.4308 - mse: 171.4308\n",
      "Epoch 8: val_loss improved from 687.38971 to 300.62311, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 171.4308 - mse: 171.4308 - val_loss: 300.6231 - val_mse: 300.6231 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 127.5347 - mse: 127.5347\n",
      "Epoch 9: val_loss improved from 300.62311 to 135.71225, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 59s 622ms/step - loss: 127.5347 - mse: 127.5347 - val_loss: 135.7122 - val_mse: 135.7122 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 119.3388 - mse: 119.3388\n",
      "Epoch 10: val_loss improved from 135.71225 to 127.14862, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 59s 626ms/step - loss: 119.3388 - mse: 119.3388 - val_loss: 127.1486 - val_mse: 127.1486 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 105.4693 - mse: 105.4693\n",
      "Epoch 11: val_loss did not improve from 127.14862\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 105.4693 - mse: 105.4693 - val_loss: 127.3754 - val_mse: 127.3754 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 134.0224 - mse: 134.0224\n",
      "Epoch 12: val_loss did not improve from 127.14862\n",
      "95/95 [==============================] - 59s 626ms/step - loss: 134.0224 - mse: 134.0224 - val_loss: 144.8157 - val_mse: 144.8157 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 94.2531 - mse: 94.2531\n",
      "Epoch 13: val_loss did not improve from 127.14862\n",
      "95/95 [==============================] - 59s 617ms/step - loss: 94.2531 - mse: 94.2531 - val_loss: 232.3304 - val_mse: 232.3304 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 117.4193 - mse: 117.4193\n",
      "Epoch 14: val_loss did not improve from 127.14862\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 117.4193 - mse: 117.4193 - val_loss: 500.4820 - val_mse: 500.4820 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 119.8852 - mse: 119.8852\n",
      "Epoch 15: val_loss improved from 127.14862 to 112.76408, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 119.8852 - mse: 119.8852 - val_loss: 112.7641 - val_mse: 112.7641 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 78.7685 - mse: 78.7685\n",
      "Epoch 16: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 78.7685 - mse: 78.7685 - val_loss: 212.0811 - val_mse: 212.0811 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 72.7526 - mse: 72.7526\n",
      "Epoch 17: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 59s 618ms/step - loss: 72.7526 - mse: 72.7526 - val_loss: 154.7435 - val_mse: 154.7435 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 101.7470 - mse: 101.7470\n",
      "Epoch 18: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 59s 621ms/step - loss: 101.7470 - mse: 101.7470 - val_loss: 191.7102 - val_mse: 191.7102 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 95.4507 - mse: 95.4507\n",
      "Epoch 19: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 95.4507 - mse: 95.4507 - val_loss: 162.8169 - val_mse: 162.8169 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 80.4455 - mse: 80.4455\n",
      "Epoch 20: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 80.4455 - mse: 80.4455 - val_loss: 118.3105 - val_mse: 118.3105 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 120.6594 - mse: 120.6594\n",
      "Epoch 21: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 120.6594 - mse: 120.6594 - val_loss: 115.5262 - val_mse: 115.5262 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 61.8626 - mse: 61.8626\n",
      "Epoch 22: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 61.8626 - mse: 61.8626 - val_loss: 124.6401 - val_mse: 124.6401 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 53.9192 - mse: 53.9192\n",
      "Epoch 23: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 53.9192 - mse: 53.9192 - val_loss: 116.4695 - val_mse: 116.4695 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 55.5231 - mse: 55.5231\n",
      "Epoch 24: val_loss did not improve from 112.76408\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 55.5231 - mse: 55.5231 - val_loss: 119.9644 - val_mse: 119.9644 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 43.9181 - mse: 43.9181\n",
      "Epoch 25: val_loss improved from 112.76408 to 106.19617, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 43.9181 - mse: 43.9181 - val_loss: 106.1962 - val_mse: 106.1962 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 87.4612 - mse: 87.4612\n",
      "Epoch 26: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 59s 616ms/step - loss: 87.4612 - mse: 87.4612 - val_loss: 121.1597 - val_mse: 121.1597 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 53.6038 - mse: 53.6038\n",
      "Epoch 27: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 53.6038 - mse: 53.6038 - val_loss: 127.4335 - val_mse: 127.4335 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 64.2503 - mse: 64.2503\n",
      "Epoch 28: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 64.2503 - mse: 64.2503 - val_loss: 112.9858 - val_mse: 112.9858 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 66.0663 - mse: 66.0663\n",
      "Epoch 29: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 58s 616ms/step - loss: 66.0663 - mse: 66.0663 - val_loss: 148.3150 - val_mse: 148.3150 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 64.1892 - mse: 64.1892\n",
      "Epoch 30: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 58s 613ms/step - loss: 64.1892 - mse: 64.1892 - val_loss: 115.8132 - val_mse: 115.8132 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 36.1411 - mse: 36.1411\n",
      "Epoch 31: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 59s 621ms/step - loss: 36.1411 - mse: 36.1411 - val_loss: 107.4886 - val_mse: 107.4886 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 31.6455 - mse: 31.6455\n",
      "Epoch 32: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 58s 613ms/step - loss: 31.6455 - mse: 31.6455 - val_loss: 130.4158 - val_mse: 130.4158 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 32.7686 - mse: 32.7686\n",
      "Epoch 33: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 59s 618ms/step - loss: 32.7686 - mse: 32.7686 - val_loss: 110.1814 - val_mse: 110.1814 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 40.3958 - mse: 40.3958\n",
      "Epoch 34: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 40.3958 - mse: 40.3958 - val_loss: 131.5833 - val_mse: 131.5833 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 43.8997 - mse: 43.8997\n",
      "Epoch 35: val_loss did not improve from 106.19617\n",
      "95/95 [==============================] - 59s 617ms/step - loss: 43.8997 - mse: 43.8997 - val_loss: 117.1909 - val_mse: 117.1909 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.4815 - mse: 23.4815\n",
      "Epoch 36: val_loss improved from 106.19617 to 102.40417, saving model to E-scale2/E2-scale_run6.h5\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 23.4815 - mse: 23.4815 - val_loss: 102.4042 - val_mse: 102.4042 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.0179 - mse: 22.0179\n",
      "Epoch 37: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 57s 603ms/step - loss: 22.0179 - mse: 22.0179 - val_loss: 104.0806 - val_mse: 104.0806 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.3820 - mse: 17.3820\n",
      "Epoch 38: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 618ms/step - loss: 17.3820 - mse: 17.3820 - val_loss: 104.0371 - val_mse: 104.0371 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.8819 - mse: 19.8819\n",
      "Epoch 39: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 610ms/step - loss: 19.8819 - mse: 19.8819 - val_loss: 103.4249 - val_mse: 103.4249 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.3604 - mse: 19.3604\n",
      "Epoch 40: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 606ms/step - loss: 19.3604 - mse: 19.3604 - val_loss: 103.9321 - val_mse: 103.9321 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.1145 - mse: 18.1145\n",
      "Epoch 41: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 608ms/step - loss: 18.1145 - mse: 18.1145 - val_loss: 103.3043 - val_mse: 103.3043 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.0994 - mse: 16.0994\n",
      "Epoch 42: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 617ms/step - loss: 16.0994 - mse: 16.0994 - val_loss: 104.0058 - val_mse: 104.0058 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.1095 - mse: 17.1095\n",
      "Epoch 43: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 17.1095 - mse: 17.1095 - val_loss: 104.4740 - val_mse: 104.4740 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.1556 - mse: 18.1556\n",
      "Epoch 44: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 18.1556 - mse: 18.1556 - val_loss: 104.5124 - val_mse: 104.5124 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.8436 - mse: 15.8436\n",
      "Epoch 45: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 608ms/step - loss: 15.8436 - mse: 15.8436 - val_loss: 104.8322 - val_mse: 104.8322 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.6395 - mse: 15.6395\n",
      "Epoch 46: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 15.6395 - mse: 15.6395 - val_loss: 105.9127 - val_mse: 105.9127 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.5778 - mse: 13.5778\n",
      "Epoch 47: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 13.5778 - mse: 13.5778 - val_loss: 104.8413 - val_mse: 104.8413 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.6496 - mse: 13.6496\n",
      "Epoch 48: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 13.6496 - mse: 13.6496 - val_loss: 104.7965 - val_mse: 104.7965 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9397 - mse: 12.9397\n",
      "Epoch 49: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 12.9397 - mse: 12.9397 - val_loss: 105.1060 - val_mse: 105.1060 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.1852 - mse: 13.1852\n",
      "Epoch 50: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 13.1852 - mse: 13.1852 - val_loss: 104.9944 - val_mse: 104.9944 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.0018 - mse: 17.0018\n",
      "Epoch 51: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 17.0018 - mse: 17.0018 - val_loss: 104.6989 - val_mse: 104.6989 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.7457 - mse: 16.7457\n",
      "Epoch 52: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 16.7457 - mse: 16.7457 - val_loss: 104.3104 - val_mse: 104.3104 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.3183 - mse: 13.3183\n",
      "Epoch 53: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 613ms/step - loss: 13.3183 - mse: 13.3183 - val_loss: 104.5989 - val_mse: 104.5989 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.6571 - mse: 14.6571\n",
      "Epoch 54: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 57s 603ms/step - loss: 14.6571 - mse: 14.6571 - val_loss: 103.8125 - val_mse: 103.8125 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.0276 - mse: 13.0276\n",
      "Epoch 55: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 13.0276 - mse: 13.0276 - val_loss: 104.6137 - val_mse: 104.6137 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.8625 - mse: 13.8625\n",
      "Epoch 56: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 57s 600ms/step - loss: 13.8625 - mse: 13.8625 - val_loss: 104.5893 - val_mse: 104.5893 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.7607 - mse: 15.7607\n",
      "Epoch 57: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 616ms/step - loss: 15.7607 - mse: 15.7607 - val_loss: 105.2742 - val_mse: 105.2742 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.2991 - mse: 16.2991\n",
      "Epoch 58: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 16.2991 - mse: 16.2991 - val_loss: 104.8544 - val_mse: 104.8544 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9263 - mse: 12.9263\n",
      "Epoch 59: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 12.9263 - mse: 12.9263 - val_loss: 104.7069 - val_mse: 104.7069 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.7667 - mse: 13.7667\n",
      "Epoch 60: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 57s 604ms/step - loss: 13.7667 - mse: 13.7667 - val_loss: 104.5153 - val_mse: 104.5153 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.9856 - mse: 13.9856\n",
      "Epoch 61: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 13.9856 - mse: 13.9856 - val_loss: 104.8580 - val_mse: 104.8580 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.5198 - mse: 14.5198\n",
      "Epoch 62: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 14.5198 - mse: 14.5198 - val_loss: 106.3016 - val_mse: 106.3016 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9209 - mse: 12.9209\n",
      "Epoch 63: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 12.9209 - mse: 12.9209 - val_loss: 104.4308 - val_mse: 104.4308 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.8260 - mse: 13.8260\n",
      "Epoch 64: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 13.8260 - mse: 13.8260 - val_loss: 104.9419 - val_mse: 104.9419 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.5420 - mse: 14.5420\n",
      "Epoch 65: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 618ms/step - loss: 14.5420 - mse: 14.5420 - val_loss: 104.2365 - val_mse: 104.2365 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.8092 - mse: 12.8092\n",
      "Epoch 66: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 12.8092 - mse: 12.8092 - val_loss: 104.8101 - val_mse: 104.8101 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.4525 - mse: 14.4525\n",
      "Epoch 67: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 14.4525 - mse: 14.4525 - val_loss: 104.8801 - val_mse: 104.8801 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.2993 - mse: 12.2993\n",
      "Epoch 68: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 12.2993 - mse: 12.2993 - val_loss: 104.6031 - val_mse: 104.6031 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.3362 - mse: 14.3362\n",
      "Epoch 69: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 14.3362 - mse: 14.3362 - val_loss: 105.6911 - val_mse: 105.6911 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.7793 - mse: 12.7793\n",
      "Epoch 70: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 622ms/step - loss: 12.7793 - mse: 12.7793 - val_loss: 104.4755 - val_mse: 104.4755 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.9486 - mse: 13.9486\n",
      "Epoch 71: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 13.9486 - mse: 13.9486 - val_loss: 105.5551 - val_mse: 105.5551 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.3130 - mse: 13.3130\n",
      "Epoch 72: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 13.3130 - mse: 13.3130 - val_loss: 104.6748 - val_mse: 104.6748 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.5490 - mse: 13.5490\n",
      "Epoch 73: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 616ms/step - loss: 13.5490 - mse: 13.5490 - val_loss: 104.2963 - val_mse: 104.2963 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.3387 - mse: 12.3387\n",
      "Epoch 74: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 12.3387 - mse: 12.3387 - val_loss: 104.3742 - val_mse: 104.3742 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.4030 - mse: 15.4030\n",
      "Epoch 75: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 15.4030 - mse: 15.4030 - val_loss: 105.2737 - val_mse: 105.2737 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.6229 - mse: 14.6229\n",
      "Epoch 76: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 14.6229 - mse: 14.6229 - val_loss: 104.4247 - val_mse: 104.4247 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.4311 - mse: 13.4311\n",
      "Epoch 77: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 625ms/step - loss: 13.4311 - mse: 13.4311 - val_loss: 104.5528 - val_mse: 104.5528 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9934 - mse: 12.9934\n",
      "Epoch 78: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 626ms/step - loss: 12.9934 - mse: 12.9934 - val_loss: 104.2938 - val_mse: 104.2938 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.0439 - mse: 12.0439\n",
      "Epoch 79: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 12.0439 - mse: 12.0439 - val_loss: 104.4604 - val_mse: 104.4604 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.2568 - mse: 12.2568\n",
      "Epoch 80: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 12.2568 - mse: 12.2568 - val_loss: 105.2283 - val_mse: 105.2283 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.7765 - mse: 13.7765\n",
      "Epoch 81: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 51s 541ms/step - loss: 13.7765 - mse: 13.7765 - val_loss: 104.3758 - val_mse: 104.3758 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.0164 - mse: 14.0164\n",
      "Epoch 82: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 611ms/step - loss: 14.0164 - mse: 14.0164 - val_loss: 105.1530 - val_mse: 105.1530 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.1527 - mse: 12.1527\n",
      "Epoch 83: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 610ms/step - loss: 12.1527 - mse: 12.1527 - val_loss: 104.9258 - val_mse: 104.9258 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.1754 - mse: 12.1754\n",
      "Epoch 84: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 626ms/step - loss: 12.1754 - mse: 12.1754 - val_loss: 104.4240 - val_mse: 104.4240 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.8816 - mse: 11.8816\n",
      "Epoch 85: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 61s 639ms/step - loss: 11.8816 - mse: 11.8816 - val_loss: 104.5146 - val_mse: 104.5146 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.2500 - mse: 14.2500\n",
      "Epoch 86: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 58s 612ms/step - loss: 14.2500 - mse: 14.2500 - val_loss: 103.9974 - val_mse: 103.9974 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.6194 - mse: 14.6194\n",
      "Epoch 87: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 628ms/step - loss: 14.6194 - mse: 14.6194 - val_loss: 104.6852 - val_mse: 104.6852 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.9437 - mse: 11.9437\n",
      "Epoch 88: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 11.9437 - mse: 11.9437 - val_loss: 104.3689 - val_mse: 104.3689 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.0461 - mse: 14.0461\n",
      "Epoch 89: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 622ms/step - loss: 14.0461 - mse: 14.0461 - val_loss: 105.4314 - val_mse: 105.4314 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.1644 - mse: 12.1644\n",
      "Epoch 90: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 621ms/step - loss: 12.1644 - mse: 12.1644 - val_loss: 104.8456 - val_mse: 104.8456 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.0758 - mse: 13.0758\n",
      "Epoch 91: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 13.0758 - mse: 13.0758 - val_loss: 104.8320 - val_mse: 104.8320 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.5555 - mse: 13.5555\n",
      "Epoch 92: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 13.5555 - mse: 13.5555 - val_loss: 104.7345 - val_mse: 104.7345 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.1959 - mse: 13.1959\n",
      "Epoch 93: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 621ms/step - loss: 13.1959 - mse: 13.1959 - val_loss: 105.6297 - val_mse: 105.6297 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.6363 - mse: 12.6363\n",
      "Epoch 94: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 627ms/step - loss: 12.6363 - mse: 12.6363 - val_loss: 105.9598 - val_mse: 105.9598 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.8382 - mse: 11.8382\n",
      "Epoch 95: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 634ms/step - loss: 11.8382 - mse: 11.8382 - val_loss: 105.0408 - val_mse: 105.0408 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.7632 - mse: 12.7632\n",
      "Epoch 96: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 59s 626ms/step - loss: 12.7632 - mse: 12.7632 - val_loss: 104.3774 - val_mse: 104.3774 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.1031 - mse: 12.1031\n",
      "Epoch 97: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 12.1031 - mse: 12.1031 - val_loss: 104.9496 - val_mse: 104.9496 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.1541 - mse: 13.1541\n",
      "Epoch 98: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 627ms/step - loss: 13.1541 - mse: 13.1541 - val_loss: 105.3343 - val_mse: 105.3343 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9730 - mse: 12.9730\n",
      "Epoch 99: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 12.9730 - mse: 12.9730 - val_loss: 106.1555 - val_mse: 106.1555 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9353 - mse: 12.9353\n",
      "Epoch 100: val_loss did not improve from 102.40417\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 12.9353 - mse: 12.9353 - val_loss: 104.1664 - val_mse: 104.1664 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 05:34:26.818603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 5341.8101 - mse: 5341.8101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 05:35:25.822337: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 7956.88232, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 65s 651ms/step - loss: 5341.8101 - mse: 5341.8101 - val_loss: 7956.8823 - val_mse: 7956.8823 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 586.3589 - mse: 586.3589\n",
      "Epoch 2: val_loss did not improve from 7956.88232\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 586.3589 - mse: 586.3589 - val_loss: 8321.2764 - val_mse: 8321.2764 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 290.4094 - mse: 290.4094\n",
      "Epoch 3: val_loss improved from 7956.88232 to 7483.13330, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 60s 634ms/step - loss: 290.4094 - mse: 290.4094 - val_loss: 7483.1333 - val_mse: 7483.1333 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 224.7766 - mse: 224.7766\n",
      "Epoch 4: val_loss improved from 7483.13330 to 4912.07568, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 61s 643ms/step - loss: 224.7766 - mse: 224.7766 - val_loss: 4912.0757 - val_mse: 4912.0757 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 189.2631 - mse: 189.2631\n",
      "Epoch 5: val_loss improved from 4912.07568 to 3141.62646, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 61s 644ms/step - loss: 189.2631 - mse: 189.2631 - val_loss: 3141.6265 - val_mse: 3141.6265 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 195.1086 - mse: 195.1086\n",
      "Epoch 6: val_loss improved from 3141.62646 to 1774.48999, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 60s 634ms/step - loss: 195.1086 - mse: 195.1086 - val_loss: 1774.4900 - val_mse: 1774.4900 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 144.4405 - mse: 144.4405\n",
      "Epoch 7: val_loss improved from 1774.48999 to 989.33167, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 62s 648ms/step - loss: 144.4405 - mse: 144.4405 - val_loss: 989.3317 - val_mse: 989.3317 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 173.2520 - mse: 173.2520\n",
      "Epoch 8: val_loss improved from 989.33167 to 431.07074, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 173.2520 - mse: 173.2520 - val_loss: 431.0707 - val_mse: 431.0707 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 132.0449 - mse: 132.0449\n",
      "Epoch 9: val_loss improved from 431.07074 to 107.65816, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 62s 647ms/step - loss: 132.0449 - mse: 132.0449 - val_loss: 107.6582 - val_mse: 107.6582 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 97.1398 - mse: 97.1398\n",
      "Epoch 10: val_loss did not improve from 107.65816\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 97.1398 - mse: 97.1398 - val_loss: 164.0945 - val_mse: 164.0945 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 131.5129 - mse: 131.5129\n",
      "Epoch 11: val_loss did not improve from 107.65816\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 131.5129 - mse: 131.5129 - val_loss: 135.0656 - val_mse: 135.0656 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 117.4291 - mse: 117.4291\n",
      "Epoch 12: val_loss improved from 107.65816 to 93.39188, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 62s 655ms/step - loss: 117.4291 - mse: 117.4291 - val_loss: 93.3919 - val_mse: 93.3919 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 91.5496 - mse: 91.5496\n",
      "Epoch 13: val_loss did not improve from 93.39188\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 91.5496 - mse: 91.5496 - val_loss: 120.1101 - val_mse: 120.1101 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 107.2535 - mse: 107.2535\n",
      "Epoch 14: val_loss did not improve from 93.39188\n",
      "95/95 [==============================] - 62s 649ms/step - loss: 107.2535 - mse: 107.2535 - val_loss: 347.5763 - val_mse: 347.5763 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 109.8241 - mse: 109.8241\n",
      "Epoch 15: val_loss did not improve from 93.39188\n",
      "95/95 [==============================] - 61s 646ms/step - loss: 109.8241 - mse: 109.8241 - val_loss: 125.9724 - val_mse: 125.9724 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 145.4050 - mse: 145.4050\n",
      "Epoch 16: val_loss improved from 93.39188 to 83.97656, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 61s 636ms/step - loss: 145.4050 - mse: 145.4050 - val_loss: 83.9766 - val_mse: 83.9766 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 118.5983 - mse: 118.5983\n",
      "Epoch 17: val_loss did not improve from 83.97656\n",
      "95/95 [==============================] - 62s 648ms/step - loss: 118.5983 - mse: 118.5983 - val_loss: 113.4030 - val_mse: 113.4030 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 80.0963 - mse: 80.0963\n",
      "Epoch 18: val_loss did not improve from 83.97656\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 80.0963 - mse: 80.0963 - val_loss: 163.4552 - val_mse: 163.4552 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 72.0221 - mse: 72.0221\n",
      "Epoch 19: val_loss improved from 83.97656 to 76.96198, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 63s 659ms/step - loss: 72.0221 - mse: 72.0221 - val_loss: 76.9620 - val_mse: 76.9620 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 57.9612 - mse: 57.9612\n",
      "Epoch 20: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 61s 641ms/step - loss: 57.9612 - mse: 57.9612 - val_loss: 88.6955 - val_mse: 88.6955 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 65.9544 - mse: 65.9544\n",
      "Epoch 21: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 61s 640ms/step - loss: 65.9544 - mse: 65.9544 - val_loss: 102.1436 - val_mse: 102.1436 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 114.0629 - mse: 114.0629\n",
      "Epoch 22: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 114.0629 - mse: 114.0629 - val_loss: 138.4503 - val_mse: 138.4503 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 53.6934 - mse: 53.6934\n",
      "Epoch 23: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 53.6934 - mse: 53.6934 - val_loss: 100.8154 - val_mse: 100.8154 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 65.7113 - mse: 65.7113\n",
      "Epoch 24: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 65.7113 - mse: 65.7113 - val_loss: 91.0573 - val_mse: 91.0573 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 74.1238 - mse: 74.1238\n",
      "Epoch 25: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 62s 654ms/step - loss: 74.1238 - mse: 74.1238 - val_loss: 84.3385 - val_mse: 84.3385 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 84.3442 - mse: 84.3442\n",
      "Epoch 26: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 84.3442 - mse: 84.3442 - val_loss: 108.4161 - val_mse: 108.4161 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 48.6108 - mse: 48.6108\n",
      "Epoch 27: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 60s 632ms/step - loss: 48.6108 - mse: 48.6108 - val_loss: 97.8672 - val_mse: 97.8672 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 47.7747 - mse: 47.7747\n",
      "Epoch 28: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 47.7747 - mse: 47.7747 - val_loss: 83.2124 - val_mse: 83.2124 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 50.1264 - mse: 50.1264\n",
      "Epoch 29: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 50.1264 - mse: 50.1264 - val_loss: 79.3388 - val_mse: 79.3388 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.4033 - mse: 30.4033\n",
      "Epoch 30: val_loss did not improve from 76.96198\n",
      "95/95 [==============================] - 62s 647ms/step - loss: 30.4033 - mse: 30.4033 - val_loss: 81.4711 - val_mse: 81.4711 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 29.3077 - mse: 29.3077\n",
      "Epoch 31: val_loss improved from 76.96198 to 76.85040, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 62s 649ms/step - loss: 29.3077 - mse: 29.3077 - val_loss: 76.8504 - val_mse: 76.8504 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.2644 - mse: 26.2644\n",
      "Epoch 32: val_loss did not improve from 76.85040\n",
      "95/95 [==============================] - 61s 639ms/step - loss: 26.2644 - mse: 26.2644 - val_loss: 77.9224 - val_mse: 77.9224 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.0537 - mse: 24.0537\n",
      "Epoch 33: val_loss improved from 76.85040 to 75.14210, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 24.0537 - mse: 24.0537 - val_loss: 75.1421 - val_mse: 75.1421 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.5222 - mse: 23.5222\n",
      "Epoch 34: val_loss did not improve from 75.14210\n",
      "95/95 [==============================] - 62s 647ms/step - loss: 23.5222 - mse: 23.5222 - val_loss: 75.2461 - val_mse: 75.2461 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 25.5073 - mse: 25.5073\n",
      "Epoch 35: val_loss did not improve from 75.14210\n",
      "95/95 [==============================] - 61s 639ms/step - loss: 25.5073 - mse: 25.5073 - val_loss: 75.1913 - val_mse: 75.1913 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.8599 - mse: 21.8599\n",
      "Epoch 36: val_loss improved from 75.14210 to 74.65452, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 62s 650ms/step - loss: 21.8599 - mse: 21.8599 - val_loss: 74.6545 - val_mse: 74.6545 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.0603 - mse: 24.0603\n",
      "Epoch 37: val_loss did not improve from 74.65452\n",
      "95/95 [==============================] - 62s 648ms/step - loss: 24.0603 - mse: 24.0603 - val_loss: 74.8893 - val_mse: 74.8893 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 23.1804 - mse: 23.1804\n",
      "Epoch 38: val_loss improved from 74.65452 to 74.28600, saving model to E-scale2/E2-scale_run7.h5\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 23.1804 - mse: 23.1804 - val_loss: 74.2860 - val_mse: 74.2860 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.8139 - mse: 24.8139\n",
      "Epoch 39: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 62s 649ms/step - loss: 24.8139 - mse: 24.8139 - val_loss: 75.0544 - val_mse: 75.0544 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.0169 - mse: 26.0169\n",
      "Epoch 40: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 62s 649ms/step - loss: 26.0169 - mse: 26.0169 - val_loss: 75.9731 - val_mse: 75.9731 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.3117 - mse: 19.3117\n",
      "Epoch 41: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 19.3117 - mse: 19.3117 - val_loss: 75.8011 - val_mse: 75.8011 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.7952 - mse: 19.7952\n",
      "Epoch 42: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 62s 652ms/step - loss: 19.7952 - mse: 19.7952 - val_loss: 75.3590 - val_mse: 75.3590 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.7961 - mse: 18.7961\n",
      "Epoch 43: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 62s 650ms/step - loss: 18.7961 - mse: 18.7961 - val_loss: 76.0632 - val_mse: 76.0632 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.7760 - mse: 19.7760\n",
      "Epoch 44: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 19.7760 - mse: 19.7760 - val_loss: 75.8372 - val_mse: 75.8372 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.0503 - mse: 21.0503\n",
      "Epoch 45: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 645ms/step - loss: 21.0503 - mse: 21.0503 - val_loss: 76.6222 - val_mse: 76.6222 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.4066 - mse: 20.4066\n",
      "Epoch 46: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 62s 650ms/step - loss: 20.4066 - mse: 20.4066 - val_loss: 75.7935 - val_mse: 75.7935 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.2996 - mse: 21.2996\n",
      "Epoch 47: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 21.2996 - mse: 21.2996 - val_loss: 77.1560 - val_mse: 77.1560 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.1630 - mse: 17.1630\n",
      "Epoch 48: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 634ms/step - loss: 17.1630 - mse: 17.1630 - val_loss: 76.8150 - val_mse: 76.8150 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.5445 - mse: 15.5445\n",
      "Epoch 49: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 15.5445 - mse: 15.5445 - val_loss: 76.4905 - val_mse: 76.4905 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.3437 - mse: 16.3437\n",
      "Epoch 50: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 16.3437 - mse: 16.3437 - val_loss: 76.4400 - val_mse: 76.4400 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.1040 - mse: 17.1040\n",
      "Epoch 51: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 628ms/step - loss: 17.1040 - mse: 17.1040 - val_loss: 76.8425 - val_mse: 76.8425 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.9922 - mse: 15.9922\n",
      "Epoch 52: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 15.9922 - mse: 15.9922 - val_loss: 76.5353 - val_mse: 76.5353 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.1594 - mse: 19.1594\n",
      "Epoch 53: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 19.1594 - mse: 19.1594 - val_loss: 76.1693 - val_mse: 76.1693 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.9365 - mse: 15.9365\n",
      "Epoch 54: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 15.9365 - mse: 15.9365 - val_loss: 76.2908 - val_mse: 76.2908 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.4695 - mse: 16.4695\n",
      "Epoch 55: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 53s 553ms/step - loss: 16.4695 - mse: 16.4695 - val_loss: 76.3146 - val_mse: 76.3146 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.7450 - mse: 19.7450\n",
      "Epoch 56: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 59s 618ms/step - loss: 19.7450 - mse: 19.7450 - val_loss: 76.5771 - val_mse: 76.5771 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2203 - mse: 15.2203\n",
      "Epoch 57: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 15.2203 - mse: 15.2203 - val_loss: 76.3793 - val_mse: 76.3793 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.8694 - mse: 15.8694\n",
      "Epoch 58: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 636ms/step - loss: 15.8694 - mse: 15.8694 - val_loss: 76.5614 - val_mse: 76.5614 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.9669 - mse: 18.9669\n",
      "Epoch 59: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 18.9669 - mse: 18.9669 - val_loss: 77.0187 - val_mse: 77.0187 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2963 - mse: 15.2963\n",
      "Epoch 60: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 15.2963 - mse: 15.2963 - val_loss: 76.4756 - val_mse: 76.4756 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.7006 - mse: 15.7006\n",
      "Epoch 61: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 15.7006 - mse: 15.7006 - val_loss: 76.3627 - val_mse: 76.3627 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 20.9790 - mse: 20.9790\n",
      "Epoch 62: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 20.9790 - mse: 20.9790 - val_loss: 76.1162 - val_mse: 76.1162 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.0775 - mse: 18.0775\n",
      "Epoch 63: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 59s 626ms/step - loss: 18.0775 - mse: 18.0775 - val_loss: 76.1968 - val_mse: 76.1968 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.8617 - mse: 16.8617\n",
      "Epoch 64: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 16.8617 - mse: 16.8617 - val_loss: 76.9622 - val_mse: 76.9622 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.6958 - mse: 16.6958\n",
      "Epoch 65: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 16.6958 - mse: 16.6958 - val_loss: 76.3762 - val_mse: 76.3762 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.4667 - mse: 15.4667\n",
      "Epoch 66: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 15.4667 - mse: 15.4667 - val_loss: 76.3644 - val_mse: 76.3644 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.3698 - mse: 16.3698\n",
      "Epoch 67: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 16.3698 - mse: 16.3698 - val_loss: 77.4219 - val_mse: 77.4219 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.6908 - mse: 16.6908\n",
      "Epoch 68: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 643ms/step - loss: 16.6908 - mse: 16.6908 - val_loss: 76.7376 - val_mse: 76.7376 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.0631 - mse: 15.0631\n",
      "Epoch 69: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 628ms/step - loss: 15.0631 - mse: 15.0631 - val_loss: 76.7251 - val_mse: 76.7251 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.4025 - mse: 17.4025\n",
      "Epoch 70: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 17.4025 - mse: 17.4025 - val_loss: 76.4455 - val_mse: 76.4455 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.6229 - mse: 16.6229\n",
      "Epoch 71: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 630ms/step - loss: 16.6229 - mse: 16.6229 - val_loss: 77.0478 - val_mse: 77.0478 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.3246 - mse: 17.3246\n",
      "Epoch 72: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 17.3246 - mse: 17.3246 - val_loss: 77.1904 - val_mse: 77.1904 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.6356 - mse: 18.6356\n",
      "Epoch 73: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 18.6356 - mse: 18.6356 - val_loss: 76.7527 - val_mse: 76.7527 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.9718 - mse: 15.9718\n",
      "Epoch 74: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 15.9718 - mse: 15.9718 - val_loss: 77.1017 - val_mse: 77.1017 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 18.3158 - mse: 18.3158\n",
      "Epoch 75: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 636ms/step - loss: 18.3158 - mse: 18.3158 - val_loss: 77.2462 - val_mse: 77.2462 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.3022 - mse: 16.3022\n",
      "Epoch 76: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 16.3022 - mse: 16.3022 - val_loss: 76.5358 - val_mse: 76.5358 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.8391 - mse: 14.8391\n",
      "Epoch 77: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 627ms/step - loss: 14.8391 - mse: 14.8391 - val_loss: 76.9659 - val_mse: 76.9659 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.4114 - mse: 14.4114\n",
      "Epoch 78: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 628ms/step - loss: 14.4114 - mse: 14.4114 - val_loss: 77.1898 - val_mse: 77.1898 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 17.2878 - mse: 17.2878\n",
      "Epoch 79: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 17.2878 - mse: 17.2878 - val_loss: 78.2869 - val_mse: 78.2869 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.6918 - mse: 16.6918\n",
      "Epoch 80: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 16.6918 - mse: 16.6918 - val_loss: 76.8557 - val_mse: 76.8557 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2016 - mse: 15.2016\n",
      "Epoch 81: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 627ms/step - loss: 15.2016 - mse: 15.2016 - val_loss: 78.1788 - val_mse: 78.1788 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2367 - mse: 15.2367\n",
      "Epoch 82: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 15.2367 - mse: 15.2367 - val_loss: 77.0904 - val_mse: 77.0904 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.9335 - mse: 15.9335\n",
      "Epoch 83: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 626ms/step - loss: 15.9335 - mse: 15.9335 - val_loss: 77.1870 - val_mse: 77.1870 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.5692 - mse: 16.5692\n",
      "Epoch 84: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 645ms/step - loss: 16.5692 - mse: 16.5692 - val_loss: 77.3957 - val_mse: 77.3957 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.1406 - mse: 16.1406\n",
      "Epoch 85: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 634ms/step - loss: 16.1406 - mse: 16.1406 - val_loss: 77.5802 - val_mse: 77.5802 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.4514 - mse: 13.4514\n",
      "Epoch 86: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 632ms/step - loss: 13.4514 - mse: 13.4514 - val_loss: 77.1359 - val_mse: 77.1359 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.3945 - mse: 14.3945\n",
      "Epoch 87: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 625ms/step - loss: 14.3945 - mse: 14.3945 - val_loss: 77.1331 - val_mse: 77.1331 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.9308 - mse: 13.9308\n",
      "Epoch 88: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 628ms/step - loss: 13.9308 - mse: 13.9308 - val_loss: 77.1361 - val_mse: 77.1361 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.7740 - mse: 14.7740\n",
      "Epoch 89: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 638ms/step - loss: 14.7740 - mse: 14.7740 - val_loss: 77.3029 - val_mse: 77.3029 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.7511 - mse: 14.7511\n",
      "Epoch 90: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 14.7511 - mse: 14.7511 - val_loss: 77.0493 - val_mse: 77.0493 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.4336 - mse: 13.4336\n",
      "Epoch 91: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 13.4336 - mse: 13.4336 - val_loss: 77.3933 - val_mse: 77.3933 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.3276 - mse: 13.3276\n",
      "Epoch 92: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 640ms/step - loss: 13.3276 - mse: 13.3276 - val_loss: 77.0901 - val_mse: 77.0901 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.2964 - mse: 14.2964\n",
      "Epoch 93: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 633ms/step - loss: 14.2964 - mse: 14.2964 - val_loss: 77.3858 - val_mse: 77.3858 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.4261 - mse: 13.4261\n",
      "Epoch 94: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 13.4261 - mse: 13.4261 - val_loss: 77.4539 - val_mse: 77.4539 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.2285 - mse: 14.2285\n",
      "Epoch 95: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 637ms/step - loss: 14.2285 - mse: 14.2285 - val_loss: 77.3745 - val_mse: 77.3745 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.3300 - mse: 16.3300\n",
      "Epoch 96: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 61s 641ms/step - loss: 16.3300 - mse: 16.3300 - val_loss: 79.4768 - val_mse: 79.4768 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.8132 - mse: 15.8132\n",
      "Epoch 97: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 635ms/step - loss: 15.8132 - mse: 15.8132 - val_loss: 78.3350 - val_mse: 78.3350 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.1372 - mse: 14.1372\n",
      "Epoch 98: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 631ms/step - loss: 14.1372 - mse: 14.1372 - val_loss: 77.4334 - val_mse: 77.4334 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.7157 - mse: 12.7157\n",
      "Epoch 99: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 629ms/step - loss: 12.7157 - mse: 12.7157 - val_loss: 77.5092 - val_mse: 77.5092 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.1413 - mse: 14.1413\n",
      "Epoch 100: val_loss did not improve from 74.28600\n",
      "95/95 [==============================] - 60s 632ms/step - loss: 14.1413 - mse: 14.1413 - val_loss: 77.4841 - val_mse: 77.4841 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 07:15:36.428683: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 5156.8867 - mse: 5156.8867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 07:16:35.391401: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 7782.07568, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 69s 666ms/step - loss: 5156.8867 - mse: 5156.8867 - val_loss: 7782.0757 - val_mse: 7782.0757 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 449.6926 - mse: 449.6926\n",
      "Epoch 2: val_loss improved from 7782.07568 to 7047.91992, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 59s 625ms/step - loss: 449.6926 - mse: 449.6926 - val_loss: 7047.9199 - val_mse: 7047.9199 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 341.0695 - mse: 341.0695\n",
      "Epoch 3: val_loss improved from 7047.91992 to 5633.30518, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 59s 616ms/step - loss: 341.0695 - mse: 341.0695 - val_loss: 5633.3052 - val_mse: 5633.3052 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 267.3617 - mse: 267.3617\n",
      "Epoch 4: val_loss improved from 5633.30518 to 4694.77783, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 267.3617 - mse: 267.3617 - val_loss: 4694.7778 - val_mse: 4694.7778 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 190.3903 - mse: 190.3903\n",
      "Epoch 5: val_loss improved from 4694.77783 to 3579.74585, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 190.3903 - mse: 190.3903 - val_loss: 3579.7458 - val_mse: 3579.7458 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 152.5732 - mse: 152.5732\n",
      "Epoch 6: val_loss improved from 3579.74585 to 1773.22339, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 152.5732 - mse: 152.5732 - val_loss: 1773.2234 - val_mse: 1773.2234 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 157.2963 - mse: 157.2963\n",
      "Epoch 7: val_loss improved from 1773.22339 to 805.50732, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 57s 605ms/step - loss: 157.2963 - mse: 157.2963 - val_loss: 805.5073 - val_mse: 805.5073 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 166.5562 - mse: 166.5562\n",
      "Epoch 8: val_loss improved from 805.50732 to 453.42062, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 59s 618ms/step - loss: 166.5562 - mse: 166.5562 - val_loss: 453.4206 - val_mse: 453.4206 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 128.1327 - mse: 128.1327\n",
      "Epoch 9: val_loss improved from 453.42062 to 146.07761, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 128.1327 - mse: 128.1327 - val_loss: 146.0776 - val_mse: 146.0776 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 104.4324 - mse: 104.4324\n",
      "Epoch 10: val_loss improved from 146.07761 to 104.39818, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 59s 623ms/step - loss: 104.4324 - mse: 104.4324 - val_loss: 104.3982 - val_mse: 104.3982 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 110.4632 - mse: 110.4632\n",
      "Epoch 11: val_loss improved from 104.39818 to 94.47274, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 59s 619ms/step - loss: 110.4632 - mse: 110.4632 - val_loss: 94.4727 - val_mse: 94.4727 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 145.8242 - mse: 145.8242\n",
      "Epoch 12: val_loss did not improve from 94.47274\n",
      "95/95 [==============================] - 59s 617ms/step - loss: 145.8242 - mse: 145.8242 - val_loss: 137.6425 - val_mse: 137.6425 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 92.4414 - mse: 92.4414\n",
      "Epoch 13: val_loss did not improve from 94.47274\n",
      "95/95 [==============================] - 58s 610ms/step - loss: 92.4414 - mse: 92.4414 - val_loss: 205.2422 - val_mse: 205.2422 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 112.7703 - mse: 112.7703\n",
      "Epoch 14: val_loss did not improve from 94.47274\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 112.7703 - mse: 112.7703 - val_loss: 99.6416 - val_mse: 99.6416 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 106.5004 - mse: 106.5004\n",
      "Epoch 15: val_loss did not improve from 94.47274\n",
      "95/95 [==============================] - 58s 608ms/step - loss: 106.5004 - mse: 106.5004 - val_loss: 137.1866 - val_mse: 137.1866 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 101.9640 - mse: 101.9640\n",
      "Epoch 16: val_loss did not improve from 94.47274\n",
      "95/95 [==============================] - 59s 617ms/step - loss: 101.9640 - mse: 101.9640 - val_loss: 101.5708 - val_mse: 101.5708 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 93.1108 - mse: 93.1108\n",
      "Epoch 17: val_loss did not improve from 94.47274\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 93.1108 - mse: 93.1108 - val_loss: 130.5449 - val_mse: 130.5449 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 129.4653 - mse: 129.4653\n",
      "Epoch 18: val_loss improved from 94.47274 to 93.62007, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 58s 615ms/step - loss: 129.4653 - mse: 129.4653 - val_loss: 93.6201 - val_mse: 93.6201 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 139.5656 - mse: 139.5656\n",
      "Epoch 19: val_loss did not improve from 93.62007\n",
      "95/95 [==============================] - 59s 624ms/step - loss: 139.5656 - mse: 139.5656 - val_loss: 108.2172 - val_mse: 108.2172 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 76.8680 - mse: 76.8680\n",
      "Epoch 20: val_loss did not improve from 93.62007\n",
      "95/95 [==============================] - 59s 623ms/step - loss: 76.8680 - mse: 76.8680 - val_loss: 143.6756 - val_mse: 143.6756 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 63.8044 - mse: 63.8044\n",
      "Epoch 21: val_loss did not improve from 93.62007\n",
      "95/95 [==============================] - 59s 621ms/step - loss: 63.8044 - mse: 63.8044 - val_loss: 271.8724 - val_mse: 271.8724 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 105.5574 - mse: 105.5574\n",
      "Epoch 22: val_loss did not improve from 93.62007\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 105.5574 - mse: 105.5574 - val_loss: 113.4467 - val_mse: 113.4467 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 74.9438 - mse: 74.9438\n",
      "Epoch 23: val_loss improved from 93.62007 to 91.10120, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 59s 620ms/step - loss: 74.9438 - mse: 74.9438 - val_loss: 91.1012 - val_mse: 91.1012 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 71.5693 - mse: 71.5693\n",
      "Epoch 24: val_loss did not improve from 91.10120\n",
      "95/95 [==============================] - 58s 609ms/step - loss: 71.5693 - mse: 71.5693 - val_loss: 140.5301 - val_mse: 140.5301 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 58.9802 - mse: 58.9802\n",
      "Epoch 25: val_loss did not improve from 91.10120\n",
      "95/95 [==============================] - 59s 617ms/step - loss: 58.9802 - mse: 58.9802 - val_loss: 92.2660 - val_mse: 92.2660 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 49.4633 - mse: 49.4633\n",
      "Epoch 26: val_loss improved from 91.10120 to 89.05053, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 58s 614ms/step - loss: 49.4633 - mse: 49.4633 - val_loss: 89.0505 - val_mse: 89.0505 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 45.6491 - mse: 45.6491\n",
      "Epoch 27: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 59s 622ms/step - loss: 45.6491 - mse: 45.6491 - val_loss: 787.8872 - val_mse: 787.8872 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 163.5910 - mse: 163.5910\n",
      "Epoch 28: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 58s 613ms/step - loss: 163.5910 - mse: 163.5910 - val_loss: 292.3132 - val_mse: 292.3132 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 93.2763 - mse: 93.2763\n",
      "Epoch 29: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 43s 447ms/step - loss: 93.2763 - mse: 93.2763 - val_loss: 97.9458 - val_mse: 97.9458 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 43.8466 - mse: 43.8466\n",
      "Epoch 30: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 307ms/step - loss: 43.8466 - mse: 43.8466 - val_loss: 111.2418 - val_mse: 111.2418 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 36.1755 - mse: 36.1755\n",
      "Epoch 31: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 36.1755 - mse: 36.1755 - val_loss: 119.7198 - val_mse: 119.7198 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 31.8104 - mse: 31.8104\n",
      "Epoch 32: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 31.8104 - mse: 31.8104 - val_loss: 95.2762 - val_mse: 95.2762 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.9418 - mse: 27.9418\n",
      "Epoch 33: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 27.9418 - mse: 27.9418 - val_loss: 96.1983 - val_mse: 96.1983 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.8678 - mse: 24.8678\n",
      "Epoch 34: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 24.8678 - mse: 24.8678 - val_loss: 100.3876 - val_mse: 100.3876 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 22.9505 - mse: 22.9505\n",
      "Epoch 35: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 22.9505 - mse: 22.9505 - val_loss: 96.2248 - val_mse: 96.2248 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.5465 - mse: 24.5465\n",
      "Epoch 36: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 24.5465 - mse: 24.5465 - val_loss: 90.9154 - val_mse: 90.9154 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.9518 - mse: 16.9518\n",
      "Epoch 37: val_loss did not improve from 89.05053\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 16.9518 - mse: 16.9518 - val_loss: 90.3536 - val_mse: 90.3536 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.2965 - mse: 15.2965\n",
      "Epoch 38: val_loss improved from 89.05053 to 88.23651, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 15.2965 - mse: 15.2965 - val_loss: 88.2365 - val_mse: 88.2365 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.1679 - mse: 14.1679\n",
      "Epoch 39: val_loss improved from 88.23651 to 87.68893, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 14.1679 - mse: 14.1679 - val_loss: 87.6889 - val_mse: 87.6889 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.6568 - mse: 13.6568\n",
      "Epoch 40: val_loss did not improve from 87.68893\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 13.6568 - mse: 13.6568 - val_loss: 88.4193 - val_mse: 88.4193 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.1759 - mse: 13.1759\n",
      "Epoch 41: val_loss did not improve from 87.68893\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 13.1759 - mse: 13.1759 - val_loss: 88.0958 - val_mse: 88.0958 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.8677 - mse: 12.8677\n",
      "Epoch 42: val_loss improved from 87.68893 to 87.55260, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 12.8677 - mse: 12.8677 - val_loss: 87.5526 - val_mse: 87.5526 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.6114 - mse: 12.6114\n",
      "Epoch 43: val_loss did not improve from 87.55260\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 12.6114 - mse: 12.6114 - val_loss: 88.1018 - val_mse: 88.1018 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.3381 - mse: 12.3381\n",
      "Epoch 44: val_loss did not improve from 87.55260\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 12.3381 - mse: 12.3381 - val_loss: 87.9516 - val_mse: 87.9516 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.1187 - mse: 12.1187\n",
      "Epoch 45: val_loss did not improve from 87.55260\n",
      "95/95 [==============================] - 29s 307ms/step - loss: 12.1187 - mse: 12.1187 - val_loss: 88.0510 - val_mse: 88.0510 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.8436 - mse: 11.8436\n",
      "Epoch 46: val_loss did not improve from 87.55260\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 11.8436 - mse: 11.8436 - val_loss: 87.6290 - val_mse: 87.6290 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.5075 - mse: 11.5075\n",
      "Epoch 47: val_loss improved from 87.55260 to 86.89801, saving model to E-scale2/E2-scale_run8.h5\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 11.5075 - mse: 11.5075 - val_loss: 86.8980 - val_mse: 86.8980 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.3843 - mse: 11.3843\n",
      "Epoch 48: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 11.3843 - mse: 11.3843 - val_loss: 87.6643 - val_mse: 87.6643 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.1152 - mse: 11.1152\n",
      "Epoch 49: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 11.1152 - mse: 11.1152 - val_loss: 87.0792 - val_mse: 87.0792 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.0080 - mse: 11.0080\n",
      "Epoch 50: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 11.0080 - mse: 11.0080 - val_loss: 87.3670 - val_mse: 87.3670 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.7580 - mse: 10.7580\n",
      "Epoch 51: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 10.7580 - mse: 10.7580 - val_loss: 87.5865 - val_mse: 87.5865 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.6496 - mse: 10.6496\n",
      "Epoch 52: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 10.6496 - mse: 10.6496 - val_loss: 88.2628 - val_mse: 88.2628 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.3861 - mse: 10.3861\n",
      "Epoch 53: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 10.3861 - mse: 10.3861 - val_loss: 87.9911 - val_mse: 87.9911 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.3090 - mse: 10.3090\n",
      "Epoch 54: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 10.3090 - mse: 10.3090 - val_loss: 89.3613 - val_mse: 89.3613 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.3133 - mse: 10.3133\n",
      "Epoch 55: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 10.3133 - mse: 10.3133 - val_loss: 87.9198 - val_mse: 87.9198 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.9857 - mse: 9.9857\n",
      "Epoch 56: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 9.9857 - mse: 9.9857 - val_loss: 87.1780 - val_mse: 87.1780 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.6159 - mse: 9.6159\n",
      "Epoch 57: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 302ms/step - loss: 9.6159 - mse: 9.6159 - val_loss: 87.7525 - val_mse: 87.7525 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.0977 - mse: 9.0977\n",
      "Epoch 58: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 9.0977 - mse: 9.0977 - val_loss: 87.6944 - val_mse: 87.6944 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.0473 - mse: 9.0473\n",
      "Epoch 59: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 9.0473 - mse: 9.0473 - val_loss: 87.8502 - val_mse: 87.8502 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.0038 - mse: 9.0038\n",
      "Epoch 60: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 9.0038 - mse: 9.0038 - val_loss: 87.8347 - val_mse: 87.8347 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.0141 - mse: 9.0141\n",
      "Epoch 61: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 9.0141 - mse: 9.0141 - val_loss: 87.9507 - val_mse: 87.9507 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.9576 - mse: 8.9576\n",
      "Epoch 62: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.9576 - mse: 8.9576 - val_loss: 87.9242 - val_mse: 87.9242 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.9906 - mse: 8.9906\n",
      "Epoch 63: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.9906 - mse: 8.9906 - val_loss: 87.9273 - val_mse: 87.9273 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.0006 - mse: 9.0006\n",
      "Epoch 64: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 9.0006 - mse: 9.0006 - val_loss: 87.8740 - val_mse: 87.8740 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.9852 - mse: 8.9852\n",
      "Epoch 65: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.9852 - mse: 8.9852 - val_loss: 87.8928 - val_mse: 87.8928 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.9128 - mse: 8.9128\n",
      "Epoch 66: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.9128 - mse: 8.9128 - val_loss: 87.8641 - val_mse: 87.8641 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.9358 - mse: 8.9358\n",
      "Epoch 67: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.9358 - mse: 8.9358 - val_loss: 88.1318 - val_mse: 88.1318 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.8597 - mse: 8.8597\n",
      "Epoch 68: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.8597 - mse: 8.8597 - val_loss: 87.8898 - val_mse: 87.8898 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.8158 - mse: 8.8158\n",
      "Epoch 69: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.8158 - mse: 8.8158 - val_loss: 88.1232 - val_mse: 88.1232 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.7976 - mse: 8.7976\n",
      "Epoch 70: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.7976 - mse: 8.7976 - val_loss: 87.9672 - val_mse: 87.9672 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.7821 - mse: 8.7821\n",
      "Epoch 71: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.7821 - mse: 8.7821 - val_loss: 88.1792 - val_mse: 88.1792 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.7611 - mse: 8.7611\n",
      "Epoch 72: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.7611 - mse: 8.7611 - val_loss: 88.1312 - val_mse: 88.1312 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.7626 - mse: 8.7626\n",
      "Epoch 73: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.7626 - mse: 8.7626 - val_loss: 88.3027 - val_mse: 88.3027 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.6687 - mse: 8.6687\n",
      "Epoch 74: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.6687 - mse: 8.6687 - val_loss: 88.3913 - val_mse: 88.3913 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.7049 - mse: 8.7049\n",
      "Epoch 75: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.7049 - mse: 8.7049 - val_loss: 88.3745 - val_mse: 88.3745 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.6338 - mse: 8.6338\n",
      "Epoch 76: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 8.6338 - mse: 8.6338 - val_loss: 88.3148 - val_mse: 88.3148 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.5934 - mse: 8.5934\n",
      "Epoch 77: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.5934 - mse: 8.5934 - val_loss: 88.3830 - val_mse: 88.3830 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.5667 - mse: 8.5667\n",
      "Epoch 78: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.5667 - mse: 8.5667 - val_loss: 88.6219 - val_mse: 88.6219 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.5654 - mse: 8.5654\n",
      "Epoch 79: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 308ms/step - loss: 8.5654 - mse: 8.5654 - val_loss: 88.4831 - val_mse: 88.4831 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4674 - mse: 8.4674\n",
      "Epoch 80: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.4674 - mse: 8.4674 - val_loss: 88.5418 - val_mse: 88.5418 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.5007 - mse: 8.5007\n",
      "Epoch 81: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.5007 - mse: 8.5007 - val_loss: 88.4233 - val_mse: 88.4233 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4661 - mse: 8.4661\n",
      "Epoch 82: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.4661 - mse: 8.4661 - val_loss: 88.6601 - val_mse: 88.6601 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4132 - mse: 8.4132\n",
      "Epoch 83: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.4132 - mse: 8.4132 - val_loss: 88.5313 - val_mse: 88.5313 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3852 - mse: 8.3852\n",
      "Epoch 84: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.3852 - mse: 8.3852 - val_loss: 88.6298 - val_mse: 88.6298 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4200 - mse: 8.4200\n",
      "Epoch 85: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.4200 - mse: 8.4200 - val_loss: 88.7352 - val_mse: 88.7352 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3114 - mse: 8.3114\n",
      "Epoch 86: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 8.3114 - mse: 8.3114 - val_loss: 88.7737 - val_mse: 88.7737 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2639 - mse: 8.2639\n",
      "Epoch 87: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.2639 - mse: 8.2639 - val_loss: 88.8280 - val_mse: 88.8280 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2416 - mse: 8.2416\n",
      "Epoch 88: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 8.2416 - mse: 8.2416 - val_loss: 88.8336 - val_mse: 88.8336 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2077 - mse: 8.2077\n",
      "Epoch 89: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 307ms/step - loss: 8.2077 - mse: 8.2077 - val_loss: 88.9772 - val_mse: 88.9772 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1347 - mse: 8.1347\n",
      "Epoch 90: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.1347 - mse: 8.1347 - val_loss: 88.8278 - val_mse: 88.8278 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0965 - mse: 8.0965\n",
      "Epoch 91: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.0965 - mse: 8.0965 - val_loss: 89.0691 - val_mse: 89.0691 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0848 - mse: 8.0848\n",
      "Epoch 92: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.0848 - mse: 8.0848 - val_loss: 88.9941 - val_mse: 88.9941 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0512 - mse: 8.0512\n",
      "Epoch 93: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.0512 - mse: 8.0512 - val_loss: 88.9208 - val_mse: 88.9208 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9855 - mse: 7.9855\n",
      "Epoch 94: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 7.9855 - mse: 7.9855 - val_loss: 88.9264 - val_mse: 88.9264 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9432 - mse: 7.9432\n",
      "Epoch 95: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 7.9432 - mse: 7.9432 - val_loss: 89.0080 - val_mse: 89.0080 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9214 - mse: 7.9214\n",
      "Epoch 96: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 7.9214 - mse: 7.9214 - val_loss: 88.8346 - val_mse: 88.8346 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8978 - mse: 7.8978\n",
      "Epoch 97: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 7.8978 - mse: 7.8978 - val_loss: 89.1132 - val_mse: 89.1132 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8454 - mse: 7.8454\n",
      "Epoch 98: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 7.8454 - mse: 7.8454 - val_loss: 89.1168 - val_mse: 89.1168 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8238 - mse: 7.8238\n",
      "Epoch 99: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 7.8238 - mse: 7.8238 - val_loss: 89.0660 - val_mse: 89.0660 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.7560 - mse: 7.7560\n",
      "Epoch 100: val_loss did not improve from 86.89801\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 7.7560 - mse: 7.7560 - val_loss: 89.3702 - val_mse: 89.3702 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 08:18:07.250131: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 6007.6606 - mse: 6007.6606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 08:18:39.016371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 7672.01074, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 35s 335ms/step - loss: 6007.6606 - mse: 6007.6606 - val_loss: 7672.0107 - val_mse: 7672.0107 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 455.1036 - mse: 455.1036\n",
      "Epoch 2: val_loss improved from 7672.01074 to 6883.49316, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 455.1036 - mse: 455.1036 - val_loss: 6883.4932 - val_mse: 6883.4932 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 241.7116 - mse: 241.7116\n",
      "Epoch 3: val_loss improved from 6883.49316 to 5952.44678, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 337ms/step - loss: 241.7116 - mse: 241.7116 - val_loss: 5952.4468 - val_mse: 5952.4468 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 194.2047 - mse: 194.2047\n",
      "Epoch 4: val_loss improved from 5952.44678 to 4833.06982, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 335ms/step - loss: 194.2047 - mse: 194.2047 - val_loss: 4833.0698 - val_mse: 4833.0698 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 160.5188 - mse: 160.5188\n",
      "Epoch 5: val_loss improved from 4833.06982 to 3758.58008, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 336ms/step - loss: 160.5188 - mse: 160.5188 - val_loss: 3758.5801 - val_mse: 3758.5801 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 140.6492 - mse: 140.6492\n",
      "Epoch 6: val_loss improved from 3758.58008 to 2028.21985, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 337ms/step - loss: 140.6492 - mse: 140.6492 - val_loss: 2028.2198 - val_mse: 2028.2198 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 130.7755 - mse: 130.7755\n",
      "Epoch 7: val_loss improved from 2028.21985 to 837.84998, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 336ms/step - loss: 130.7755 - mse: 130.7755 - val_loss: 837.8500 - val_mse: 837.8500 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 125.7592 - mse: 125.7592\n",
      "Epoch 8: val_loss improved from 837.84998 to 340.94263, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 125.7592 - mse: 125.7592 - val_loss: 340.9426 - val_mse: 340.9426 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 125.2172 - mse: 125.2172\n",
      "Epoch 9: val_loss improved from 340.94263 to 173.14790, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 336ms/step - loss: 125.2172 - mse: 125.2172 - val_loss: 173.1479 - val_mse: 173.1479 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 91.9778 - mse: 91.9778\n",
      "Epoch 10: val_loss improved from 173.14790 to 143.75311, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 91.9778 - mse: 91.9778 - val_loss: 143.7531 - val_mse: 143.7531 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 98.0566 - mse: 98.0566\n",
      "Epoch 11: val_loss improved from 143.75311 to 108.62658, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 98.0566 - mse: 98.0566 - val_loss: 108.6266 - val_mse: 108.6266 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 89.6675 - mse: 89.6675\n",
      "Epoch 12: val_loss did not improve from 108.62658\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 89.6675 - mse: 89.6675 - val_loss: 122.9703 - val_mse: 122.9703 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 115.8457 - mse: 115.8457\n",
      "Epoch 13: val_loss did not improve from 108.62658\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 115.8457 - mse: 115.8457 - val_loss: 150.2202 - val_mse: 150.2202 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 88.3980 - mse: 88.3980\n",
      "Epoch 14: val_loss improved from 108.62658 to 94.51865, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 88.3980 - mse: 88.3980 - val_loss: 94.5187 - val_mse: 94.5187 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 83.0843 - mse: 83.0843\n",
      "Epoch 15: val_loss did not improve from 94.51865\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 83.0843 - mse: 83.0843 - val_loss: 205.2922 - val_mse: 205.2922 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 84.7345 - mse: 84.7345\n",
      "Epoch 16: val_loss did not improve from 94.51865\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 84.7345 - mse: 84.7345 - val_loss: 97.7439 - val_mse: 97.7439 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 64.6402 - mse: 64.6402\n",
      "Epoch 17: val_loss did not improve from 94.51865\n",
      "95/95 [==============================] - 31s 329ms/step - loss: 64.6402 - mse: 64.6402 - val_loss: 97.0142 - val_mse: 97.0142 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 59.1045 - mse: 59.1045\n",
      "Epoch 18: val_loss improved from 94.51865 to 88.41566, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 59.1045 - mse: 59.1045 - val_loss: 88.4157 - val_mse: 88.4157 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 70.9686 - mse: 70.9686\n",
      "Epoch 19: val_loss did not improve from 88.41566\n",
      "95/95 [==============================] - 32s 335ms/step - loss: 70.9686 - mse: 70.9686 - val_loss: 88.4818 - val_mse: 88.4818 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 51.3760 - mse: 51.3760\n",
      "Epoch 20: val_loss did not improve from 88.41566\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 51.3760 - mse: 51.3760 - val_loss: 97.3412 - val_mse: 97.3412 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 55.9457 - mse: 55.9457\n",
      "Epoch 21: val_loss did not improve from 88.41566\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 55.9457 - mse: 55.9457 - val_loss: 133.3625 - val_mse: 133.3625 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 53.9096 - mse: 53.9096\n",
      "Epoch 22: val_loss did not improve from 88.41566\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 53.9096 - mse: 53.9096 - val_loss: 115.3784 - val_mse: 115.3784 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 40.3498 - mse: 40.3498\n",
      "Epoch 23: val_loss did not improve from 88.41566\n",
      "95/95 [==============================] - 32s 336ms/step - loss: 40.3498 - mse: 40.3498 - val_loss: 92.9407 - val_mse: 92.9407 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 40.9357 - mse: 40.9357\n",
      "Epoch 24: val_loss did not improve from 88.41566\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 40.9357 - mse: 40.9357 - val_loss: 92.9313 - val_mse: 92.9313 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 49.1267 - mse: 49.1267\n",
      "Epoch 25: val_loss improved from 88.41566 to 83.58815, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 336ms/step - loss: 49.1267 - mse: 49.1267 - val_loss: 83.5882 - val_mse: 83.5882 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.0165 - mse: 30.0165\n",
      "Epoch 26: val_loss did not improve from 83.58815\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 30.0165 - mse: 30.0165 - val_loss: 93.0777 - val_mse: 93.0777 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.2064 - mse: 30.2064\n",
      "Epoch 27: val_loss improved from 83.58815 to 83.15047, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 30.2064 - mse: 30.2064 - val_loss: 83.1505 - val_mse: 83.1505 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 34.8821 - mse: 34.8821\n",
      "Epoch 28: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 34.8821 - mse: 34.8821 - val_loss: 116.7297 - val_mse: 116.7297 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.8955 - mse: 26.8955\n",
      "Epoch 29: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 335ms/step - loss: 26.8955 - mse: 26.8955 - val_loss: 93.7886 - val_mse: 93.7886 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 29.8294 - mse: 29.8294\n",
      "Epoch 30: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 29.8294 - mse: 29.8294 - val_loss: 90.4112 - val_mse: 90.4112 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 45.3477 - mse: 45.3477\n",
      "Epoch 31: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 45.3477 - mse: 45.3477 - val_loss: 99.5590 - val_mse: 99.5590 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 47.0797 - mse: 47.0797\n",
      "Epoch 32: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 47.0797 - mse: 47.0797 - val_loss: 191.8265 - val_mse: 191.8265 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 34.3911 - mse: 34.3911\n",
      "Epoch 33: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 34.3911 - mse: 34.3911 - val_loss: 87.9580 - val_mse: 87.9580 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 36.1686 - mse: 36.1686\n",
      "Epoch 34: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 36.1686 - mse: 36.1686 - val_loss: 88.4334 - val_mse: 88.4334 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.4007 - mse: 30.4007\n",
      "Epoch 35: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 30.4007 - mse: 30.4007 - val_loss: 107.0481 - val_mse: 107.0481 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 29.0655 - mse: 29.0655\n",
      "Epoch 36: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 29.0655 - mse: 29.0655 - val_loss: 87.1497 - val_mse: 87.1497 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 30.8669 - mse: 30.8669\n",
      "Epoch 37: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 30.8669 - mse: 30.8669 - val_loss: 110.4495 - val_mse: 110.4495 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 19.6778 - mse: 19.6778\n",
      "Epoch 38: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 19.6778 - mse: 19.6778 - val_loss: 84.5946 - val_mse: 84.5946 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 16.5414 - mse: 16.5414\n",
      "Epoch 39: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 16.5414 - mse: 16.5414 - val_loss: 84.5408 - val_mse: 84.5408 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.5364 - mse: 15.5364\n",
      "Epoch 40: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 15.5364 - mse: 15.5364 - val_loss: 84.1411 - val_mse: 84.1411 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.0462 - mse: 15.0462\n",
      "Epoch 41: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 15.0462 - mse: 15.0462 - val_loss: 84.5303 - val_mse: 84.5303 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 14.2570 - mse: 14.2570\n",
      "Epoch 42: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 14.2570 - mse: 14.2570 - val_loss: 84.2183 - val_mse: 84.2183 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.7654 - mse: 13.7654\n",
      "Epoch 43: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 330ms/step - loss: 13.7654 - mse: 13.7654 - val_loss: 84.7597 - val_mse: 84.7597 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 13.4586 - mse: 13.4586\n",
      "Epoch 44: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 13.4586 - mse: 13.4586 - val_loss: 83.6850 - val_mse: 83.6850 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.9790 - mse: 12.9790\n",
      "Epoch 45: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 12.9790 - mse: 12.9790 - val_loss: 84.0921 - val_mse: 84.0921 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.4883 - mse: 12.4883\n",
      "Epoch 46: val_loss did not improve from 83.15047\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 12.4883 - mse: 12.4883 - val_loss: 83.2827 - val_mse: 83.2827 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 12.0114 - mse: 12.0114\n",
      "Epoch 47: val_loss improved from 83.15047 to 82.11921, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 12.0114 - mse: 12.0114 - val_loss: 82.1192 - val_mse: 82.1192 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.6946 - mse: 11.6946\n",
      "Epoch 48: val_loss improved from 82.11921 to 80.79407, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 11.6946 - mse: 11.6946 - val_loss: 80.7941 - val_mse: 80.7941 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.4854 - mse: 11.4854\n",
      "Epoch 49: val_loss improved from 80.79407 to 80.64500, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 11.4854 - mse: 11.4854 - val_loss: 80.6450 - val_mse: 80.6450 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.1017 - mse: 11.1017\n",
      "Epoch 50: val_loss improved from 80.64500 to 80.28346, saving model to E-scale2/E2-scale_run9.h5\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 11.1017 - mse: 11.1017 - val_loss: 80.2835 - val_mse: 80.2835 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.7665 - mse: 10.7665\n",
      "Epoch 51: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 10.7665 - mse: 10.7665 - val_loss: 80.7932 - val_mse: 80.7932 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.4882 - mse: 10.4882\n",
      "Epoch 52: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 10.4882 - mse: 10.4882 - val_loss: 81.9330 - val_mse: 81.9330 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.3468 - mse: 10.3468\n",
      "Epoch 53: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 10.3468 - mse: 10.3468 - val_loss: 81.9351 - val_mse: 81.9351 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.2272 - mse: 10.2272\n",
      "Epoch 54: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 10.2272 - mse: 10.2272 - val_loss: 81.6021 - val_mse: 81.6021 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.9750 - mse: 9.9750\n",
      "Epoch 55: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 9.9750 - mse: 9.9750 - val_loss: 81.9055 - val_mse: 81.9055 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.6860 - mse: 9.6860\n",
      "Epoch 56: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 328ms/step - loss: 9.6860 - mse: 9.6860 - val_loss: 82.7198 - val_mse: 82.7198 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.5223 - mse: 9.5223\n",
      "Epoch 57: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 9.5223 - mse: 9.5223 - val_loss: 82.2664 - val_mse: 82.2664 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.3410 - mse: 9.3410\n",
      "Epoch 58: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 329ms/step - loss: 9.3410 - mse: 9.3410 - val_loss: 82.1915 - val_mse: 82.1915 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.3142 - mse: 9.3142\n",
      "Epoch 59: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 330ms/step - loss: 9.3142 - mse: 9.3142 - val_loss: 82.2799 - val_mse: 82.2799 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.1212 - mse: 9.1212\n",
      "Epoch 60: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 9.1212 - mse: 9.1212 - val_loss: 82.4379 - val_mse: 82.4379 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.5327 - mse: 8.5327\n",
      "Epoch 61: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 328ms/step - loss: 8.5327 - mse: 8.5327 - val_loss: 82.5358 - val_mse: 82.5358 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4540 - mse: 8.4540\n",
      "Epoch 62: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 329ms/step - loss: 8.4540 - mse: 8.4540 - val_loss: 82.5730 - val_mse: 82.5730 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4631 - mse: 8.4631\n",
      "Epoch 63: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 8.4631 - mse: 8.4631 - val_loss: 82.2863 - val_mse: 82.2863 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4569 - mse: 8.4569\n",
      "Epoch 64: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 328ms/step - loss: 8.4569 - mse: 8.4569 - val_loss: 82.4244 - val_mse: 82.4244 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4059 - mse: 8.4059\n",
      "Epoch 65: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 330ms/step - loss: 8.4059 - mse: 8.4059 - val_loss: 82.3711 - val_mse: 82.3711 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3807 - mse: 8.3807\n",
      "Epoch 66: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 328ms/step - loss: 8.3807 - mse: 8.3807 - val_loss: 82.4065 - val_mse: 82.4065 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4076 - mse: 8.4076\n",
      "Epoch 67: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 329ms/step - loss: 8.4076 - mse: 8.4076 - val_loss: 82.9689 - val_mse: 82.9689 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3803 - mse: 8.3803\n",
      "Epoch 68: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 8.3803 - mse: 8.3803 - val_loss: 82.4337 - val_mse: 82.4337 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3428 - mse: 8.3428\n",
      "Epoch 69: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 329ms/step - loss: 8.3428 - mse: 8.3428 - val_loss: 82.6051 - val_mse: 82.6051 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3287 - mse: 8.3287\n",
      "Epoch 70: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 329ms/step - loss: 8.3287 - mse: 8.3287 - val_loss: 82.6452 - val_mse: 82.6452 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3362 - mse: 8.3362\n",
      "Epoch 71: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 8.3362 - mse: 8.3362 - val_loss: 82.7468 - val_mse: 82.7468 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2690 - mse: 8.2690\n",
      "Epoch 72: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 8.2690 - mse: 8.2690 - val_loss: 82.7184 - val_mse: 82.7184 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2382 - mse: 8.2382\n",
      "Epoch 73: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 8.2382 - mse: 8.2382 - val_loss: 82.7168 - val_mse: 82.7168 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2201 - mse: 8.2201\n",
      "Epoch 74: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 8.2201 - mse: 8.2201 - val_loss: 82.6066 - val_mse: 82.6066 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1975 - mse: 8.1975\n",
      "Epoch 75: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 8.1975 - mse: 8.1975 - val_loss: 82.8601 - val_mse: 82.8601 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1618 - mse: 8.1618\n",
      "Epoch 76: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 332ms/step - loss: 8.1618 - mse: 8.1618 - val_loss: 82.8479 - val_mse: 82.8479 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1514 - mse: 8.1514\n",
      "Epoch 77: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 8.1514 - mse: 8.1514 - val_loss: 82.6983 - val_mse: 82.6983 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1238 - mse: 8.1238\n",
      "Epoch 78: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 8.1238 - mse: 8.1238 - val_loss: 82.8018 - val_mse: 82.8018 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1278 - mse: 8.1278\n",
      "Epoch 79: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 8.1278 - mse: 8.1278 - val_loss: 82.7145 - val_mse: 82.7145 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1049 - mse: 8.1049\n",
      "Epoch 80: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 8.1049 - mse: 8.1049 - val_loss: 83.0528 - val_mse: 83.0528 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0644 - mse: 8.0644\n",
      "Epoch 81: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 8.0644 - mse: 8.0644 - val_loss: 82.9423 - val_mse: 82.9423 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9933 - mse: 7.9933\n",
      "Epoch 82: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 7.9933 - mse: 7.9933 - val_loss: 82.9725 - val_mse: 82.9725 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9718 - mse: 7.9718\n",
      "Epoch 83: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.9718 - mse: 7.9718 - val_loss: 82.9442 - val_mse: 82.9442 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9525 - mse: 7.9525\n",
      "Epoch 84: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 7.9525 - mse: 7.9525 - val_loss: 82.9426 - val_mse: 82.9426 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9294 - mse: 7.9294\n",
      "Epoch 85: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.9294 - mse: 7.9294 - val_loss: 83.2413 - val_mse: 83.2413 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9472 - mse: 7.9472\n",
      "Epoch 86: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 7.9472 - mse: 7.9472 - val_loss: 83.0998 - val_mse: 83.0998 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8657 - mse: 7.8657\n",
      "Epoch 87: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 7.8657 - mse: 7.8657 - val_loss: 82.9943 - val_mse: 82.9943 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8331 - mse: 7.8331\n",
      "Epoch 88: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.8331 - mse: 7.8331 - val_loss: 82.9190 - val_mse: 82.9190 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8059 - mse: 7.8059\n",
      "Epoch 89: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.8059 - mse: 7.8059 - val_loss: 83.0065 - val_mse: 83.0065 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.7990 - mse: 7.7990\n",
      "Epoch 90: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.7990 - mse: 7.7990 - val_loss: 82.9534 - val_mse: 82.9534 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.7741 - mse: 7.7741\n",
      "Epoch 91: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 334ms/step - loss: 7.7741 - mse: 7.7741 - val_loss: 83.2040 - val_mse: 83.2040 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.7003 - mse: 7.7003\n",
      "Epoch 92: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.7003 - mse: 7.7003 - val_loss: 83.0561 - val_mse: 83.0561 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6973 - mse: 7.6973\n",
      "Epoch 93: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 335ms/step - loss: 7.6973 - mse: 7.6973 - val_loss: 83.1841 - val_mse: 83.1841 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6338 - mse: 7.6338\n",
      "Epoch 94: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.6338 - mse: 7.6338 - val_loss: 83.3523 - val_mse: 83.3523 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6274 - mse: 7.6274\n",
      "Epoch 95: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 331ms/step - loss: 7.6274 - mse: 7.6274 - val_loss: 83.1037 - val_mse: 83.1037 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.5749 - mse: 7.5749\n",
      "Epoch 96: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.5749 - mse: 7.5749 - val_loss: 83.3769 - val_mse: 83.3769 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6088 - mse: 7.6088\n",
      "Epoch 97: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 32s 333ms/step - loss: 7.6088 - mse: 7.6088 - val_loss: 83.0769 - val_mse: 83.0769 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.5184 - mse: 7.5184\n",
      "Epoch 98: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 329ms/step - loss: 7.5184 - mse: 7.5184 - val_loss: 83.5258 - val_mse: 83.5258 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.5256 - mse: 7.5256\n",
      "Epoch 99: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 323ms/step - loss: 7.5256 - mse: 7.5256 - val_loss: 83.2504 - val_mse: 83.2504 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.5202 - mse: 7.5202\n",
      "Epoch 100: val_loss did not improve from 80.28346\n",
      "95/95 [==============================] - 31s 322ms/step - loss: 7.5202 - mse: 7.5202 - val_loss: 83.5228 - val_mse: 83.5228 - lr: 1.0000e-05\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 09:11:05.508771: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - ETA: 0s - loss: 5108.2349 - mse: 5108.2349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 09:11:34.175007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 7557.39062, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 34s 317ms/step - loss: 5108.2349 - mse: 5108.2349 - val_loss: 7557.3906 - val_mse: 7557.3906 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 368.8134 - mse: 368.8134\n",
      "Epoch 2: val_loss improved from 7557.39062 to 6444.93408, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 368.8134 - mse: 368.8134 - val_loss: 6444.9341 - val_mse: 6444.9341 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 209.3176 - mse: 209.3176\n",
      "Epoch 3: val_loss improved from 6444.93408 to 5655.58350, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 209.3176 - mse: 209.3176 - val_loss: 5655.5835 - val_mse: 5655.5835 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 186.7636 - mse: 186.7636\n",
      "Epoch 4: val_loss improved from 5655.58350 to 4436.81592, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 307ms/step - loss: 186.7636 - mse: 186.7636 - val_loss: 4436.8159 - val_mse: 4436.8159 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 158.9554 - mse: 158.9554\n",
      "Epoch 5: val_loss improved from 4436.81592 to 2516.78735, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 158.9554 - mse: 158.9554 - val_loss: 2516.7874 - val_mse: 2516.7874 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 140.3722 - mse: 140.3722\n",
      "Epoch 6: val_loss improved from 2516.78735 to 1732.12183, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 308ms/step - loss: 140.3722 - mse: 140.3722 - val_loss: 1732.1218 - val_mse: 1732.1218 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 112.7720 - mse: 112.7720\n",
      "Epoch 7: val_loss improved from 1732.12183 to 869.76715, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 112.7720 - mse: 112.7720 - val_loss: 869.7672 - val_mse: 869.7672 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 133.2795 - mse: 133.2795\n",
      "Epoch 8: val_loss improved from 869.76715 to 233.85262, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 308ms/step - loss: 133.2795 - mse: 133.2795 - val_loss: 233.8526 - val_mse: 233.8526 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 113.6470 - mse: 113.6470\n",
      "Epoch 9: val_loss did not improve from 233.85262\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 113.6470 - mse: 113.6470 - val_loss: 374.3744 - val_mse: 374.3744 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 191.6973 - mse: 191.6973\n",
      "Epoch 10: val_loss improved from 233.85262 to 102.36893, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 307ms/step - loss: 191.6973 - mse: 191.6973 - val_loss: 102.3689 - val_mse: 102.3689 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 97.0855 - mse: 97.0855\n",
      "Epoch 11: val_loss improved from 102.36893 to 101.45583, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 97.0855 - mse: 97.0855 - val_loss: 101.4558 - val_mse: 101.4558 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 87.3486 - mse: 87.3486\n",
      "Epoch 12: val_loss did not improve from 101.45583\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 87.3486 - mse: 87.3486 - val_loss: 160.7551 - val_mse: 160.7551 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 91.1807 - mse: 91.1807\n",
      "Epoch 13: val_loss did not improve from 101.45583\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 91.1807 - mse: 91.1807 - val_loss: 119.2445 - val_mse: 119.2445 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 76.7006 - mse: 76.7006\n",
      "Epoch 14: val_loss did not improve from 101.45583\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 76.7006 - mse: 76.7006 - val_loss: 108.2556 - val_mse: 108.2556 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 96.7381 - mse: 96.7381\n",
      "Epoch 15: val_loss did not improve from 101.45583\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 96.7381 - mse: 96.7381 - val_loss: 115.5401 - val_mse: 115.5401 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 71.9205 - mse: 71.9205\n",
      "Epoch 16: val_loss did not improve from 101.45583\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 71.9205 - mse: 71.9205 - val_loss: 112.0951 - val_mse: 112.0951 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 78.1200 - mse: 78.1200\n",
      "Epoch 17: val_loss improved from 101.45583 to 94.17776, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 78.1200 - mse: 78.1200 - val_loss: 94.1778 - val_mse: 94.1778 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 83.5766 - mse: 83.5766\n",
      "Epoch 18: val_loss did not improve from 94.17776\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 83.5766 - mse: 83.5766 - val_loss: 107.7349 - val_mse: 107.7349 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 72.4276 - mse: 72.4276\n",
      "Epoch 19: val_loss did not improve from 94.17776\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 72.4276 - mse: 72.4276 - val_loss: 120.1730 - val_mse: 120.1730 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 53.5461 - mse: 53.5461\n",
      "Epoch 20: val_loss did not improve from 94.17776\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 53.5461 - mse: 53.5461 - val_loss: 120.9513 - val_mse: 120.9513 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 52.0542 - mse: 52.0542\n",
      "Epoch 21: val_loss improved from 94.17776 to 92.76650, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 308ms/step - loss: 52.0542 - mse: 52.0542 - val_loss: 92.7665 - val_mse: 92.7665 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 49.4363 - mse: 49.4363\n",
      "Epoch 22: val_loss improved from 92.76650 to 92.36761, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 49.4363 - mse: 49.4363 - val_loss: 92.3676 - val_mse: 92.3676 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 49.3957 - mse: 49.3957\n",
      "Epoch 23: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 49.3957 - mse: 49.3957 - val_loss: 118.7845 - val_mse: 118.7845 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 45.5888 - mse: 45.5888\n",
      "Epoch 24: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 45.5888 - mse: 45.5888 - val_loss: 98.0437 - val_mse: 98.0437 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 41.6716 - mse: 41.6716\n",
      "Epoch 25: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 41.6716 - mse: 41.6716 - val_loss: 96.9450 - val_mse: 96.9450 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 39.8352 - mse: 39.8352\n",
      "Epoch 26: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 39.8352 - mse: 39.8352 - val_loss: 98.6171 - val_mse: 98.6171 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 58.4928 - mse: 58.4928\n",
      "Epoch 27: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 58.4928 - mse: 58.4928 - val_loss: 104.3432 - val_mse: 104.3432 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 50.5605 - mse: 50.5605\n",
      "Epoch 28: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 50.5605 - mse: 50.5605 - val_loss: 98.6404 - val_mse: 98.6404 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 37.2799 - mse: 37.2799\n",
      "Epoch 29: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 37.2799 - mse: 37.2799 - val_loss: 102.9095 - val_mse: 102.9095 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 34.2312 - mse: 34.2312\n",
      "Epoch 30: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 34.2312 - mse: 34.2312 - val_loss: 92.8200 - val_mse: 92.8200 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 46.0161 - mse: 46.0161\n",
      "Epoch 31: val_loss did not improve from 92.36761\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 46.0161 - mse: 46.0161 - val_loss: 114.5645 - val_mse: 114.5645 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 38.5172 - mse: 38.5172\n",
      "Epoch 32: val_loss improved from 92.36761 to 91.19788, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 38.5172 - mse: 38.5172 - val_loss: 91.1979 - val_mse: 91.1979 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 42.5852 - mse: 42.5852\n",
      "Epoch 33: val_loss did not improve from 91.19788\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 42.5852 - mse: 42.5852 - val_loss: 92.8563 - val_mse: 92.8563 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 28.9290 - mse: 28.9290\n",
      "Epoch 34: val_loss did not improve from 91.19788\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 28.9290 - mse: 28.9290 - val_loss: 98.8117 - val_mse: 98.8117 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.5042 - mse: 24.5042\n",
      "Epoch 35: val_loss did not improve from 91.19788\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 24.5042 - mse: 24.5042 - val_loss: 105.9860 - val_mse: 105.9860 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.9441 - mse: 26.9441\n",
      "Epoch 36: val_loss improved from 91.19788 to 85.57491, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 26.9441 - mse: 26.9441 - val_loss: 85.5749 - val_mse: 85.5749 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 24.8753 - mse: 24.8753\n",
      "Epoch 37: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 24.8753 - mse: 24.8753 - val_loss: 171.5114 - val_mse: 171.5114 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 54.3317 - mse: 54.3317\n",
      "Epoch 38: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 54.3317 - mse: 54.3317 - val_loss: 112.0220 - val_mse: 112.0220 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 43.8699 - mse: 43.8699\n",
      "Epoch 39: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 43.8699 - mse: 43.8699 - val_loss: 132.5495 - val_mse: 132.5495 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 42.5325 - mse: 42.5325\n",
      "Epoch 40: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 42.5325 - mse: 42.5325 - val_loss: 90.7530 - val_mse: 90.7530 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 47.1817 - mse: 47.1817\n",
      "Epoch 41: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 47.1817 - mse: 47.1817 - val_loss: 109.3558 - val_mse: 109.3558 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 26.4746 - mse: 26.4746\n",
      "Epoch 42: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 26.4746 - mse: 26.4746 - val_loss: 93.2118 - val_mse: 93.2118 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 21.9020 - mse: 21.9020\n",
      "Epoch 43: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 21.9020 - mse: 21.9020 - val_loss: 91.6287 - val_mse: 91.6287 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 27.1382 - mse: 27.1382\n",
      "Epoch 44: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 27.1382 - mse: 27.1382 - val_loss: 96.6918 - val_mse: 96.6918 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 28.0317 - mse: 28.0317\n",
      "Epoch 45: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 28.0317 - mse: 28.0317 - val_loss: 129.1770 - val_mse: 129.1770 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 32.4865 - mse: 32.4865\n",
      "Epoch 46: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 32.4865 - mse: 32.4865 - val_loss: 109.3171 - val_mse: 109.3171 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 15.3586 - mse: 15.3586\n",
      "Epoch 47: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 15.3586 - mse: 15.3586 - val_loss: 93.1919 - val_mse: 93.1919 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 11.9745 - mse: 11.9745\n",
      "Epoch 48: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 11.9745 - mse: 11.9745 - val_loss: 88.5831 - val_mse: 88.5831 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.9049 - mse: 10.9049\n",
      "Epoch 49: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 10.9049 - mse: 10.9049 - val_loss: 87.9952 - val_mse: 87.9952 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.4814 - mse: 10.4814\n",
      "Epoch 50: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 10.4814 - mse: 10.4814 - val_loss: 88.1670 - val_mse: 88.1670 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 10.2305 - mse: 10.2305\n",
      "Epoch 51: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 10.2305 - mse: 10.2305 - val_loss: 87.5307 - val_mse: 87.5307 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.9461 - mse: 9.9461\n",
      "Epoch 52: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 9.9461 - mse: 9.9461 - val_loss: 89.0055 - val_mse: 89.0055 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.7321 - mse: 9.7321\n",
      "Epoch 53: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 9.7321 - mse: 9.7321 - val_loss: 88.5057 - val_mse: 88.5057 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.6213 - mse: 9.6213\n",
      "Epoch 54: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 9.6213 - mse: 9.6213 - val_loss: 87.5389 - val_mse: 87.5389 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.2137 - mse: 9.2137\n",
      "Epoch 55: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 9.2137 - mse: 9.2137 - val_loss: 87.0763 - val_mse: 87.0763 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 9.2890 - mse: 9.2890\n",
      "Epoch 56: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 302ms/step - loss: 9.2890 - mse: 9.2890 - val_loss: 88.2944 - val_mse: 88.2944 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.5158 - mse: 8.5158\n",
      "Epoch 57: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.5158 - mse: 8.5158 - val_loss: 86.8820 - val_mse: 86.8820 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4756 - mse: 8.4756\n",
      "Epoch 58: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.4756 - mse: 8.4756 - val_loss: 86.8134 - val_mse: 86.8134 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4374 - mse: 8.4374\n",
      "Epoch 59: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.4374 - mse: 8.4374 - val_loss: 86.8780 - val_mse: 86.8780 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4361 - mse: 8.4361\n",
      "Epoch 60: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.4361 - mse: 8.4361 - val_loss: 86.6507 - val_mse: 86.6507 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4472 - mse: 8.4472\n",
      "Epoch 61: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.4472 - mse: 8.4472 - val_loss: 86.7268 - val_mse: 86.7268 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4148 - mse: 8.4148\n",
      "Epoch 62: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.4148 - mse: 8.4148 - val_loss: 86.6215 - val_mse: 86.6215 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.4004 - mse: 8.4004\n",
      "Epoch 63: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.4004 - mse: 8.4004 - val_loss: 86.5442 - val_mse: 86.5442 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3855 - mse: 8.3855\n",
      "Epoch 64: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.3855 - mse: 8.3855 - val_loss: 86.5713 - val_mse: 86.5713 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3611 - mse: 8.3611\n",
      "Epoch 65: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.3611 - mse: 8.3611 - val_loss: 86.4282 - val_mse: 86.4282 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3226 - mse: 8.3226\n",
      "Epoch 66: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.3226 - mse: 8.3226 - val_loss: 86.3678 - val_mse: 86.3678 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.3152 - mse: 8.3152\n",
      "Epoch 67: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.3152 - mse: 8.3152 - val_loss: 86.4536 - val_mse: 86.4536 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2616 - mse: 8.2616\n",
      "Epoch 68: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.2616 - mse: 8.2616 - val_loss: 86.5197 - val_mse: 86.5197 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2641 - mse: 8.2641\n",
      "Epoch 69: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.2641 - mse: 8.2641 - val_loss: 86.5174 - val_mse: 86.5174 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2434 - mse: 8.2434\n",
      "Epoch 70: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.2434 - mse: 8.2434 - val_loss: 86.2942 - val_mse: 86.2942 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.2231 - mse: 8.2231\n",
      "Epoch 71: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 299ms/step - loss: 8.2231 - mse: 8.2231 - val_loss: 86.5320 - val_mse: 86.5320 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1906 - mse: 8.1906\n",
      "Epoch 72: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 301ms/step - loss: 8.1906 - mse: 8.1906 - val_loss: 86.1540 - val_mse: 86.1540 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1743 - mse: 8.1743\n",
      "Epoch 73: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 8.1743 - mse: 8.1743 - val_loss: 86.1567 - val_mse: 86.1567 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.1149 - mse: 8.1149\n",
      "Epoch 74: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 296ms/step - loss: 8.1149 - mse: 8.1149 - val_loss: 86.3250 - val_mse: 86.3250 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0845 - mse: 8.0845\n",
      "Epoch 75: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 310ms/step - loss: 8.0845 - mse: 8.0845 - val_loss: 85.9659 - val_mse: 85.9659 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0573 - mse: 8.0573\n",
      "Epoch 76: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 299ms/step - loss: 8.0573 - mse: 8.0573 - val_loss: 85.9627 - val_mse: 85.9627 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0766 - mse: 8.0766\n",
      "Epoch 77: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 8.0766 - mse: 8.0766 - val_loss: 86.0313 - val_mse: 86.0313 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0067 - mse: 8.0067\n",
      "Epoch 78: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 300ms/step - loss: 8.0067 - mse: 8.0067 - val_loss: 85.8102 - val_mse: 85.8102 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0211 - mse: 8.0211\n",
      "Epoch 79: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 300ms/step - loss: 8.0211 - mse: 8.0211 - val_loss: 85.9569 - val_mse: 85.9569 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 8.0016 - mse: 8.0016\n",
      "Epoch 80: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 8.0016 - mse: 8.0016 - val_loss: 85.8709 - val_mse: 85.8709 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9014 - mse: 7.9014\n",
      "Epoch 81: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 7.9014 - mse: 7.9014 - val_loss: 85.6686 - val_mse: 85.6686 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9294 - mse: 7.9294\n",
      "Epoch 82: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 298ms/step - loss: 7.9294 - mse: 7.9294 - val_loss: 85.7780 - val_mse: 85.7780 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.9206 - mse: 7.9206\n",
      "Epoch 83: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 296ms/step - loss: 7.9206 - mse: 7.9206 - val_loss: 85.7382 - val_mse: 85.7382 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8352 - mse: 7.8352\n",
      "Epoch 84: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 298ms/step - loss: 7.8352 - mse: 7.8352 - val_loss: 85.5988 - val_mse: 85.5988 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.7812 - mse: 7.7812\n",
      "Epoch 85: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 28s 295ms/step - loss: 7.7812 - mse: 7.7812 - val_loss: 85.6202 - val_mse: 85.6202 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.8225 - mse: 7.8225\n",
      "Epoch 86: val_loss did not improve from 85.57491\n",
      "95/95 [==============================] - 29s 302ms/step - loss: 7.8225 - mse: 7.8225 - val_loss: 85.7603 - val_mse: 85.7603 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.7288 - mse: 7.7288\n",
      "Epoch 87: val_loss improved from 85.57491 to 85.41795, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 301ms/step - loss: 7.7288 - mse: 7.7288 - val_loss: 85.4180 - val_mse: 85.4180 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6996 - mse: 7.6996\n",
      "Epoch 88: val_loss improved from 85.41795 to 85.32465, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 301ms/step - loss: 7.6996 - mse: 7.6996 - val_loss: 85.3246 - val_mse: 85.3246 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6542 - mse: 7.6542\n",
      "Epoch 89: val_loss did not improve from 85.32465\n",
      "95/95 [==============================] - 29s 303ms/step - loss: 7.6542 - mse: 7.6542 - val_loss: 85.6860 - val_mse: 85.6860 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6712 - mse: 7.6712\n",
      "Epoch 90: val_loss did not improve from 85.32465\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 7.6712 - mse: 7.6712 - val_loss: 85.4955 - val_mse: 85.4955 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.6262 - mse: 7.6262\n",
      "Epoch 91: val_loss did not improve from 85.32465\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 7.6262 - mse: 7.6262 - val_loss: 85.4544 - val_mse: 85.4544 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.5859 - mse: 7.5859\n",
      "Epoch 92: val_loss improved from 85.32465 to 85.28694, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 7.5859 - mse: 7.5859 - val_loss: 85.2869 - val_mse: 85.2869 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.5426 - mse: 7.5426\n",
      "Epoch 93: val_loss did not improve from 85.28694\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 7.5426 - mse: 7.5426 - val_loss: 85.4103 - val_mse: 85.4103 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.5032 - mse: 7.5032\n",
      "Epoch 94: val_loss improved from 85.28694 to 85.19719, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 28s 299ms/step - loss: 7.5032 - mse: 7.5032 - val_loss: 85.1972 - val_mse: 85.1972 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.4214 - mse: 7.4214\n",
      "Epoch 95: val_loss improved from 85.19719 to 85.06003, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 28s 296ms/step - loss: 7.4214 - mse: 7.4214 - val_loss: 85.0600 - val_mse: 85.0600 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.4147 - mse: 7.4147\n",
      "Epoch 96: val_loss did not improve from 85.06003\n",
      "95/95 [==============================] - 28s 296ms/step - loss: 7.4147 - mse: 7.4147 - val_loss: 85.5716 - val_mse: 85.5716 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.3849 - mse: 7.3849\n",
      "Epoch 97: val_loss did not improve from 85.06003\n",
      "95/95 [==============================] - 28s 298ms/step - loss: 7.3849 - mse: 7.3849 - val_loss: 85.0749 - val_mse: 85.0749 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.3446 - mse: 7.3446\n",
      "Epoch 98: val_loss improved from 85.06003 to 84.94755, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 305ms/step - loss: 7.3446 - mse: 7.3446 - val_loss: 84.9475 - val_mse: 84.9476 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.3791 - mse: 7.3791\n",
      "Epoch 99: val_loss did not improve from 84.94755\n",
      "95/95 [==============================] - 29s 304ms/step - loss: 7.3791 - mse: 7.3791 - val_loss: 85.5068 - val_mse: 85.5068 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "95/95 [==============================] - ETA: 0s - loss: 7.2955 - mse: 7.2955\n",
      "Epoch 100: val_loss improved from 84.94755 to 84.92284, saving model to E-scale2/E2-scale_run10.h5\n",
      "95/95 [==============================] - 29s 306ms/step - loss: 7.2955 - mse: 7.2955 - val_loss: 84.9228 - val_mse: 84.9228 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# This code trains 10 Convolutional Neural Networks (CNNs) on differently split subsets\n",
    "# of a dataset for binary classification,saves the best model of each training session, \n",
    "# and records their training histories.\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Create the directory for saving models and histories if it doesn't exist\n",
    "save_dir = 'E-scale'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Initialize lists to store the training histories and filenames of the best models\n",
    "histories = []\n",
    "model_filenames = []\n",
    "\n",
    "# Define the ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,      # Factor to reduce the learning rate\n",
    "    patience=10,     # Number of epochs with no improvement to wait before reducing LR\n",
    "    min_lr=0.00001   # Minimum learning rate\n",
    ")\n",
    "\n",
    "# Loop to train 10 CNN models with different data splits\n",
    "for i in range(10):\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i)\n",
    "\n",
    "    # Create a new CNN model for each iteration\n",
    "    model = NOIREnet()\n",
    "\n",
    "    # Define the filename for the checkpoint model\n",
    "    model_filename = os.path.join(save_dir, f'E-scale_run{i+1}.h5')\n",
    "\n",
    "    # Define a checkpoint callback to save the best model based on validation accuracy\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        model_filename,\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        save_weights_only=False\n",
    "    )\n",
    "\n",
    "    # Train the model with specified callbacks including ReduceLROnPlateau\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=64,\n",
    "        epochs=100,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[checkpoint_callback, reduce_lr]  # Include ReduceLROnPlateau callback\n",
    "    )\n",
    "\n",
    "    # Save the training history and the filename of the saved best model\n",
    "    histories.append(history.history)\n",
    "    model_filenames.append(model_filename)\n",
    "\n",
    "# Optionally, save the training histories to a file in the same 'E-scale' directory\n",
    "history_filename = os.path.join(save_dir, 'training_histories.pkl')\n",
    "with open(history_filename, 'wb') as file:\n",
    "    pickle.dump({'histories': histories, 'model_filenames': model_filenames}, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a690a-733a-4d3b-afb1-b0e3b206d660",
   "metadata": {},
   "source": [
    "## 2 - Test the performance of NOIRE-Net on an independent test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f89d8-3587-466a-a86b-26365eb8a92c",
   "metadata": {},
   "source": [
    "### 2.1 - Define a function to get ionogram labels from the testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f04a5-1f1c-4961-a88a-6fbbb955fce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code defines the get_majority_label function which determines the majority label \n",
    "# (True or False) among a list of .par files, and in case of a tie, it randomly selects a label.\n",
    "def get_majority_label(par_files):\n",
    "    # Extract labels from each .par file using the get_regression_label_from_par function\n",
    "    labels = [get_regression_label_from_par(f) for f in par_files]\n",
    "\n",
    "    # If the majority of labels are True, return True\n",
    "    if labels.count(True) > len(labels) / 2:\n",
    "        return True\n",
    "    # If the majority of labels are False, return False\n",
    "    elif labels.count(False) > len(labels) / 2:\n",
    "        return False\n",
    "    # If there is a tie between True and False labels, randomly choose one\n",
    "    else:\n",
    "        return random.choice([True, False])  # Randomize in case of a tie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411faa7-67ce-4838-8090-8f9b2d742b2f",
   "metadata": {},
   "source": [
    "### 2.2 - Define a function to load and process test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc09a7b-ca6e-4587-a920-09739013287d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code defines the load_and_preprocess_image function, which loads an image from a \n",
    "# specified path, converts it to grayscale, resizes it to 310x310 pixels, normalizes its pixel\n",
    "# values, and returns the processed image as an array.\n",
    "def load_and_preprocess_image(image_path):\n",
    "    # Load the image from the given path, convert it to grayscale, and resize it to 310x310 pixels\n",
    "    image = load_img(image_path, color_mode='grayscale', target_size=(310, 310))\n",
    "\n",
    "    # Convert the image to a numpy array\n",
    "    image = img_to_array(image)\n",
    "\n",
    "    # Normalize the pixel values to be in the range [0, 1]\n",
    "    image /= 255.0\n",
    "\n",
    "    # Return the preprocessed image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a051fa-44f6-4c89-82e1-f0ccd304024b",
   "metadata": {},
   "source": [
    "### 2.3 - Load the trained models with the highest validation accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd34df-3db6-41c3-aea5-57afc2eeaa0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to load models\n",
    "def load_models(models_dir):\n",
    "    return [load_model(os.path.join(models_dir, mf)) for mf in os.listdir(models_dir) if mf.endswith('.h5')]\n",
    "\n",
    "# Specify the directory where the trained models are stored\n",
    "models_dir = 'E-classify'\n",
    "\n",
    "# Load the models\n",
    "models = load_models(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2bc90a-ba73-4029-8331-baaedcbb0105",
   "metadata": {},
   "source": [
    "### 2.4 - Define a function to prepare the resting data for comparison with CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f21219-1788-49a4-9321-47832ae4fdbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function prepares the testing dataset by loading and processing images from a \n",
    "# specified directory and determining corresponding human labels based on majority voting\n",
    "# from associated .par files.\n",
    "def prepare_test_data(ionograms_dir, parameters_dir):\n",
    "    X_test = []  # List to store preprocessed images\n",
    "    y_human = []  # List to store corresponding human labels\n",
    "\n",
    "    # Cache the paths of all .par files for efficient access\n",
    "    par_files_cache = {f: os.path.join(parameters_dir, f) for f in os.listdir(parameters_dir)}\n",
    "\n",
    "    # Iterate through each image file in the ionograms directory\n",
    "    for img_file in os.listdir(ionograms_dir):\n",
    "        if img_file.endswith('.png'):  # Only process .png files\n",
    "            img_path = os.path.join(ionograms_dir, img_file)\n",
    "            X_test.append(load_and_preprocess_image(img_path))  # Load and preprocess the image\n",
    "\n",
    "            # Extract timestamp from the image filename\n",
    "            timestamp = os.path.splitext(img_file)[0]\n",
    "\n",
    "            # Get all .par files relevant to the current image based on timestamp\n",
    "            relevant_par_files = [fpath for fname, fpath in par_files_cache.items() if timestamp in fname]\n",
    "            y_human.append(get_majority_label(relevant_par_files))  # Determine the majority label\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    return np.array(X_test), np.array(y_human).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a6848-033d-4b97-9148-b01fe0ce6327",
   "metadata": {},
   "source": [
    "### 2.5 - Define a function compare the CNN predictions to the human labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25fd9b5-5aa7-4157-beae-66220de9108f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function evaluates a list of pre-loaded CNN models on a prepared test dataset, calculates key\n",
    "# performance metrics (precision, recall, F1-score, accuracy), prints their mean and standard deviation,\n",
    "# and returns the normalized confusion matrices for each model.\n",
    "def evaluate_models(models, X_test, y_human):\n",
    "    metrics = {'precision': [], 'recall': [], 'f1': [], 'accuracy': []}  # Dictionary to store metrics for each model\n",
    "    confusion_matrices = []  # List to store confusion matrices for each model\n",
    "\n",
    "    # Iterate over each model and evaluate it\n",
    "    for model in models:\n",
    "        y_pred = model.predict(X_test).round().astype(int)  # Predict labels for the test dataset\n",
    "\n",
    "        # Calculate and store the performance metrics for the current model\n",
    "        metrics['precision'].append(precision_score(y_human, y_pred))\n",
    "        metrics['recall'].append(recall_score(y_human, y_pred))\n",
    "        metrics['f1'].append(f1_score(y_human, y_pred))\n",
    "        metrics['accuracy'].append(accuracy_score(y_human, y_pred))\n",
    "\n",
    "        # Calculate and store the normalized confusion matrix\n",
    "        confusion_matrices.append(confusion_matrix(y_human, y_pred, normalize='true'))\n",
    "\n",
    "    # Print the mean and standard deviation for each metric\n",
    "    for metric, values in metrics.items():\n",
    "        print(f\"Mean {metric.capitalize()}: {np.mean(values):.3f}, Std {metric.capitalize()}: {np.std(values):.3f}\")\n",
    "\n",
    "    return confusion_matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77730928-60d6-445e-bc3c-4e0032b96a48",
   "metadata": {},
   "source": [
    "### 2.6 - Specify testing directories and prepare testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e111cc-bc88-470b-995e-278041927e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the directory where the testing data is located\n",
    "testing_dir = 'testing'\n",
    "\n",
    "# Specify the directory where the input ionograms are located\n",
    "ionograms_dir = os.path.join(testing_dir, 'ionograms')\n",
    "\n",
    "# Specify the directory where the output parameters are located\n",
    "parameters_dir = os.path.join(testing_dir, 'parameters')\n",
    "\n",
    "# Load and prepare the testing data\n",
    "X_test, y_human = prepare_test_data(ionograms_dir, parameters_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712b1aa-747a-4d4e-9212-9f83ed02ca56",
   "metadata": {},
   "source": [
    "### 2.7 - Evaluate the models using precision, recall, F1-score, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bce69-be60-494f-878d-26a4a6e7c65a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the models located in 'models_dir' using the test data in 'testing_dir'\n",
    "# and store the returned confusion matrices\n",
    "confusion_matrices = evaluate_models(models, X_test, y_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3abad7-447e-433f-8a60-b54554d057bc",
   "metadata": {},
   "source": [
    "### 2.8 - Calculate the mean and standard deviation of TP, FN, FP and TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3af965-6919-49a8-8781-0e0f33421841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert list of confusion matrices to a 3D NumPy array for easier calculations\n",
    "confusion_matrices = np.array(confusion_matrices)\n",
    "\n",
    "# Calculate mean and standard deviation for TP, FN, FP, TN\n",
    "mean_tp = np.mean(confusion_matrices[:, 1, 1])\n",
    "std_tp = np.std(confusion_matrices[:, 1, 1])\n",
    "\n",
    "mean_fn = np.mean(confusion_matrices[:, 1, 0])\n",
    "std_fn = np.std(confusion_matrices[:, 1, 0])\n",
    "\n",
    "mean_fp = np.mean(confusion_matrices[:, 0, 1])\n",
    "std_fp = np.std(confusion_matrices[:, 0, 1])\n",
    "\n",
    "mean_tn = np.mean(confusion_matrices[:, 0, 0])\n",
    "std_tn = np.std(confusion_matrices[:, 0, 0])\n",
    "\n",
    "# Metrics, means, and standard deviations\n",
    "means = [mean_tp, mean_fn, mean_fp, mean_tn]\n",
    "std_devs = [std_tp, std_fn, std_fp, std_tn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afdf7bc-b2f4-4e2f-9f8c-beb9252378b3",
   "metadata": {},
   "source": [
    "## 3 - Display the confusion matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e5485-206d-4adf-a015-f40767f4d547",
   "metadata": {},
   "source": [
    "### 3.1 - Define Function for Text Color Based on Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0855531-5415-4c41-b608-b842c585a43a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function determines the text color (black or white) based on the background color's\n",
    "# luminance for better readability.\n",
    "def text_color_based_on_bg(bg_color):\n",
    "    # Calculate the perceptual luminance of the color\n",
    "    luminance = (0.299 * bg_color[0] + 0.587 * bg_color[1] + 0.114 * bg_color[2])\n",
    "    return 'white' if luminance < 0.5 else 'black'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe17e3-1220-4083-ba76-fae52c70fc60",
   "metadata": {},
   "source": [
    "### 3.2 - Plot the Confusion Matrix Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72244be-2546-42c8-a21f-bf0b0198296e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code creates a 2x2 plot with colored squares representing the mean and standard \n",
    "# deviation of TP, FN, FP, and TN from the confusion matrices.\n",
    "\n",
    "# Setup color map with normalization between 0 and 1\n",
    "cmap = plt.cm.inferno\n",
    "norm = mcolors.Normalize(vmin=0, vmax=1)\n",
    "\n",
    "# Create a 2x2 subplot figure with adjusted spacing\n",
    "fig, axs = plt.subplots(2, 2, figsize=(6, 6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "means = [mean_tp, mean_fn, mean_fp, mean_tn]\n",
    "std_devs = [std_tp, std_fn, std_fp, std_tn]\n",
    "\n",
    "# Iterate over each subplot to add the confusion matrix data\n",
    "for i, ax in enumerate(axs):\n",
    "    color = cmap(norm(means[i]))  # Set the color based on the mean value\n",
    "    ax.add_patch(plt.Rectangle((0, 0), 1, 1, color=color))  # Create a colored square\n",
    "\n",
    "    text_color = text_color_based_on_bg(color)  # Determine text color\n",
    "    text = f'{means[i]:.3f}  {std_devs[i]:.3f}'  # Format text for mean  std deviation\n",
    "    ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=14, color=text_color)  # Add text to the subplot\n",
    "\n",
    "    ax.axis('off')  # Remove axes\n",
    "\n",
    "# Adjust subplot parameters so squares touch each other\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# Add a colorbar and adjust its font size\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=axs, orientation='horizontal', fraction=0.046, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=14)  # Set font size for colorbar ticks\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a2a51-1340-426a-b634-be1d2afbf625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
