{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba4361-557f-4d7f-aae8-1c266f6a8007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d70445-0923-4e1f-872f-cb2b0ce34fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the paths to the directories\n",
    "base_dir = ''  # You should replace this with the actual base path\n",
    "training_dir = os.path.join(base_dir, 'training')\n",
    "testing_dir = os.path.join(base_dir, 'testing')\n",
    "validation_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d89627-dcb2-4741-9781-47583d4e81ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_regression_label_from_par(par_file_path):\n",
    "    try:\n",
    "        with open(par_file_path, 'r') as file:\n",
    "            content = file.readline().strip()\n",
    "            items = content.split()\n",
    "\n",
    "            # Check if both second and fourth items are numbers\n",
    "            if items[0].lower() != 'nan' and items[2].lower() != 'nan':\n",
    "                return float(items[0]), float(items[2])\n",
    "            else:\n",
    "                return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {par_file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b12a43-ffba-41ae-b305-2c7124e5b70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(os.path.join(directory, 'ionograms')):\n",
    "        if filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory, 'ionograms', filename)\n",
    "            par_file_path = os.path.join(directory, 'parameters', filename.replace('.png', '.par'))\n",
    "            \n",
    "            # Get the regression labels from the .par file\n",
    "            regression_label = get_regression_label_from_par(par_file_path)\n",
    "            \n",
    "            # Proceed only if valid regression labels are found\n",
    "            if regression_label is not None:\n",
    "                image = load_and_preprocess_image(image_path)\n",
    "                images.append(image)\n",
    "                labels.append(regression_label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99388b-c083-40e4-995a-7134a88f94a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update your load_and_preprocess_image function if necessary to ensure consistent image sizes\n",
    "def load_and_preprocess_image(image_path, target_size=(310, 310)):\n",
    "    image = load_img(image_path, target_size=target_size, color_mode='grayscale')\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e941416-6fdc-4fc4-812b-73f2f17849aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "X_train, y_train = prepare_dataset('training')\n",
    "X_val, y_val = prepare_dataset('testing')\n",
    "X_test, y_test = prepare_dataset('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d5d6e-07bc-4936-8138-309fd998dc3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf1faf-d496-4e08-893b-bba1e2a5c727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(310, 310, 1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d039427-69c9-45ad-b885-cb6737ab8689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'SCALE-Net-F.h5',\n",
    "    monitor='val_loss',          # Monitor the validation accuracy\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='min',                      # The direction is set to maximize `val_accuracy`\n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,      # Reduce lr by a factor of 0.1\n",
    "    patience=50,     # Number of epochs with no improvement\n",
    "    min_lr=0.00001    # Minimum learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96477fbb-066c-41ed-beab-cb68e227211e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7125659-1408-4db4-bc54-7baf7741459d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "    batch_size=32,                        \n",
    "    epochs=1000,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_callback, reduce_lr]  # Include the callback here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db123649-bdd0-4608-a8bf-89fd1cdf3dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = load_model('SCALE-Net-F.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9d250-b64d-4685-81ec-ef3670dbddce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the history of training and validation accuracy\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Extract the number of epochs\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_loss, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 300)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9051d21-b339-40a2-8c76-544ef61331c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Assuming best_model is your loaded model and X_test, y_test are your test data and labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE) on Test Set:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73ca6c-c6f6-4a0c-a48e-3ad7a3b97597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def draw_colored_lines_on_image(image, horizontal, vertical, color='r'):\n",
    "    \"\"\"\n",
    "    Draws horizontal and vertical colored lines on the image.\n",
    "    :param image: The grayscale image on which to draw.\n",
    "    :param horizontal: The y-coordinate for the horizontal line.\n",
    "    :param vertical: The x-coordinate for the vertical line.\n",
    "    :param color: Line color ('r' for red, 'g' for green).\n",
    "    :return: Image with colored lines.\n",
    "    \"\"\"\n",
    "    # Convert grayscale to RGB\n",
    "    if len(image.shape) == 2 or image.shape[2] == 1:\n",
    "        image_rgb = np.stack((image.squeeze(),) * 3, axis=-1)\n",
    "    else:\n",
    "        image_rgb = image\n",
    "\n",
    "    # Draw lines\n",
    "    if color == 'r':\n",
    "        line_color = [1, 0, 0]  # Red\n",
    "    elif color == 'b':\n",
    "        line_color = [0, 0, 1]  # Green\n",
    "\n",
    "    image_rgb[int(horizontal), :] = line_color  # Horizontal line\n",
    "    image_rgb[:, int(vertical)] = line_color  # Vertical line\n",
    "\n",
    "    return image_rgb\n",
    "\n",
    "# Select 9 random images and their labels from the test set\n",
    "indices = random.sample(range(len(X_test)), 9)\n",
    "sample_images = X_test[indices]\n",
    "sample_labels = y_test[indices]\n",
    "sample_predictions = best_model.predict(sample_images)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Original image flipped\n",
    "    img = np.flipud(sample_images[i].squeeze())  # Remove channel dimension and flip\n",
    "\n",
    "    # True and predicted values, adjusted for the flip\n",
    "    true_vertical, true_horizontal = sample_labels[i]  # Swap the order here\n",
    "    true_horizontal = img.shape[0] - true_horizontal  # Adjust for flipping\n",
    "    pred_vertical, pred_horizontal = sample_predictions[i]  # Swap the order here\n",
    "    pred_horizontal = img.shape[0] - pred_horizontal  # Adjust for flipping\n",
    "\n",
    "    # Draw lines\n",
    "    img_with_true_lines = draw_colored_lines_on_image(img, true_horizontal, true_vertical, color='b')\n",
    "    img_with_pred_lines = draw_colored_lines_on_image(img, pred_horizontal, pred_vertical, color='r')\n",
    "\n",
    "    # Combined image\n",
    "    combined_img = np.maximum(img_with_true_lines, img_with_pred_lines)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(combined_img, cmap='gray')\n",
    "    ax.set_title(f\"Image {indices[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e211c-7ac6-43b2-b5b2-8f371cfcd651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
