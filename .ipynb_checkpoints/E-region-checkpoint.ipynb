{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba4361-557f-4d7f-aae8-1c266f6a8007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d70445-0923-4e1f-872f-cb2b0ce34fb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the paths to the directories\n",
    "base_dir = ''  # You should replace this with the actual base path\n",
    "training_dir = os.path.join(base_dir, 'training')\n",
    "testing_dir = os.path.join(base_dir, 'testing')\n",
    "validation_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d89627-dcb2-4741-9781-47583d4e81ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_label_from_par(par_file_path):\n",
    "    try:\n",
    "        with open(par_file_path, 'r') as file:\n",
    "            content = file.readline().strip()  # Read the first line of the file\n",
    "            items = content.split()  # Split the line into items\n",
    "            # Check if the second and fourth items are not 'nan'\n",
    "            is_e_region = items[1].lower() != 'nan' or items[3].lower() != 'nan'\n",
    "        return is_e_region\n",
    "    except IndexError:\n",
    "        # If there are not enough items, return False indicating no E-region\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        # If any other exception occurs, print it and return False\n",
    "        print(f\"Error reading {par_file_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de3a56-d6c4-4aae-9280-9a3ff7907aab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess images function adjusted for new resolution\n",
    "def load_and_preprocess_image(image_path, target_size=(310, 310)):\n",
    "    image = load_img(image_path, target_size=target_size, color_mode='grayscale')\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b12a43-ffba-41ae-b305-2c7124e5b70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to prepare dataset\n",
    "def prepare_dataset(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(os.path.join(directory, 'ionograms')):\n",
    "        if filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory, 'ionograms', filename)\n",
    "            par_file_path = os.path.join(directory, 'parameters', filename.replace('.png', '.par'))\n",
    "            \n",
    "            image = load_and_preprocess_image(image_path)\n",
    "            label = get_label_from_par(par_file_path)\n",
    "            \n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels).astype(int)\n",
    "\n",
    "# Prepare datasets\n",
    "X_train, y_train = prepare_dataset('training')\n",
    "X_val, y_val = prepare_dataset('testing')\n",
    "X_test, y_test = prepare_dataset('validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cf1faf-d496-4e08-893b-bba1e2a5c727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(310, 310, 1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d039427-69c9-45ad-b885-cb6737ab8689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    'NOIRE-Net-E.h5',\n",
    "    monitor='val_accuracy',          # Monitor the validation accuracy\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',                      # The direction is set to maximize `val_accuracy`\n",
    "    save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96477fbb-066c-41ed-beab-cb68e227211e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7125659-1408-4db4-bc54-7baf7741459d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "    batch_size=64,                        \n",
    "    epochs=200,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint_callback]  # Include the callback here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db123649-bdd0-4608-a8bf-89fd1cdf3dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = load_model('NOIRE-Net-E.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fed25-d41e-4353-be93-f338a07ba9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the more complex model\n",
    "test_loss_complex, test_acc_complex = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Model Accuracy: {test_acc_complex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9d250-b64d-4685-81ec-ef3670dbddce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the history of training and validation accuracy\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# Extract the number of epochs\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, train_acc, 'bo-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9051d21-b339-40a2-8c76-544ef61331c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict classes using the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.round(y_pred).astype(int).flatten()  # Convert probabilities to class labels\n",
    "\n",
    "# Calculate Precision, Recall, F1-score, and Accuracy\n",
    "report = classification_report(y_test, y_pred_classes, target_names=['Non-E-region', 'E-region'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73ca6c-c6f6-4a0c-a48e-3ad7a3b97597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate and display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
